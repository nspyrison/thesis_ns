---
chapter: 1
knit: "bookdown::render_book"
---

# Introduction {#ch-introduction}

<!-- Exploratory data analysis -->
Exploratory Data Analysis (EDA) is the process of the initial summarization and visualization of a dataset. EDA is a critical first step of checking for realistic values, identifying improper data formats, and revealing insights [@tukey_exploratory_1977]. @wickham_r_2017 describe the analyst workflow into a series of discrete steps. The data is imported and cleaned before entering into an iterated cycle of transformation, visualization, and modeling. This work focuses the visualization step, specifically for quantitative multivariate data. The implementation of packages also facilitates transformation and modeling while these aspects are not the primary contributions.

<!-- (ref:ch1fig1-cap) Data analysis workflow [@wickham_r_2017]. This work focuses primarily on visualization of multivariate data. -->
<!-- ```{r ch1fig1, echo=F, out.width="100%", fig.cap = "(ref:ch1fig1-cap)"} -->
<!-- nsSafeIncGraphic("./figures/ch1_fig1_data_analysis_workflow.PNG") -->
<!-- ``` -->

<!-- Dimensionality increases, making data viz hard -->
Multivariate data has become ubiquitous in contemporary data sets. Multivariate data is found in physics, biology, social sciences, and manufacturing to name a few [@wang_mapping_2018; @huber_orchestrating_2015; @brown_confirmatory_2015; @evans_multivariate_2017]. As the number of variables in the data increases, it becomes increasingly difficult to visualize this space and reveal the structure of the data. This thesis addresses the visualization and analysis of multivariate data.

<!-- Shadow analogy segue to linear proj. -->
One of the most common and successful approaches to visualize multivariate data is to use linear projection, which approximates $p$-dimensional data onto 1-3 display dimensions. In the same way that 3D object casts a 2D shadow, these projections cast one orientation of the data onto a lower plane.

<!-- Linear projections -->
Linear projections defines new variables called components, essentially a linear combination, orientation of the original variables. A basis is the orthonormal matrix that maps the variable to the component output space. The basis of a linear projections is frequently illustrated with a biplot [@gabriel_biplot_1971]. The biplot shows the magnitude and angle each variable contributes to the resulting display dimensions inscribed in a unit circle, such as in Figure \@ref(fig:ch1fig2). Traditional axes-based visuals look at 1- to 3D views of orthogonal variables. In contrast by viewing linear combinations of these variables on the axes can reveal features that exist in more than three dimension. 

(ref:ch1fig2-cap) Two linear projections of penguins data. Biplot circles depict the basis, the direction and magnitudes of the contributions of the variables. In the left panel, the direction of separation of the orange cluster is mainly in the direction that `bl` contributes, meaning that the variable is sensitive to the separation of this cluster. The purple cluster's separation is attributed primarily to `bd` and `fl` and `bm` to a smaller extent. Many other linear orientations do not resolve structures of interest, such as cluster separation (right panel). The Palmer Penguin data [@gorman_ecological_2014; @horst_palmerpenguins_2020] measures four physical variables: bill length (`bl`), bill depth (`bd`), flipper length (`fl`), and body mass (`bm`) for three species of penguins.
```{r ch1fig2, echo=F, out.width="100%", fig.cap = "(ref:ch1fig2-cap)"}
nsSafeIncGraphic("./figures/ch1_fig2_penguin_cl_sep.png")
```

<!-- Talk about features, structure and sensitivity -->
There are many features that an analyst may be interested in when analyzing multivariate data. Shape, spread, identifying clusters, outliers, and irregularities are the most common. Not all of the basis orientations of a data will reveal the features the data. Thus the choice of projection is important. Furthermore, the analyst is interested in understanding which combination of variables indicate the feature. For instance, Figure \@ref(fig:ch1fig2) shows two linear projections of penguin data. The color and shape of the data points distinguish the three penguin species. The linear projection used in the left panel contains a significant separation of the clusters, while the right panel does not show a discern differences in the species clusters.

<!-- Tours, animated linear projections -->
Therefore, it makes sense for an analyst to explore many projections with very different bases. However, it can be difficult to link observations across different projections with no relationship to one another. The _tour_ is a dynamic visualization that overcomes this difficulty [@cook_grand_2008; @lee_state_2021]. It is a class of linear projections that animate over small changes to the projection basis. A key feature of the tour is the visual permanence and trackability of the points through the frames. In the shadow analogy, an object such as a barstool will cast a circular shadow if the light is directly above the seat. However, such a shadow does not give the observer sufficient information as it could arise from any number of shapes that contain circular profiles: spheres, cylinders, or circles. However, if the stool was rotated, its legs would show in the shadow quickly giving an intuitive interpretation of the object. Similarly, the rotation of a data object yields information about its structure.

<!-- Manual tour -->
Originally component spaces and the original tour have no means to influence the basis or its path. @cook_manual_1997 introduced the _manual tour_, offering user control over the basis. By selecting a variable and initializing an additional manipulation dimension to a projection, the contribution of the variable can be controlled through a rotation of the manipulation space. This user-controlled steering of the basis path enables the analyst to explore what happens to the structure when one variable is removed or the contribution of another is increased. 

<!-- Radial tour -->
The manual tour allows the analyst to control the angle and magnitude that a variable contributes to the projection. However, controlling the magnitude is generally more meaningful as angular manipulations effectively rotate the projection, changing the relative position but not the contributions of a variables. Because of this, this work focuses on a specific manual tour, the _radial tour_, where the angle of the manipulated variable is fixed, but the analyst can vary its magnitude, changing its radius. Figure \@ref(fig:ch1fig3) shows a radial tour of the penguins data varying the contribution of bill length. The left panel has a full contribution from `bl`, middle panels contains about half contribution while bill length has been removed in the the right panel. The separation between orange and green clusters was in the direction that `bl` contributed and when this contribution is removed so to is the separation of the clusters; we say this variable is sensitive to the separation of these two clusters.

(ref:ch1fig3-cap) A radial tour changing the contribution of bill length (`bl`). When bill length has a considerable contribution, the clusters of orange and green are separated (left and middle). When its contribution is removed, the clusters overlap (right). Because of this, we say that bill length is sensitive to the separation of these two species. An animated version can be viewed at [vimeo.com/676723431](https://vimeo.com/676723431).
```{r ch1fig3, echo=F, out.width="100%", fig.cap = "(ref:ch1fig3-cap)"}
nsSafeIncGraphic("./figures/ch1_fig3_penguin_manualtour.png")
```


## Research questions
<!-- Hypothesis statement -->

Discerning variable sensitivity to the structure is crucial to understanding which variables contribute to a feature being revealed. We conjecture that the user interaction afforded by the radial tour should allow for a more precise exploration of this structure by testing the variable sensitivity to that structure. The over-arching question of interest can, therefore, be stated as:

__Can the radial tour, with user-steering of the basis, help analysts understand the variable sensitivity of structure in the projection?__

While @cook_manual_1997 sketched the theoretical basis for the manual (and hence radial) tour, some details are missing. Furthermore, we lack a publicly available implementation, fully-featured interface design, implementation notes, and have no evaluation of its performance over alternatives.

RQ 1. __How do we define and implement a user interface and interactions for the radial tours to add and remove variables smoothly from a 2D linear data projection?__

<!-- Most perceptible way to visualize multivariate spaces -->
At present, the radial tour is not used by analysts. Instead, they would use a single projection to understand the structure, almost always the principal components analysis [PCA, @pearson_liii._1901], which chooses the basis that shows the most variation. Another approach is to use a _grand tour_ [@asimov_grand_1985]. The grand tour animates many interpolated frames between randomly selects target bases. Neither PCA nor the grand tour provides a means for manually manipulating a desired variable's contribution to the basis. We wish to investigate if the basis-steering of the radial tour facilitates a better understanding of variable sensitivity to the structure. 

RQ 2. __Does the use of the interactive radial tour improve analysts understanding of the relationship between variables and structure in 2D linear projections compared to existing approaches?__

<!-- Interpretability crisis of the nonlinear models -->
Complex nonlinear models are also being applied more frequently to predict or classify with many predictors. While these models lead to increased accuracy over linear models, they suffer from a loss of the interpretability of their variables. One aspect of eXplainable Artificial Intelligence [XAI, @adadi_peeking_2018; @arrieta_explainable_2020] tries to preserve the interpretability of such models through local explanations. These explanations are essentially linear variable importance in the vicinity of one observation of a model. That is, the extent that variables help the model explain the difference between the observed means and this observation's prediction. The user control from the radial tour potentially allows an analyst to better understand the model and the support of these local explanations.

RQ 3. __Can the radial tours be used in conjunction with local explanations to improve the interpretability of black-box models?__


## Methodology

The research corresponding to RQ 1 entails _algorithm & software design_ [@kleinberg_algorithm_2006] adapts the algorithm from @cook_manual_1997.

To address RQ 2, we use _experimental design_ [@winer_statistical_1962]. We must define a task and measure suitable to evaluate the radial tour against alternatives. The experimental factors and their levels must be selected and randomly assigned to explore the efficacy of user-controlled radial tours compared with two benchmark methods.

The research responding to RQ 3 involves _design science_ [@hevner_design_2004]. It is not obvious how to combine a radial tour with a nonlinear model. A local explanation approximates the linear variable importance in the vicinity of one observation. We must develop a novel interactive visualization that accommodates two aspects. First, it should visually facilitate the selection of observations to explore. Secondly, the biplot must be extended to show the distribution of the local explanations and examine the variable sensitivity to the structure identified in the local explanation with the radial tour.


## Contributions

The contributions resulting from the research to address these research questions can be split into scientific knowledge and software contributions: 


### Scientific knowledge

- Radial tour algorithm
    - Refined and clarified the steps to producing a radial tour based on the use of the Rodrigues' rotation formula extends the approach from @rodrigues_lois_1840.
    - The algorithm makes radial tour in the animation and
interactive systems simpler.
    - Provides new examples of usage.
- A user study comparing the radial tour's efficacy against two alternatives--PCA and the grand tour, the first empirical evaluation of the radial tour.
    - Creation of supervised classification task to assess the variable attribution to the separation of two clusters.
    - As tested over experimental factors: location, shape, and dimensionality.
    - Definition of an accuracy measure to evaluate this task.
    - Results: strong evidence that the radial tour increases the accuracy of this task by a sizable amount and minor evidence to suggest a moderate increase in accuracy of the grand tour over PCA.
    - Mixed model regression helps to attribution the source of the error accounting for the variability of participant's skills and the difficulty of the simulation by chance. 
- A novel interactive visualization using the radial tour to explore the variable sensitivity of local explanations from nonlinear models, part of XAI.
    - A global view approximates the variable space, attribution space, and model information side-by-side serves to identify a primary observation of interest.
    - This observation's normalized variable attribution is used as a projection basis.
    - Explore the support of the local explanation; using the radial tour, the variable sensitivity to the structure identified test the range of contributions supporting the explanation.


### Software

- __spinifex__, an __R__ package for transforming data, performing manual tours, and extend the display and animation exportation of any tour.
    - Facilitates the transformation of numeric variables in the data.
    - Identify various bases finding various features of the data.
    - Creation of manual tours allows analyst steering of the basis to explore the variable sensitivity to the structure.
    - Layered composition of tour displays that mirrors the approach in __ggplot2__ [@wickham_ggplot2_2016], interoperable with tours made from __tourr__ [@wickham_tourr:_2011].
    - Exporting rendered animation either to interactive `html` widgets with __plotly__ [@sievert_interactive_2020] or to `gif`, `mp4`, and other video formats with __gganimate__ [@pedersen_gganimate_2020].
    - Interactive __shiny__ [@chang_shiny_2021] application to preprocess data and explore. Users can choose from six supplied datasets or upload their own.
    - Vignettes and code examples help users get up to speed.
    - Introduces an interactive application to preprocess data and explore. Users can choose from six supplied datasets or upload their own.
- __cheem__, an __R__ package that facilitates the exploration of local explanations of nonlinear models through the use of the radial tour.
    - Preprocessing: given a tree-based model, calculate the tree SHAP local explanation [via __treeshap__, @kominsarczyk_treeshap_2021] of all observations, and find statistics to accent the separability of this space.
    - Visualization of approximations of the data space, attribution space, and model residual information side-by-side with linked brushing, hover tooltips, and tabular display facilitates the selection of observations to explore.
    - Use of the radial tour changes variable contribution to test the support of the variable contribution in agreement with the explanation.
    - Interactive application facilitates this analysis for several prepared datasets or user preprocessed data.
    - A vignette and code examples help users get up to speed.


## Thesis structure

The remainder of the thesis is organized as follows: Chapter \@ref(ch-background) covers various visualizing techniques before introducing related studies and nonlinear models and their interpretability issues. Chapter \@ref(ch-spinifex) discusses the theory and implementation of the radial tours in the package __spinifex__. Chapter \@ref(ch-userstudy) discusses a user study evaluating the radial tour's efficacy compared with PCA and the grand tour. Chapter \@ref(ch-cheem) discusses the __cheem__ package which extends the use of radial tours to improve the interpretability of nonlinear models. Lastly, Chapter \@ref(ch-conclusion) concludes with some takeaways and a discussion of limitations and possible extensions.

