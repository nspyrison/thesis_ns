---
output:
  pdf_document: default
  html_document: default
---
```{r include=FALSE}
knitr::opts_chunk$set(
  echo  = FALSE, 
  cache = FALSE,
  cache.lazy = FALSE,
  #out.width = "100%", ## this is % of page width, not % of figure size.
  out.extra = '', fig.show='hold', fig.align='center'
)
```

`r if (knitr::is_html_output()) '<!--'`

# Copyright notice {- #ch-copyright}

\textcopyright { }Nicholas Spyrison (\number\the\year).

I certify that I have made all reasonable efforts to secure copyright permissions for third-party content included in this thesis and have not knowingly added copyright content to my work without the owner's permission.

\newpage

`r if (knitr::is_html_output()) '-->'`

<!--chapter:end:00-a-copyright.Rmd-->

<!-- Short abstract for MGRO/Bridges: -->
<!-- currently 117 words, may need to be cut to 100 -->
<!--
As the dimensionality of data increases, so does the difficulty in their visualization. Traditional linear projections view discrete pairs of linear components. _Tours_ are a class of linear projections that animate over small changes to the projection. The _manual tour_ uniquely enables an analyst to steer a path of bases. This thesis discusses an __R__ package that facilitates their creation. A user study finds the manual tour outperforms traditional visualizations on a variable attribution task. Local explanations increase the interpretability of nonlinear models by approximating the variable importance at the vicinity of one observation. This work introduces a novel approach to explore the support of explanations with the radial tour. An accompanying package facilitates this analysis.
-->

# Abstract {-}

<!-- EDA, motivation, linear projections, tours -->
Visualizing data space is a crucial aspect of exploratory data analysis, checking assumptions, and validating model performance. However, visualization quickly becomes complex as the dimensionality of the data or features increases. Traditionally, linear projections have viewed discrete pairs of components to mitigate this complexity. Data visualization _tours_ are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis. The permanence of observations between nearby frames potentially conveys more information than discrete orthogonal frames alone.

<!-- manual tours and spinifex -->
Tours are categorized by the path of their bases. _Manual tours_ uniquely allow for user-controlled steering of a path of bases, where the contributions of individual variables can be changed. The _radial tour_ is a specific case of the manual tour, that freezes the angle of movement but allows the magnitude to be varied. This is used in the work reported here. Chapter \@ref(ch-spinifex) clarifies the theoretical basis of the radial tour. The details of implementation and illustration of its use are provided. It introduces an open-source __R__ package, that facilitates creating these tours with a variety of display choices and user controls. <!--An interactive application, vignettes, and example code illustrate the use of the radial tour.-->

<!-- user study -->
Allowing the analyst to steer a path in the radial tour should enable a better understanding of the variable importance to any structure revealed in a projection. Chapter \@ref(ch-userstudy) discusses a within-participant user study comparing the radial tour with current practices: principal component analysis (PCA) and the original type of tour that has no steering. The $n=108$ crowdsourced participants performed a variable attribution task describing the separation between clusters. The results find that the radial tour lead to more accurate variable attribution. Participants also reported that the radial tour was their preferred visualization method.

<!-- cheem -->
Nonlinear modeling techniques are sometimes referred to as black-box models due to the uninterpretable nature of the model terms. Recent research in Explainable Artificial Intelligence (XAI) tries to bring these models interpretability through _local explanations_. Local explanations are a class of techniques that approximate the linear-variable importance for prediction at one point in the data. Chapter \@ref(ch-cheem) provides a new approach for exploring the variable sensitivity of local explanations using radial tour. Local explanations can be considered projection bases. The radial tour is used to vary the contribution of an feature to assess the importance that feature for any particular prediction. This is illustrated using four contemporary data examples covering classification and regression. An accompanying __R__ package provides a graphical user interface (GUI) for conducting this analysis.

<!-- The following line is required to re-set page numbering after preliminary material. Do not remove -->
\clearpage\pagenumbering{arabic}\setcounter{page}{0}

<!--chapter:end:00-b-abstract.Rmd-->

`r if (knitr::is_html_output()) '<!--'` 

# Declaration {-}

I hereby declare that this thesis contains no material which has been accepted for the award of any other degree or diploma at any university or equivalent institution and that, to the best of my knowledge and belief, this thesis contains no material previously published or written by another person, except where due reference is made in the text of the thesis.


## Publication as part of this thesis {-}

The work corresponding to Chapter \@ref(ch-spinifex) has been accepted for publication in _The R Journal_ [@spyrison_spinifex_2020]. While respective studies discussed in Chapters \@ref(ch-userstudy) and \@ref(ch-cheem) have not yet been submitted.

I have renumbered and updated sections of the published paper to generate a consistent presentation within the thesis. The code illustrated has been adjusted to highlight the new ggproto API. Introductory and background content has been moved to their respective thesis chapters.
 

## Publications and papers during candidature not part of this thesis {-}

In addition to the research discussed in the thesis, other notable contributions during my candidature include:

- _The state-of-the-art on tours for dynamic visualization of high-dimensional data_ [@lee_state_2021]. A WIREs Computational Statistics Review of current tour methods. I contributed writing and visuals  discussing manual tours.
- _"Is IEEE VIS that good?" On key factors in the initial assessment of manuscript and venue quality_ [@spyrison_is_2021]. A survey IEEE VIS authors, how they source articles, decide which to read, and evaluate venue quality. We find low evidence that sentiment changes across academic positions for these topics and provide discussion on the effects of "publish or perish" environment, standard author and journal metrics, and difficulty in publishing "null" findings and replication studies.
- _Intraday effect of COVID-19 restrictions on Melbourne electricity consumption_ [@barrow_changes_2020]. We corroborate that the Victorian interday effect on energy consumption did not change but novelly find that the _intraday_ distribution of energy consumption does change. Namely, we find a statistically significant change in the height of the morning and evening peak energy consumption. We posit this is due to less strict schedules associated with working from home, absence of commute time, and other employment changes. We were awarded 1st place of hundreds of entries in the insights category of the Melbourne 2020 Datathon.
<!-- - Student volunteering at three conferences: UseR!2021 - Online, CHI Down Under 2020 - Online, and UseR!2018 - Brisbane, Australia. -->


\textbf{Student name:} Nicholas Spyrison

\textbf{Student signature:}

```{r, out.width = "33%", fig.align = "left"}
nsSafeIncGraphic("./figures/ch0_signature.PNG")
```

\textbf{Date:} `r as.Date("2021-12-12")`

`r if (knitr::is_html_output()) '-->'`

<!-- TRADITIONAL THESIS (NOT BY RESEARCH) DOES NOT INCLUDE THE BELOW IN DECLARATION -->
<!-- \vspace{2em} -->
<!-- \noindent -->
<!-- The undersigned hereby certify that the above declaration correctly reflects the nature and extent of the student's co-authors' contribution to this work. -->

<!-- \textbf{Main Supervisor name:} Kim Marriott -->

<!-- \textbf{Main Supervisor signature:} -->

<!-- \vspace*{2cm} -->

<!-- \textbf{Date:} `r as.Date("2021-12-12")` -->


<!--
All of the papers in the thesis were conceptualized, developed, and written by myself, the student, while working in the Department of Human-Centered Computing under the supervision of Professor Kimbal Marriott and Professor Dianne Cook. When co-authors are listed, it indicates that the work was produced through active collaboration between researchers and that their contributions to team-based research have been recognized. The following table details the work, including my and my fellow co-authors' contributions.

\begin{table}
\centering\footnotesize\tabcolsep=0.12cm
\begin{tabular}{|p{1cm}|p{2cm}|p{1.5cm}|p{3.5cm}|p{3.5cm}|p{1.5cm}|}
\hline
\RaggedRight\textbf{Thesis Chapter}  &
\RaggedRight\textbf{Publication Title}  &
\RaggedRight\textbf{Status (published, in press, accepted or returned for revision)}  & \RaggedRight\textbf{Nature and} {\%} \RaggedRight\textbf{of student contribution} & \RaggedRight\textbf{Co-author name(s) Nature and} {\%} \RaggedRight\textbf{of Co-author’s contribution} &
\RaggedRight\textbf{Co-author(s), Monash student Y/N} \\ \hline
3 & spinifex: an R package for creating
user-controlled animated linear projections & 75\%. Concept, development, writing first draft and software development & (1) Dianne Cook, concept, methodology, writing 25\% & N \\ \hline
4 & The benefit of user-controlled radial tour for understanding variable contributions to structure in linear projections & To be submitted & 80\%. Concept, development, writing first draft, application, and conducting user study & (1) Dianne Cook, Concept, methodology, editing 12\% (2) Kimbal Marriott, concept, methodology, editing 8\% & N \\ \hline
5 & Interrogating the linear variable importance of local explanations of nonlinear models with animated linear projections & To be submitted & 85\%. Concept, development, writing first draft and software development & (1) Dianne Cook, methodology, editing 10\% (2) Kimbal Marriott, methodology, editing 5\% & N \\ \hline
\end{tabular}
\end{table}
-->

<!--chapter:end:00-c-declaration.Rmd-->

# Acknowledgments {-}

<!-- Supervisors -->
I would like to express my sincere gratitude to my supervisors, Professor Dianne Cook and Professor Kimbal Marriott, for their support of my Ph.D studies and research, their subject expertise, and their careers of supervising and teaching in addition to performing research. Thank you for continuously pushing me and my research to new levels. I have enjoyed teaching data visualization, which has been strongly shaped by Di's practical, data-first, visualization-often approach. I will continue to hear Kim’s persistent question, “what do we learn from this?” as a reminder not to get lost in the details of implementation and regularly step back and analyze if this is the correct object to change. Thanks to the member of supervisory panel, Associate Professor Bernhard Jenny, Dr. Maxime Cordeil, and Dr. Shirui Pan for their time, engagement, and suggestions through the duration of this research.

<!-- PhD students, promodo, Ying -->
Special thanks to Jieyang Chong and Julie Holden for their proofreading and suggested language clarifications. I thank my fellow Ph.D students, NUMBAT and DVIA lab members, and Pomodoro partners, primarily on the occasion of stimulating discussions and the positive peer pressure of knowing others are around and working. Thanks immensely to those who empathized with me and others, especially through the hardships of studies and COVID-19. Gratitude to Ying Zhou for her enduring support through the thick of my studies and wavering mental health. 

<!-- Family -->
Last but not least, I would like to thank my parents, Doug and Terry, for their continued support and airing my grievances at odd hours of the day. Thanks to Alan and Claire for their companionship and support now and in our more formative years.

<!-- Scholarship required shoutout -->
This research was supported in part by an Australian Government Research Training Program (RTP) Scholarship.

<!--chapter:end:00-d-acknowldge.Rmd-->

# Preface {-}

This thesis has been written using R Markdown with the bookdown package [@xie_bookdown:_2016]. All materials required to compile the thesis are available at [github.com/nspyrison/thesis_monash_phd](https://github.com/nspyrison/thesis_monash_phd). Versions are made available as `html` and `pdf` at [nspyrison.github.io/thesis_ns/](https://nspyrison.github.io/thesis_ns/) and [github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf](https://github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf), respectively.
<!-- The renv package has been used to create a reproducible environment to build the thesis from source (Ushey, 2019). -->



<!--chapter:end:00-e-preface.Rmd-->

---
chapter: 1
knit: "bookdown::render_book"
---

# Introduction {#ch-introduction}

<!-- Exploratory data analysis -->
Exploratory Data Analysis (EDA) is the process of the initial summarization and visualization of a dataset. EDA is a critical first step of checking for realistic values, identifying improper data formats, and revealing insights [@tukey_exploratory_1977]. @wickham_r_2017 describe the analyst workflow into a series of discrete steps. The data is imported and cleaned before entering into an iterated cycle of transformation, visualization, and modeling. This work focuses the visualization step, specifically for quantitative multivariate data. The implementation of packages also facilitates transformation and modeling while these aspects are not the primary contributions.

<!-- (ref:ch1fig1-cap) Data analysis workflow [@wickham_r_2017]. This work focuses primarily on visualization of multivariate data. -->
<!-- ```{r ch1fig1, echo=F, out.width="100%", fig.cap = "(ref:ch1fig1-cap)"} -->
<!-- nsSafeIncGraphic("./figures/ch1_fig1_data_analysis_workflow.PNG") -->
<!-- ``` -->

<!-- Dimensionality increases, making data viz hard -->
Multivariate data has become ubiquitous in contemporary data sets. Multivariate data is found in physics, biology, social sciences, and manufacturing  to name a few [@wang_mapping_2018; @huber_orchestrating_2015; @brown_confirmatory_2015; @evans_multivariate_2017]. As the number of variables in the data increases, it becomes increasingly difficult to visualize this space and reveal the structure of the data. This thesis addresses the visualization and analysis of multivariate data.

<!-- Shadow analogy segue to linear proj. -->
One of the most common and successful approaches to visualize multivariate data is to use linear projection, which approximates $p$-dimensional data onto 1-3 display dimensions. In the same way that 3D object casts a 2D shadow, these projections cast one orientation of the data onto a lower plane.

<!-- Linear projections -->
Linear projections defines new variables called components, essentially a linear combination, orientation of the original variables. A basis is the orthonormal matrix that maps the variable to the component output space. The basis of a linear projections is frequently illustrated with a biplot [@gabriel_biplot_1971]. The biplot shows the magnitude and angle each variable contributes to the resulting display dimensions inscribed in a unit circle, such as in Figure \@ref(fig:ch1fig2). Traditional axes-based visuals look at 1-3D scatterplots of orthogonal variables. In contrast by viewing linear combinations of these variables on the axes can reveal features that exist in more than three dimension. 

(ref:ch1fig2-cap) Two linear projections of penguins data. Biplot circles depict the basis, the direction and magnitudes of the contributions of the variables. In the left frame, the direction of separation of the orange cluster is mainly in the direction that `bl` contributes, meaning that the variable is sensitive to the separation of this cluster. The purple cluster's separation is attributed primarily to `bd` and `fl` and `bm` to a smaller extent. Many other linear orientations do not resolve structures of interest, such as cluster separation (right frame). The Palmer Penguin data [@gorman_ecological_2014; @horst_palmerpenguins_2020] measures four physical variables: bill length (`bl`), bill depth (`bd`), flipper length (`fl`), and body mass (`bm`) for three species of penguins.
```{r ch1fig2, echo=F, out.width="100%", fig.cap = "(ref:ch1fig2-cap)"}
nsSafeIncGraphic("./figures/ch1_fig2_penguin_cl_sep.png")
```

<!-- Talk about features, structure and sensitivity -->
There are many features that an analyst may be interested in when analyzing multivariate data. Shape, spread, identifying clusters, outliers, and irregularities are the most common. Not all of the basis orientations of a data will reveal the features the data. Thus the choice of projection is important. Furthermore, the analyst is interested in understanding which combination of variables indicate the feature. For instance, Figure \@ref(fig:ch1fig2) shows two linear projections of penguin data. The color and shape of the data points distinguish the three penguin species. The linear projection used in the left frame contains a significant separation of the clusters, while the right frame does not show a discern differences in the species clusters.

<!-- Tours, animated linear projections -->
Therefore, it makes sense for an analyst to explore many projections with very different bases. However, it can be difficult to link observations across different projections with no relationship to one another. The _tour_ is a dynamic visualization that overcomes this difficulty [@cook_grand_2008; @lee_state_2021]. It is a class of linear projections that animate over small changes to the projection basis. A key feature of the tour is the visual permanence and trackability of the points through the frames. In the shadow analogy, an object such as a barstool will cast a circular shadow if the light is directly above the seat. However, such a shadow does not give the observer sufficient information as it could arise from any number of shapes that contain circular profiles: spheres, cylinders, or circles. However, if the stool was rotated, its legs would show in the shadow quickly giving an intuitive interpretation of the object. Similarly, the rotation of a data object yields information about its structure.

<!-- Manual tour -->
Originally  component spaces and the original tour have no means to influence the basis or its path. @cook_manual_1997 introduced the _manual tour_, offering user control over the basis. By selecting a variable and initializing an additional manipulation dimension to a projection, the contribution of the variable can be controlled through a rotation of the manipulation space. This user-controlled steering of the basis path enables the analyst to explore what happens to the structure when one variable is removed or the contribution of another is increased. 

<!-- Radial tour -->
The manual tour allows the analyst to control the angle and magnitude that a variable contributes to the projection. However, controlling the magnitude is generally more meaningful as angular manipulations effectively rotate the projection, changing the relative position but not the contributions of a variables. Because of this, this work focuses on a specific manual tour, the _radial tour_, where the angle of the manipulated variable is fixed, but the analyst can vary its magnitude, changing its radius. Figure \@ref(fig:ch1fig3) shows a radial tour of the penguins data varying the contribution of bill length. The left frame has a full contribution from `bl`, middle frames contains about half contribution while bill length has been removed in the the right frame. The separation between orange and green clusters was in the direction that `bl` contributed and when this contribution is removed so to is the separation of the clusters; we say this variable is sensitive to the separation of these two clusters.

(ref:ch1fig3-cap) A radial tour changing the contribution of bill length (`bl`). When bill length has a considerable contribution, the clusters of orange and green are separated (left and middle). When its contribution is removed, the clusters overlap (right). Because of this, we say that bill length is sensitive to the separation of these two species. An animated version can be viewed at [vimeo.com/676723431](https://vimeo.com/676723431).
```{r ch1fig3, echo=F, out.width="100%", fig.cap = "(ref:ch1fig3-cap)"}
nsSafeIncGraphic("./figures/ch1_fig3_penguin_manualtour.png")
```


## Research questions
<!-- Hypothesis statement -->

Discerning variable sensitivity to the structure is crucial to understanding which variables contribute to a feature being revealed. We conjecture that the user interaction afforded by the radial tour should allow for a more precise exploration of this structure by testing the variable sensitivity to that structure. The over-arching question of interest can, therefore, be stated as:

__Can the radial tour, with user-steering of the basis, help analysts understand the variable sensitivity of structure in the projection?__

While @cook_manual_1997 sketched the theoretical basis for the manual (and hence radial) tour, some details are missing. Furthermore, we lack a publicly available implementation, fully-featured interface design, implementation notes, and have no evaluation of its performance over alternatives.

RQ 1. __How do we define and implement a user interface and interactions for the radial tours to add and remove variables smoothly from a 2D linear data projection?__

<!-- Most perceptible way to visualize multivariate spaces -->
At present, the radial tour is not used by analysts. Instead, they would use a single projection to understand the structure, almost always the principal components analysis [PCA, @pearson_liii._1901], which chooses the basis that shows the most variation. Another approach is to use a _grand tour_ [@asimov_grand_1985]. The grand tour animates many interpolated frames between randomly selects target bases. Neither PCA nor the grand tour provides a means for manually manipulating a desired variable's contribution to the basis. We wish to investigate if the basis-steering of the radial tour facilitates a better understanding of variable sensitivity to the structure. 

RQ 2. __Does the use of the interactive radial tour improve analysts understanding of the relationship between variables and structure in 2D linear projections compared to existing approaches?__

<!-- Interpretability crisis of the nonlinear models -->
Complex nonlinear models are also being applied more frequently to predict or classify with many predictors. While these models lead to increased accuracy over linear models, they suffer from a loss of the interpretability of their variables. One aspect of eXplainable Artificial Intelligence [XAI, @adadi_peeking_2018; @arrieta_explainable_2020] tries to preserve the interpretability of such models through local explanations. These explanations are essentially linear variable importance in the vicinity of one observation of a model. That is, the extent that variables help the model explain the difference between the observed means and this observation's prediction. The user control from the radial tour potentially allows an analyst to better understand the model and the support of these local explanations.

RQ 3. __Can the radial tours be used in conjunction with local explanations to improve the interpretability of black-box models?__


## Methodology

The research corresponding to RQ 1 entails _algorithm & software design_ [@kleinberg_algorithm_2006] adapts the algorithm from @cook_manual_1997.

To address RQ 2, we use  _experimental design_ [@winer_statistical_1962]. We must define a task and measure suitable to evaluate the radial tour against alternatives. The experimental factors and their levels must be selected and randomly assigned to explore the efficacy of user-controlled radial tours compared with two benchmark methods.

The research responding to RQ 3 involves _design science_ [@hevner_design_2004]. It is not obvious how to combine a radial tour with a nonlinear model. A local explanation approximates the linear variable importance in the vicinity of one observation. We must develop a novel interactive visualization that accommodates two aspects. First, it should visually facilitate the selection of observations to explore. Secondly, the biplot must be extended to show the distribution of the local explanations and examine the variable sensitivity to the structure identified in the local explanation with the radial tour.


## Contributions

The contributions resulting from the research to address these research questions can be split into scientific knowledge and software contributions: 


### Scientific knowledge

- Radial tour algorithm
    - Refined and clarified the steps to producing a radial tour based on the use of the Rodrigues' rotation formula extends the approach from @rodrigues_lois_1840.
    - The algorithm makes radial tour in the animation and
interactive systems simpler.
    - Provides new examples of usage.
- A user study comparing the radial tour's efficacy against two alternatives--PCA and the grand tour, the first empirical evaluation of the radial tour.
    - Creation of supervised classification task to assess the variable attribution to the separation of two clusters.
    - As tested over experimental factors: location, shape, and dimensionality.
    - Definition of an accuracy measure to evaluate this task.
    - Results: strong evidence that the radial tour increases the accuracy of this task by a sizable amount and minor evidence to suggest a moderate increase in accuracy of the grand tour over PCA.
    - Mixed model regression helps to attribution the source of the error accounting for the variability of participant's skills and the difficulty of the simulation by chance. 
- A novel interactive visualization using the radial tour to explore the variable sensitivity of local explanations from nonlinear models, part of XAI.
    - A global view approximates the variable space, attribution space, and model information side-by-side serves to identify a primary observation of interest.
    - This observation's normalized variable attribution is used as a projection basis.
    - Explore the support of the local explanation; using the radial tour, the variable sensitivity to the structure identified test the range of contributions supporting the explanation.


### Software

- __spinifex__, an __R__ package for transforming data, performing manual tours, and extend the display and animation exportation of any tour.
    - Facilitates the transformation of numeric variables in the data.
    - Identify various bases finding various features of the data.
    - Creation of manual tours allows analyst steering of the basis to explore the variable sensitivity to the structure.
    - Layered composition of tour displays that mirrors the approach in __ggplot2__ [@wickham_ggplot2_2016], interoperable with tours made from __tourr__ [@wickham_tourr:_2011].
    - Exporting rendered animation either to interactive `html` widgets with __plotly__ [@sievert_interactive_2020] or to `gif`, `mp4`, and other video formats with __gganimate__ [@pedersen_gganimate_2020].
    - Interactive __shiny__ [@chang_shiny_2021] application to preprocess data and explore. Users can choose from six supplied datasets or upload their own.
    - Vignettes and code examples help users get up to speed.
    - Introduces an interactive application to preprocess data and explore. Users can choose from six supplied datasets or upload their own.
- __cheem__, an __R__ package that facilitates the exploration of local explanations of nonlinear models through the use of the radial tour.
    - Preprocessing: given a tree-based model, calculate the tree SHAP local explanation [via __treeshap__, @kominsarczyk_treeshap_2021] of all observations, and find statistics to accent the separability of this space.
    - Visualization of approximations of the data space, attribution space, and model residual information side-by-side with linked brushing, hover tooltips, and tabular display facilitates the selection of observations to explore.
    - Use of the radial tour changes variable contribution to test the support of the variable contribution in agreement with the explanation.
    - Interactive application facilitates this analysis for several prepared datasets or user preprocessed data.
    - A vignette and code examples help users get up to speed.


## Thesis structure

The remainder of the thesis is organized as follows: Chapter \@ref(ch-background) covers various visualizing techniques before introducing related studies and nonlinear models and their interpretability issues. Chapter \@ref(ch-spinifex) discusses the theory and implementation of the radial tours in the package __spinifex__. Chapter \@ref(ch-userstudy) discusses a user study evaluating the radial tour's efficacy compared with PCA and the grand tour. Chapter \@ref(ch-cheem) discusses the __cheem__ package which extends the use of radial tours to improve the interpretability of nonlinear models. Lastly, Chapter \@ref(ch-conclusion) concludes with some takeaways and a discussion of limitations and possible extensions.


<!--chapter:end:01-introduction.Rmd-->

---
chapter: 2
knit: "bookdown::render_book"
---


# Background {#ch-background}

<!-- Structure -->
In the last chapter, we discussed the importance of data visualization despite the complexity of viewing high-dimensional data and outlined the research questions we wish to address with the user-control of the radial tour. This chapter first motivates data visualization in general and the importance of interaction. Then we cover common visualizations for quantitative multivariate data before turning to dimension reduction. We cover linear dimension reduction, including further discussion of tours. Then we discuss empirical evaluations of multivariate visuals. Lastly, this chapter concludes with nonlinear models and extends their interpretation with local explanations.


## Motivation

<!-- Better than numerical summarization alone -->
Visualization is much more robust than numerical summarization alone [@anscombe_graphs_1973; @matejka_same_2017]. Figure \@ref(fig:ch2fig1) illustrates this. The data sets have a quite different structure revealed in the visualization but not in the summary statistics, as all data sets have the same means, standard deviations, and correlation.

(ref:ch2fig1-cap) The datasaurus dozen is a modern data set illustrating Anscombe's point that summary statistics cannot always adequately summarize the content of data. The data patterns shown in the scatterplots have the same summary statistics. Unless the data is plotted, one would never know that there were such radical differences.
```{r ch2fig1, echo=F, out.width="100%", fig.cap = "(ref:ch2fig1-cap)"}
nsSafeIncGraphic("./figures/ch2_fig1_datasaurus.png")
```

<!-- Data interaction -->
Interaction is known to be an essential aspect of modern data visualization [@batch_there_2019; @card_psychology_1983; @marriott_immersive_2018]. Interaction facilitates accessing increasing amounts of data and amplifies cognition through control and input [@dimara_what_2019].<!--The term interaction covers a broad range of uses, purposes, and contexts, making it overburdened and potentially ambiguous.--> @munzner_visualization_2014 posits that responsive and fast computer graphics allow us to move beyond paper and static resources. Interaction is key to navigating within views of sizable data and also to link observations and features across these views. 

<!-- Multivariate data vis interaction -->
Here we focus on  multivariate data interactions with coordinated view, linked brushing, and tooltip display. Coordinated and multiple views [@roberts_state_2007] [also known as ensemble graphics, @unwin_ensemble_2018] use several types of visuals that give a more comprehensive understanding than any one visual portrays in isolation. Linking observations between different views and animation frames is facilitated by linked brushing [@becker_brushing_1987]. Linked brushing colors selected observations in one view allowing these selections to be tracked and correlated across other views and frames. Linked brushing has proved to be helpful in animated tours [@arms_benefits_1999; @laa_slice_2020; @lee_casting_2020]. Tooltips display observation ID upon the cursor hovering over observations can also aid identification and display associated values. Interactive selection of parameters extends the breadth of an analysis, and animation interactions such as play, pause, and frame selection are regularly used.


## Multivariate visualization

<!-- Data scope and context -->
In this thesis, we are concerned with the visualization of multivariate data. Specifically, we are interested in quantitative multivariate data. We assume that our data consists of $n$ observations of $p$ variables. Generally $n>p$ with many more observations than variables. While written as though operating on the original variables, the visualizations discussed below could also be applied to reduced component spaces (such as PCA approximation in a few components) or feature decomposition of data not fitting this format. @kang_visualising_2017 provide a good example of decomposing time series data in a quantitative feature matrix.

<!-- Penguins data -->
@grinstein_high-dimensional_2002 illustrate many multivariate visualization methods. In particular, it shows examples of the actual visualizations. @liu_visualizing_2017 give a good classification and taxonomy. Here we focus on the most common and the most relevant visuals. We illustrate these with the Palmer penguins data that was used in the Introduction. This data contains 333 observations of three penguin species across four physical measurements: bill length, bill depth, flipper length, and body mass. Observations were collected between 2007 and 2009 near Palmer Station, Antarctica. This is a good substitute for the over-used iris data.


### Scatterplot matrices

<!-- SPLOM -->
An analyst could look at $p$-univariate histograms or density curves. Extending this idea, pairs of variables can be exhaustively viewed. Combining these brings us to scatterplot matrices, also known as SPLOM [@chambers_graphical_1983]. In a scatterplot matrix, variables are arranged across the columns and rows. The diagonal elements show univariate densities, while off-diagonal positions show scatterplot pairs, as in Figure \@ref(fig:penguinsplom). This is useful for getting a handle on the range of the variables but is not going to scale well when the number of variables $p$ is large. Such visualization will only partially resolve features that could be better show information from more dimensions.

(ref:penguinsplom-cap) A scatterplot matrix shows univariate densities and all pairs of bivariate scatterplots. The panels show partial cluster separation indicating these variables contain some cluster discerning information. This approach is suitable for quickly exploring the range of the data but will not reveal features in more than two dimensions. It is a good exploratory visual but does not scale well with an increasing number of variables.
```{r penguinsplom, echo=F, out.width="100%", fig.cap = "(ref:penguinsplom-cap)"}
nsSafeIncGraphic("./figures/ch2_fig2_penguin_splom.pdf")
```

<!-- scaling with n -->
As $n$ increases, scatterplot displays also suffer from occlusion as the points overlay each other. This is typically addressed in a few ways. One method is to decrease points' opacity, allowing more layers to be seen. Another approach is to change the geometric display to 2D density contours or an aggregated heatmap (illustrated in Figure \@ref(fig:ch2fig5)). These aggregations typically render faster and scale better with increasing observations. Or, if needed, visualization can be performed on a representative subset of the data.


### Parallel coordinate plots

<!-- PCP -->
In scatterplot matrices, each observation is spread across all panels. In contrast, observation-linked visuals have a single line or glyph for each observation. In parallel coordinate plots [@ocagne_coordonnees_1885], variables are arranged horizontally, and lines connect observations after being transformed to a common scale such as quantiles or z-value (standard deviations away from the mean). Figure \@ref(fig:penguinpcp) illustrates this method. Parallel coordinate plots scale much better with dimensions than scatterplot matrices but more poorly with observations. They  also suffer from an asymmetry with the variable order. That is, changing the order of the variables may lead to very different conclusions. The x-axis is also used to display variables rather than the values of the observations. This restricts the amount of information that can be interpreted between variables. @munzner_visualization_2014 asserts that position is the more human-perceptible channel for encoding information; we should prefer to reserve it for the values of the observations rather than distinguishing variables.

(ref:penguinpcp-cap) Parallel coordinate plots put variables on a common scale and position them side-by-side with lines connecting observations. Some variation between the clusters can be seen corroborating their importance to explaining cluster separation. This approach scales relatively well with the number of variables but poorly with the number of observations.
```{r penguinpcp, echo=F, out.width="100%", fig.cap = "(ref:penguinpcp-cap)"}
nsSafeIncGraphic("./figures/ch2_fig3_penguin_pcp.pdf")
```

<!-- Observation based visuals and scaling -->
The same issues persist across other displays that map observations into $n$ glyph or heatmaps. Examples of these include star plots [@chambers_graphical_1983], pixel-based visuals [@keim_designing_2000], and Chernoff faces [@chernoff_use_1973]. Like parallel coordinate plots, these other visuals scale quite poorly with increasing observations. However, because these visuals scale well with the number of variables they maybe candidate visualizations for low $n$, high $p$ data.


### Dimension reduction

<!-- Dimension reduction, linear and nonlinear -->
The other main approach for visualizing quantitative multivariate data is to use dimension reduction. This involves a function mapping $p$-spaces onto a lower $d$-dimensional space. Dimension reduction is separated into two categories, linear and nonlinear. The linear case spans all affine mathematical transformations, essentially any function where parallel lines stay parallel. Nonlinear transformations complement the linear case, think transformations containing exponents or interacting terms.

<!-- linear and nonlinear examples -->
Examples in low dimensions are relatable. For instance, shadows are linear projections of a 3-dimensional object down to the 2D shadow. Linear perspective drawings are another instance. An example of a nonlinear transformation is that of 2D maps of the globe. A common example is the Mercator projection, a rectangular display where the area is proportionally distorted with the distance away from the equator [@snyder_map_1987]. Other distortions are created when the surface is unwrapped into an elongated ellipse. Yet others create non-continuous gaps on land or oceans to minimize the distortion of targeted areas. Snyder lists over 200 different projections that distort the surface to display as a map, each with unique properties distorting the 3D surface. However, despite familiarity with map projections, users find it difficult to understand the distortions they introduce [@hennerdal_beyond_2015].

<!-- Nonlinear hyperparameters -->
As illustrated by map projections, nonlinear projections can be difficult to understand. Various computational quality metrics, such as Trustworthiness, Continuity, Normalized stress, and Average local error, have been introduced to describe the distortion of the space [@espadoto_toward_2021; @gracia_new_2016; @van_der_maaten_dimensionality_2009; @venna_visualizing_2006]. To quote @panagiotelis_manifold_2020, "All nonlinear projections are wrong, but some are useful", a play on George Box's quote about models ["All _models_ are wrong, but some are useful", @box_science_1976]. The distortions are hard to interpret and, thus, hard to communicate.

<!-- Dealing with hyper parameters & Sticking with linear approaches -->
Furthermore, nonlinear projections have hyperparameters (these are absent from linear methods) that control how the spaces are distorted to fit into fewer dimensions. These introduce a degree of subjectivity into the resulting projection. Opinions differ on how to best deal with hyperparameters. @probst_hyperparameters_2019 discusses tuning strategies. Others compare implementation defaults [@gijsbers_meta_2021; @pfisterer_learning_2021]. @probst_tunability_2019 look at the sensitivity of hyperparameters to the performance of a model. Automated machine learning takes a programmatic approach to hyperparameter tuning [@feurer_efficient_2015; @hutter_automated_2019; @yao_taking_2019]. Due to the difficulty of interpreting nonlinear mappings and the added subjectivity of hyperparameter selection, this thesis focuses on linear visualization techniques.


### Intrinsic data dimensionality

<!-- Up to here with Kim. -->

<!-- Intrinsic data dimensionality -->
One way dimension reduction is used is to project multivariate data onto 1-, 2-, or 3D space and visualize the results. However, it can also be used as a preprocessing step for any sort of analysis. The intrinsic dimensionality of data is the number of variables needed to minimally represent the data [@grinstein_high-dimensional_2002]. Intrinsic data dimensionality is an essential consideration of dimension reduction. Consider a Psychology survey consisting of 100 questions about the Big Five personality traits. The data consists of 100 response variables, while the theory would suggest the intrinsic dimensionality is five. Reducing the disparity of these volumes would be necessary to gate the exponentially increasing space to view. Nonlinear techniques regularly perform an implicit PCA initialization step that may default to keeping several dozen components to mitigate run time of data with hundreds or thousands of variables.


## Linear projections

Linear projections map a higher $p$-dimensional space onto a smaller $d$-space with an affine mapping (where parallel lines stay parallel). A projection is the resulting space of the data multiplied by a basis $Y_{n \times d} = X_{n \times p} \cdot A_{p \times d}$. This basis is an orthonormal matrix that explains the orientation and magnitudes that variables contribute to the resulting space. This basis is often illustrated as a biplot [@gabriel_biplot_1971], where variable contributions are inscribed in a unit circle showing the direction and the magnitude of contribution as illustrated in the previous chapter.


<!-- PCA -->
A common linear projection is principal component analysis [PCA, @pearson_liii._1901], which creates a component space ordered by descending variation. It uses eigenvalue decomposition to identify the basis. These components are typically viewed as discrete orthogonal pairs, commonly approximated as several components. The exact number of components to keep is subjective but typically guided by a screeplot [@cattell_scree_1966]. Scree plots illustrate the decreasing variation contained in subsequent components. The analyst then identifies an elbow in this plot. PCA is also commonly used in preprocessing and model initialization when there are many more variables than the intrinsic data dimensionality, such as the Big Five personality example. These reduced component spaces can be used in visualization, albeit with the added abstraction of another linear mapping to get back to the original variables.


### Tours, animated linear projections {#sec:tour}

<!-- Segue from barstool -->
In one static linear projection, one basis uniquely maps the projection. In contrast to a single projection, a data visualization tour animates many such projections over small changes in the basis. In the shadow analogy, structural information of an object is gained by watching its shadow change due to its rotation. An analyst similarly gains structural information by watching continuous changes to the basis (the orientation of the data). There are various types of tours that are classified by the generation of their basis paths. We enumerate a few related to this work. A more comprehensive discussion and review of tours can be found in the works of @cook_grand_2008 and @lee_state_2021.

<!-- Interpolation frames -->
Regardless of the type of tour target basis identified, tours must interpolate frames between distant generated target bases. This interpolation is performed along a geodesic path between the bases. Geodesic refers to the shortest path (on a $p$-sphere of possible bases). This ends up being slightly curved in 2D representation in the same way that flight paths appear curved on 2D representations of the globe. The interpolation of frames at small enough angles is foundational for the trackability of observations between frames.

<!-- Grand tour -->
Originally in a _grand_ tour [@asimov_grand_1985], several target frames are randomly selected. Figure \@ref(fig:ch2fig4) illustrates six frames from a grand tour. The grand tour is good for EDA in that it will show frames with widely varying contributions but lacks a destination, objective function, or means of steering.

(ref:ch2fig4-cap) Frames from a grand tour. Biplots (grey circles) illustrate the direction and magnitude that variables contribute. In the grand tour, target bases are selected randomly. Tours animate linear projections over small changes in the basis. The observation permanence between frames is an essential distinction in tours. An animation can be viewed at [vimeo.com/676723441](https://vimeo.com/676723441).
```{r ch2fig4, echo=F, out.width="100%", fig.cap = "(ref:ch2fig4-cap)"}
nsSafeIncGraphic("./figures/ch2_fig4_penguin_grandtour.png")
```

<!-- manual tour -->
The grand tour has no input over the bases selected. In contrast, the _manual tour_ [@cook_manual_1997] allows the analyst to change the contribution of a selected variable. It does so by initializing a manipulation dimension on a 1- or 2D projection which can then be rotated to alter the contribution of a selected variable. This work focuses on the _radial tour_ sub-variant, where the contribution angle is fixed, and the magnitude of contribution along the radius is controlled. Figure \@ref(fig:ch2fig5) illustrates the same radial tour shown in the previous chapter across three geometric displays. The use of density contours and aggregated heatmap displays help to mitigate the occlusion of dense observations and is compatible with any scatterplot display.

(ref:ch2fig5-cap) Radial tour across three geometric displays. The contribution of `bl` is removed from the frame and with it the separation between the orange and green clusters is also removed. Changing to density contours or hexagonal heatmap displays are common ways to mitigate occlusion caused by dense observations. Heatmap display is not the best choice to show supervised cluster separation but can be helpful to see structure in dense data.
```{r ch2fig5, echo=F, out.width="100%", fig.cap = "(ref:ch2fig5-cap)"}
nsSafeIncGraphic("./figures/ch2_fig5_penguin_manualtour_geoms.pdf")
```


## Evaluating multivariate data visualization

<!-- Examples, surveys, and evaluations -->
@grinstein_high-dimensional_2002 provide collected illustrations from many visualization methods. While @liu_visualizing_2017 provide a good classification of visualization techniques. Definitions and surveys of quality metrics are given in @bertini_quality_2011. The latest, most comprehensive empirical evaluations are discussed in @espadoto_toward_2021 and @nonato_multidimensional_2018. While the former papers include a discussion of tours, they are absent from empirical evaluations.

<!-- 2D vs D3, mostly PCA reduced -->
@gracia_new_2016 conducted an $n=40$ user study comparing between 2D and 3D scatterplots on traditional 2D monitors. Participants perform point classification, distance perception, and outlier identification tasks. The results are mixed and primarily have small differences. There is some evidence to suggest a lower error in distance perception from a 3D scatterplot. @wagner_filho_immersive_2018 performed an $n=30$ within participants using scatterplot display between 2D, 3D displays on monitors and 3D display with a head-mounted display on PCA reduced spaces. None of the tasks on any dataset lead to a significant difference in accuracy. However, the immersive display reduced effort and navigation, resulting in higher perceived accuracy and engagement. @sedlmair_empirical_2013 instead use two expert coders to evaluate 75 datasets and four dimension reduction techniques for 2D scatterplots, interactive 3D scatterplots, and 2D scatterplot matrices. They suggest a tiered guidance approach finding that 2D scatterplots are often "good enough" to resolve a feature. If not, try with an alternative dimension reduction technique before going to scatterplot matrix display or concluding a true negative. They find that interactive 3D scatterplots help in relatively rare cases.

<!-- Nonlinear DR quality review -->
Tours are absent from empirical studies. However, @nelson_xgobi_1999 compare scatterplots of grand tours on a 2D monitor with 3D (stereoscopic, not head-mounted) over $n=15$ participants. Participants perform clusters detection, dimensionality, and radial sparseness tasks on six-dimensional data. They find that stereoscopic 3D leads to more accuracy for cluster identification, though interaction time much increased in the 3D case.


## Nonlinear models 

Nonlinear models have many or complex interactive terms, which cause an opacity to the interpretation of the variables. This loss of the interpretability of variables in nonlinear models sometimes leads to them being referred to as black-box models.

<!-- Introduce explanatory vs predictive modeling -->
There are different reasons and emphases when considering to fit a model. @breiman_statistical_2001, reiterated by @shmueli_explain_2010, taxonomize models based on their purpose; _explanatory_ modeling is done for some inferential purpose, while _predictive_ modeling focuses more narrowly on the performance of some objective function. The intended use has important implications for model selection and development. In explanatory modeling, interpretability is vital for drawing inferential conclusions. While black-box models are preferred in predictive modeling. However, the use and prevalence of nonlinear models is not without controversy [@oneil_weapons_2016; @kodiyan_overview_2019]. And the loss of interpretation presents a challenge.

<!-- Interpretability & baises -->
Interpretability is vital for exploring and protecting against potential biases (e.g., sex  -- @dastin_amazon_2018; @duffy_apple_2019, race -- @larson_how_2016, and age  -- @diaz_addressing_2018) in any model. For instance, models regularly pick up on biases in the training data where protected classes correlate with the response feature. This bias is then built into the model. Variable-level (feature-level) interpretability of models is essential in evaluating such biases.

<!-- Interpretability & data drift -->
Another concern is data drift, where a shift in the range of the explanatory variables (features or predictors). Some nonlinear models are sensitive to this and do not extrapolate well outside the support of the training data. Maintaining variable interpretability is also essential to address issues arising from data drift.


## Local explanations {#sec:explanations}

<!-- Local explanations -->
Explainable Artificial Intelligence (XAI) is an emerging field of research that tries to increase the interpretability of black-box models. A common approach is _local explanations_, which attempt to approximate linear variable importance in the vicinity of one observation (instance). This is a linear measure indicating which variables are important for distinguishing between the mean of the data and the prediction near one observation. Because these are point-specific, the challenge is to comprehensively visualize them to understand a model.

<!-- Reminder of local explanation -->
Consider a highly nonlinear model. It can be hard to determine which variables in the data will lead to a different classification or changes in its residual. Local explanations shed light on these situations by approximating linear variable importance in the vicinity of a single observation. Figure \@ref(fig:ch2fig6) motivates local explanations where the analyst wants to know the variable attribution for a particular observation close to the classification boundary in a nonlinear model.

(ref:ch2fig6-cap) Illustration of a nonlinear classification model. An analyst may want to know the variable importance at the vicinity of the highlighted red cross. Understanding this attribution elucidates how the variable influence this point that is precariously close to the classification boundary. Local explanations approximate this linear attribution in the vicinity of one observation. Figure from @ribeiro_why_2016.
```{r ch2fig6, echo=F, out.width="50%", fig.cap = "(ref:ch2fig6-cap)"}
nsSafeIncGraphic("./figures/ch2_fig6_ribeiro16fig.PNG")
```

<!-- Taxonomy of local explanations -->
A comprehensive summary of the taxonomy and literature of explanation techniques is provided in Figure 6 of @arrieta_explainable_2020. It includes a large number of model-specific explanations such as deepLIFT [@shrikumar_not_2016; @shrikumar_learning_2017], a popular recursive method for estimating importance in neural networks. There are fewer model-agnostic explanations, of which LIME, [@ribeiro_why_2016] SHAP, [@lundberg_unified_2017], and their variants are popular.

<!-- Uses of local explanations -->
These observation-level explanations are used in various ways depending on the context. In image classification, a saliency map indicate important pixels for the resulting classification [@simonyan_deep_2014]. For example, snow is regularly highlighted when distinguishing if a picture contains a wolf or husky [@besse_can_2019]. In text analysis, word-level contextual sentiment analysis can be used to highlight the sentiment and magnitude of influential words [@vanni_textual_2018]. In the case of numeric regression, they are used to explain variable additive contributions from the observed mean to the observation's prediction [@ribeiro_why_2016].


## Conclusion

<!-- Motivation -->
We have discussed the motivation for data visualization and the importance of user interaction. We discussed several visuals before turning to linear dimension reduction. Empirical evaluations, black-box models, and their local explanations were discussed. There is an absence of studies comparing animated tours with alternative visualization. XAI and extending the interpretability of black-box models are sought-after.

The following chapters respectively address the three research questions covered in the Introduction. Chapter \@ref(ch-spinifex) discusses the implementation of a package that facilitates the creation of radial tours and extends the display and exporting of tours in general. Chapter \@ref(ch-userstudy) covers the first user study evaluating the radial tour compared with two common alternatives. Chapter \@ref(ch-cheem), introduces a novel analysis that explores local explanations of nonlinear models with the radial tour.


<!--chapter:end:02-background.rmd-->

---
chapter: 3
knit: "bookdown::render_book"
---

# A User-Controlled Radial Tour for Animated Linear Projections {#ch-spinifex}

<!-- Segue and disclose change -->
This chapter introduces manual tours that allows analysts to influence the contributions to a projection. This feature is unique from previous linear embeddings and not facilitated by compiling software.

<!-- Abstract -->
Dynamic low-dimensional linear projections of multivariate data known as _tour_ provide an essential tool for exploring multivariate data and models. The __R__ package __tourr__ provides functions for several types of tours: grand, guided, little, local, and frozen. Each of these can be viewed in a development environment, or their basis array can be saved for later consumption. This chapter describes a new package, __spinifex__, which provides a manual tour of multivariate data. In a manual tour an analyst controls the contribution of a variable to the projection. Controlled manipulation is important to explore a variables sensitivity to structure of an identified feature. The use of the manual tour is applied to particle physics data to illustrate the sensitivity of structure in a projection to specific variable contributions. Additionally, we create a ggproto API for composing any tour that mirrors the layered additive approach of __ggplot2__. Tours can then be animated and exported to various formats with __plotly__ or __gganimate__.

<!-- ## Introduction -->

<!-- Segue -->
In the Chapter \@ref(ch-background) we introduce linear projections and _tours_, dynamic linear projections animated over small changes to the basis. The _manual tour_ [@cook_grand_1995] novelly allows an analyst control the contribution of a variable to the basis. On the theoretical side of the contribution we fill in previously absent details to solve at the 3D rotation matrix used in 2D manual tours. This proves a scaffolding for the extension for solving for a 4D rotation matrix that could be used for a 3D manual tour. After that we turn our attention to the package and implementation before illustrating use of the manual tour with meta analysis on high energy particle physics data.

<!-- chapter outline -->
The chapter is organized as follows. Section \@ref(sec:algorithm) describes the algorithm used to perform a radial manual tour implemented in the package __spinifex__. Section \@ref(sec:pkgstructure) discussed the functions. Package functionality and code usage following the order applied in the algorithm follows in section \@ref(sec:usage). Section \@ref(sec:usecases) illustrates how this can be used for sensitivity analysis applied to multivariate data collected on high-energy physics experiments [@wang_mapping_2018]. Section \@ref(sec:discussion) summarizes this chapter.


<!-- Algorithm outline -->
## Algorithm {#sec:algorithm}

The types of manipulations of the manual tour can be thought of in several ways:

- *radial*: fix the direction of contribution, and allow the magnitude to change.
- *angular*: fix the magnitude, and allow the angle or direction of the contribution to vary.
- *horizontal*, *vertical*: allow rotation only around the horizontal or vertical axis of the current 2D projection.
- *oblique*: paths deviating from these movements such as being captured from the movement of a cursor.

Angular manipulations are homomorphic, in that they show the same information while rotating the frame. More interesting a change in the magnitude of the contribution, changing the radius along the original angle of contribution. For this reason we implement the radial tour as the default values for the manual tour. Below we describe the manual tour illustrated in detail. After that we also include summaries of the algorithms oblique cursor movements for in the 1D and 2D instances.


### Notation

The notation used to describe the algorithm for a 2D radial manual tour is as follows:

- $\textbf{X}$, the data, an $n \times p$ numeric matrix to be projected.
- $\textbf{A}$, any orthonormal projection basis, $p \times d$ matrix, describing the projection from $\mathbb{R}^p \Rightarrow \mathbb{R}^d$.
- $k$, is the index of the manipulation variable or manip var for short.
- $\textbf{e}$, a 1D basis vector of length $p$, with 1 in the $k$-th position and 0 elsewhere.
- $\textbf{R}$, the $d+1$-D rotation matrix, for performing unconstrained 3D rotations within the manip space, $\textbf{M}$.
- $\theta$, the angle of in-projection rotation, for example, on the reference axes; $c_\theta, s_\theta$ are its cosine and sine.
- $\phi$, the angle of out-of-projection rotation, into the manip space; $c_\phi, s_\phi$ are its cosine and sine. The initial value for animation purposes is $\phi_1$.
- $\textbf{U}$, the axis of rotation for out-of-projection rotation orthogonal to $\textbf{e}$.
- $\textbf{Y} = \textbf{X} \times \textbf{A}$, the resulting projection of the data through the manip space, $\textbf{M}$, and rotation matrix, $\textbf{R}$.

<!-- operate on bases -->
The algorithm operates entirely on projection bases and incorporates the data only when making the projected data plots in light of efficiency.


### Steps

#### Step 0) Setup

<!-- describe data. -->
The flea data (@lubischew_use_1962), available in the __tourr__ package [@wickham_tourr:_2011], is used to illustrate the algorithm. The data contains 74 observations of six variables, physical measurements of flea beetles. Each observation belongs to one of three species.

<!-- Projection basis -->
An initial 2D projection basis must be provided. A suggested way to start is to identify an interesting projection using a projection pursuit guided tour. Here the holes index is used to find a 2D projection of the flea data, which shows three separated species groups. Figure \@ref(fig:ch3fig1) shows the initial projection of the data. The left panel displays the projection basis ($\textbf{A}$) and can be used as a visual guide of the magnitude and direction that each variable contributes to the projection. The right panel shows the projected data, $\textbf{Y}_{[n,~2]} ~=~ \textbf{X}_{[n,~p]} \textbf{A}_{[p,~2]}$. The color and shape of points are mapped to the flea species.

```{r ch3fig1, fig.cap = "Biplot of the initial 2D projection: representation of the basis (left) and resulting data projection (right) of standardized flea data. The color and shape of data points are mapped to the species of flea beetle. The basis was produced by a projection pursuit guided tour with the holes index. The contribution of the variables aede2 and tars1 approximately contrasts the other variables. The visible structure in the projection are the three clusters corresponding to the three species."}
nsSafeIncGraphic("./figures/ch3_fig1_biplot.pdf")
```


#### Step 1) Choose manip variable

<!-- select a manip var-->
In figure \@ref(fig:ch3fig1) the contribution of the variables tars1 and aede2 mostly contrast the contribution of the other four variables. These two variables combined contribute in the direction of the projection where the purple cluster is separated from the other two clusters. The variable aede2 is selected as the manip var, the variable to be controlled in the tour. The question that will be explored is: how important is this variable to the separation of the clusters in this projection?


#### Step 2) Create the 3D manip space

<!-- Zero Vect, manip sp -->
Initialize the coordinate basis vector as a zero vector, $\textbf{e}$, of length $p$, and set the $k$-th element to 1. In the example data, aede2 is the fifth variable in the data, so $k=5$, set $e_5=1$. Use a Gram-Schmidt process to orthonormalize the coordinate basis vector on the original 2D projection to describe a 3D manip space, $\textbf{M}$.

\begin{align*}
  e_k &\leftarrow 1 \\ 
  \textbf{e}^*_{[p,~1]} &= \textbf{e} - \langle \textbf{e}, \textbf{A}_1 \rangle \textbf{A}_1 - \langle \textbf{e}, \textbf{A}_2 \rangle \textbf{A}_2 \\ 
  \textbf{M}_{[p,~3]} &= (\textbf{A}_1,\textbf{A}_2,\textbf{e}^*)
\end{align*}

<!-- What the manip space provides -->
The manip space provides a 3D projection from $p$-dimensional space, where the coefficient of the manip var can range completely between [0, 1]. This 3D space serves as the medium to rotate the projection basis relative to the selected manipulation variable. Figure \@ref(fig:ch3fig2) illustrates this 3D manip space with the manip var highlighted. This representation is produced by calling the `view_manip_space()` function. This diagram is purely used to help explain the algorithm.

```{r ch3fig2, fig.cap = "Illustration of a 3D manip space, the projection plane is shown as a blue circle extending into and out of the display. A manipulation direction is initialized, the red circle, orthogonal to the projection plane. This allows the selected variable, aede2, to change its contribution back to the projection plane. The other variables contributions rotate into this space as well, preserving the orthogonal structure, but are omitted in the manipulation dimension for simplicity."}
nsSafeIncGraphic("./figures/ch3_fig2_manip_sp.pdf")
```


#### Step 3) Defining a 3D rotation

<!-- illustration of axis manip -->
The basis vector corresponding to the manip var (red line in Figure \@ref(fig:ch3fig2)), can be operated like a lever anchored to the origin. This is the process of the manual control, that rotates the manip variable into and out of the 2D projection (Figure \@ref(fig:ch3fig3)). As the variable contribution is controlled, the manip space turns, and the projection onto the horizontal projection plane correspondingly changes. This is a manual tour. Generating a sequence of values for the rotation angles produces a path for the rotation of the manip space.

<!-- describe manip var path -->
For a radial tour, fix $\theta$, the angle describing rotation within the projection plane, and compute a sequence for $\phi$, defining movement out of the plane. This will change $\phi$ from the initial value, $\phi_1$, the angle between $\textbf{e}$ and its shadow in $\textbf{A}$, to a maximum of $0$ (manip var fully in projection), then to a minimum of $\pi/2$ (manip var out of projection), before returning to $\phi_1$.

<!-- define the rotation matrix -->
Rotations in 3D can be defined by the axes they pivot on. Rotation within the projection, $\theta$, is rotation around the $Z$-axis. Out-of-projection rotation, $\phi$, is the rotation around an axis on the $XY$ plane, $\textbf{U}$, orthogonal to $\textbf{e}$. Given these axes, the rotation matrix, $\textbf{R}$, can be written as follows, using Rodrigues' rotation formula (originally published in @rodrigues_lois_1840):

  \begin{align*}
    \textbf{R}_{[3,~3]} 
    &= \textbf{I}_3 + s_\phi\*\textbf{U} + (1-c_\phi)\*\textbf{U}^2 \\
        &=
    \begin{bmatrix}
      1 & 0 & 0 \\ 
      0 & 1 & 0 \\ 
      0 & 0 & 1 \\
    \end{bmatrix} +
    \begin{bmatrix}
      0 & 0 & c_\theta s_\phi \\
      0 & 0 & s_\theta s_\phi \\
      -c_\theta s_\phi & -s_\theta s_\phi & 0 \\
    \end{bmatrix} +
    \begin{bmatrix}
      -c_\theta (1-c_\phi) & s^2_\theta (1-c_\phi) & 0 \\
      -c_\theta s_\theta (1-c_\phi) & -s^2_\theta (1-c_\phi) & 0 \\
      0 & 0 & c_\phi-1 \\
    \end{bmatrix} \\
    &= 
    \begin{bmatrix}
      c_\theta^2 c_\phi + s_\theta^2 &
      -c_\theta s_\theta (1 - c_\phi) &
      -c_\theta s_\phi \\
      -c_\theta s_\theta (1 - c_\phi) &
      s_\theta^2 c_\phi + c_\theta^2 &
      -s_\theta s_\phi \\
      c_\theta s_\phi &
      s_\theta s_\phi &
      c_\phi
    \end{bmatrix} \\
\end{align*}

\noindent where

\begin{align*}
  \textbf{U} &= (u_x, u_y, u_z) =
  (s_\theta, -c_\theta, 0) \\ 
  &=
  \begin{bmatrix}
  0 & -u_z & u_y \\
  u_z & 0 & -u_x \\
  -u_y & u_x & 0 \\
  \end{bmatrix} =
  \begin{bmatrix}
    0 & 0 & -c_\theta \\
    0 & 0 & -s_\theta \\
    c_\theta & s_\theta & 0 \\
  \end{bmatrix} \\
  \end{align*}
  
<!-- The term $(1-c_\phi)$ is used by convention, but $2sin^2(\phi/2)$ is more computationally robust. -->


#### Step 4) Creating an animation of the radial rotation

<!-- Phi transform and animation -->
The steps outlined above can be used to create any arbitrary rotation in the manip space. To use these for sensitivity analysis, the radial rotation is built into an animation where the manip var is rotated fully into the projection, completely out, and then back to the initial value. This involves allowing $\phi$ to vary between $0$ and $\pi/2$, call the steps $\phi_i$. 

```{r ch3fig3, fig.cap = "Select frames highlight the animation of a radial manual tour manipulating aede2: (1) original projection, (2) full contribution, (3) zero contribution, before returning to the original contribution."}
nsSafeIncGraphic("./figures/ch3_fig3_filmstrip.pdf")
```

<!-- Sequence of $\phi_i$ -->
1. Set initial value of $\phi_1$ and $\theta$: $\phi_1 = \cos^{-1}{\sqrt{A_{k1}^2+A_{k2}^2}}$, $\theta = \tan^{-1}\frac{A_{k2}}{A_{k1}}$. Where $\phi_1$ is the angle between $\textbf{e}$ and its shadow in $\textbf{A}$.
2. Set an angle increment ($\Delta_\phi$) that sets the step size for the animation, to rotate the manip var into and out of the projection. Uses of angle increment, rather than a number of steps to control the movement is consistent with the tour algorithm as implemented in the __tourr__.
3. Step towards $0$, where the manip var is entirely in the projection plane.
4. Step towards $\pi/2$, where the manip variable has no contribution to the projection.
5. Step back to $\phi_1$.

In each of the steps 3-5, a small step may be added to ensure that the endpoints of $\phi$ ($0$, $\pi/2$, $\phi_1$) is reached. 


#### Step 5) Projecting the data {#sec:display}

<!-- the reminder of basis operation and now apply data -->
The operation of a manual tour is defined on the projection bases. Only when the data plot needs to be made the data projected into the relevant basis. 

\begin{align*}
  \textbf{Y}^{(i)}_{[n,~3]} &= \textbf{X}_{[n,~p]} \textbf{M}_{[p,~3]} \textbf{R}^{(i)}_{[3,3]}
\end{align*}

<!-- plot XY in seq for animation -->
\noindent where $\textbf{R}^{(i)}_{[3,3]}$ is the incremental rotation matrix, using $\phi_i$. To make the data plot, use the first two columns of \textbf{Y}. Show the projected data for each frame in sequence to form an animation. 

Tours are typically viewed as an animation. The animation of this tour can be viewed online on [GitHub](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/flea_radialtour_mvar5.gif). The page may take a moment to load.

## Oblique cursor movement

In a move abbreviated way we can think about the algorithm for 1D and 2D oblique manual tours as:

<!-- 1D Oblique from cursor movement -->
<!-- Best version with \usepackage{algorithm} \usepackage{algpseudocode} -->
\begin{algorithm}
\caption{1D oblique manual tour from cursor movement}
\begin{algorithmic}
\Require \\
\begin{itemize}
    \item $\textbf{A}$ is a 1D basis defining the current projection;
    \item $\textbf{e} = e_k$ is a $p$-dimensional vector of zeros with a 1 in the $k$-th position, the manipulation variable;
    \item $\text{dist}_x$ = horizontal distance of the cursor movement;
    \item $\text{dist}_y$ = vertical distance of the cursor movement;
\end{itemize}
\Ensure $||\textbf{A} - \textbf{e}|| >$ tolerance \\
Initialize the manipulation space, Gram-Schmidt process orthonormalizing $\textbf{e}$ on $\textbf{A}$:
\State $\textbf{M} \gets \textbf{e} - <\textbf{e}, \textbf{A}> \textbf{A}$ \\
Initialize change in magnitude, $\phi$, as a function of the horizontal cursor movement: \\
\State $\phi \gets \frac{\text{dist}_x}{\text{size of plot}_x},~~~c_\phi = cos(\phi), ~~~s_\phi = sin(\phi)$ \\
\For{$\phi_i$ in $[0, \phi]$ by an interpolation increment step size} \\
  ~~~Rotate the manipulation space: \\
  ~~~\State $$ \textbf{M} \gets \textbf{M} \cdot \left(
    \begin{array}{cc}
        c_{\phi_i}  & s_{\phi_i} \\
        -s_{\phi_i} & c_{\phi_i} \\
    \end{array}
  \right) $$
  ~~~Append an array, $\textbf{Y}$, premultiplying the data by each interpolated basis of the manipulation space:
  ~~~\State $\textbf{Y}_{n p i} \gets \textbf{X}_{n p} \cdot \textbf{M}_{p 1:d}$ \\
  ~~~(Alternatively, store the array of the interpolated bases for more compact format and premultiply data when needed.)
\EndFor
\end{algorithmic}
\end{algorithm}
```{r, echo=F}
## Work around for html not including algorithm
if(knitr::is_html_output())
  nsSafeIncGraphic("./figures/ch3_algo1.PNG")
```


<!-- 2D Oblique from cursor movement -->
\begin{algorithm}
\caption{2D oblique manual tour from cursor movement}
\begin{algorithmic}
\Require \\
\begin{itemize}
    \item $\textbf{A}$ is a 1D basis defining the current projection;
    \item $\textbf{e} = e_k$ is a $p$-dimensional vector of zeros with a 1 in the $k$-th position, the manipulation variable;
    \item $\text{dist}_x$ = horizontal distance of the cursor movement;
    \item $\text{dist}_y$ = vertical distance of the cursor movement;
\end{itemize}
\Ensure $||\textbf{A} - \textbf{e}|| >$ tolerance \\
Initialize the manipulation space, Gram-Schmidt process orthonormalizing $\textbf{e}$ on $\textbf{A}$:
\State $\textbf{M} \gets \textbf{e} - <\textbf{e}, \textbf{A}_1> \textbf{A}_1 - <\textbf{e}, \textbf{A}_2> \textbf{A}_2$ \\
Initialize change in magnitude, $\phi$: \\
\State $\phi \gets \frac{\sqrt{\text{dist}_x^2 + \text{dist}_y^2}}{\text{size of plot}_x},~~~c_\phi = cos(\phi), ~~~s_\phi = sin(\phi)$ \\
Initialize change in angle, $\theta$: \\
\State $c_\theta = cos(\theta) \gets \frac{\text{dist}_x}{\sqrt{\text{dist}_x^2 + \text{dist}_y^2}} $
\State $s_\theta = sin(\theta) \gets \frac{\text{dist}_y}{\sqrt{\text{dist}_x^2 + \text{dist}_y^2}} $
\For{$\phi_i$ in $[0, \phi]$ by an interpolation increment step size} \\
  ~~~Rotate the manipulation space: \\
  ~~~\State $$ \textbf{M} \gets \textbf{M} \cdot \left(
    \begin{array}{ccc}
      c_\theta^2 c_\phi + s_\theta^2 &
      -c_\theta s_\theta (1 - c_\phi) &
      -c_\theta s_\phi \\
      -c_\theta s_\theta (1 - c_\phi) &
      s_\theta^2 c_\phi + c_\theta^2 &
      -s_\theta s_\phi \\
      c_\theta s_\phi &
      s_\theta s_\phi &
      c_\phi
    \end{array}
  \right) $$
  ~~~Append an array, $\textbf{Y}$, premultiplying the data by each interpolated basis of the manipulation space:
  ~~~\State $\textbf{Y}_{n p i} \gets \textbf{X}_{n p} \cdot \textbf{M}_{p 1:d}$ \\
  ~~~(Alternatively, store the array of the interpolated bases for more compact format and premultiply data when needed.)
\EndFor
\end{algorithmic}
\end{algorithm}
```{r, echo=F}
## Work around for html not including algorithm
if(knitr::is_html_output())
  nsSafeIncGraphic("./figures/ch3_algo2.PNG")
```


## Package structure {#sec:pkgstructure}

In addition to facilitating the manual tour the other primary function is to facilitate the layered composition of tours, interoperabily with tours from __tourr__. This package tries to abstract away the complexity of dealing with a varying number of frames and replicating the length of arguments. We use a layered composition approach to tours steming from __ggplot2__ [@wickham_ggplot2_2016], which can then be animated animation by __plotly__ [@sievert_interactive_2020] or __gganimate__ [@pedersen_gganimate_2020]. This section describes the functions available in the package, their usage, and how to install and get up and running.


### Usage {#sec:usage}

Using the penguins data , available in the package, to illustrate a manual tour, we will illustrate generating a manual tour to explore the sensitivity of a variable separating two clusters. The composition of the tour display echos the additive layered approach of __ggplot2__, while abstracting away the complexity of dealing with changing number of frames and their animation.

```{r eval=F, echo=T}
## Process penguins data
dat     <- scale_sd(penguins[1:4])
clas    <- penguins$species
bas     <- basis_olda(data = dat, class = clas)

## A manual tour tour path
mt_path <- manual_tour(basis = bas, manip_var = 1, data = dat)

## Composing the display of the tour
ggt <- ggtour(mt_path, angle = .15) +
  proto_point(aes_args      = list(color = clas, shape = clas),
              identity_args = list(alpa = .8, size = 1.5)) +
  proto_basis() +
  proto_origin()

## Animating
animate_plotly(ggt, fps = 5)


## A 1D grand tour from tourr
gt_path <- save_history(
  data = dat, tour_path = grand_tour(d = 1), max_bases = 10)

## Composing the display of the tour
ggt2 <- ggtour(gt_path, angle = .15) +
  proto_default(aes_args      = list(color = clas, fill = clas)) +
  proto_basis1d() +
  proto_origin1d()

## Animating
animate_plotly(ggt2, fps = 5)
```


### Functions

Table \@ref(tab:functionsTable) lists the primary functions and their purpose. These are grouped into four types: processing the data, production of tour path, the composition of the tour display, and its animation.

```{r functionsTable, echo=F, eval=T}
library(kableExtra)

funcs_tib <- tibble::tribble(
  ~Family,      ~Function,            ~`Related to`,         ~Description,
  "processing", "scale_01/sd",        "-",                   "scale each column to [0,1]/std dev away from the mean",
  "processing", "basis_pca/olda/...", "Rdimtools::do.*",     "basis of orthogonal component spaces",
  "processing", "basis_half_circle",  "-",                   "basis with uniform contribution across half of a circle",
  "processing", "basis_guided",       "tourr::guided_tour",  "silently return the basis from a guided tour",
  "tour path",  "manual_tour",        "-",                   "basis and interpolation information for a manual tour",
  "tour path",  "save_history",       "tourr::save_history", "silent, extended wrapper returning other tour arrays",
  "display",     "ggtour",            "ggplot2::ggplot",     "canvas and initialization for a tour animation",
  "display",     "proto_point/text",  "geom_point/text",     "adds observation points/text",
  "display",     "proto_density/2d",  "geom_density/2d",     "adds density curve/2d contours",
  "display",     "proto_hex",         "geom_hex",            "adds hexagonal heatmap of observations",
  "display",     "proto_basis/1d",    "-",                   "adds adding basis visual in a unit-circle/-rectangle",
  "display",     "proto_origin/1d",   "-",                   "adds reference mark in the center of the data",
  "display",     "proto_default/1d",  "-",                   "wrapper for proto_* point + basis + origin",
  "display",     "facet_wrap_tour",   "ggplot2::facet_wrap", "facets on the levels of variable",
  "display",     "append_fixed_y",    "-",                   "add/overwrite a fixed vertical position",
  "animation",  "animate_plotly",     "plotly::ggplotly",    "render as an interactive hmtl widget",
  "animation",  "animate_gganimate",  "gganimate::animate",  "render as a gif, mp4, or other video format",
  "animation",  "filmstrip",          "-",                   "static gpplot faceting on the frames of the animation"
)

if(knitr::is_html_output()) fmt <- "html" else fmt <- "latex"
if(knitr::is_html_output()) fnt <- 12L else fnt <- 8L
kableExtra::kable(funcs_tib, fmt, caption = "Summary of primary functions.", 
                  booktabs = TRUE, linesep = "") %>%
  kableExtra::kable_styling(font_size = fnt)
```


### Installation

The __spinifex__ is available from CRAN, the following code will help to get up and running:

```{r eval=F, echo=T}
# Installation:
install.package("spinifex") ## Install from CRAN
library("spinifex") ## Load into session

# Getting started:
## Shiny app for visualizing basic application
run_app("intro")
## View the code vignette
vignette("getting_started_with_spinifex")
## More about proto_* functions
vignette("ggproto_api")
```


## Use cases {#sec:usecases}

<!-- Introduction of data and original chapter -->
@wang_mapping_2018 introduce a new tool, PDFSense, to visualize the sensitivity of hadronic experiments to nucleon structure. The parameter-space of these experiments lies in 56 dimensions, and are approximated as the ten first principal components. 

<!-- grand tours on the same data -->
@cook_dynamical_2018 illustrates how to learn more about the structures using a grand tour. Tours can better resolve the shape of clusters, intra-cluster detail, and better outlier detection than PDFSense & TFEP (TensorFlow embedded projections) or traditional static embeddings. This example builds from here, illustrating how the manual tour can be used to examine the sensitivity of structure in a projection to different parameters. The specific 2D projections passed to the manual tour were provided in their work. 

<!-- Data structure -->
The data has a hierarchical structure with top-level clusters; DIS, VBP, and jet. Each cluster is a particular class of experiments, each with many experimental datasets which each have many observations of their own. In consideration of data density, we conduct manual tours on subsets of the DIS and jet clusters. This explores the sensitivity of the structure to each of the variables in turn and we present the subjectively best and worst variable to manipulate for identifying dimensionality of the clusters and describing the span of the clusters.


### Jet cluster

<!-- jet cluster, explain dimensionality -->
The jet cluster resides in a smaller dimensionality than the full set of experiments, with four principal components explaining 95% of the variation in the cluster [@cook_dynamical_2018]. The data within this 4D embedding is further subset to ATLAS7old and ATLAS7new, to focus on two groups that occupy different parts of the subspace. Radial manual tours controlling contributions from PC4 and PC3 are shown in Figures \@ref(fig:ch3fig4) and \@ref(fig:ch3fig5), respectively. The difference in shape can be interpreted as the experiments probing different phase spaces. Back-transforming the principal components to the original variables can be done for a more detailed interpretation.

<!-- discussion of findings and which is more insightful -->
When PC4 is removed from the projection (Figure \@ref(fig:ch3fig4)), the difference between the two groups is removed, indicating that PC4 is essential for the separation of experiments. However, eliminating PC3 from the projection (Figure \@ref(fig:ch3fig5)) does not affect the structure, meaning PC3 is not important for distinguishing experiments. Animations for the remaining PCs can be viewed at the following links: [PC1](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/jetcluster_manualtour_pc1.gif), [PC2](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/jetcluster_manualtour_pc2.gif), [PC3](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/jetcluster_manualtour_pc3.gif), and [PC4](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/jetcluster_manualtour_pc4.gif). It can be seen that only PC4 is important for viewing the difference in these two experiments.

<!-- JetClusterGood -->
```{r ch3fig4, fig.cap="Select frames from a radial tour of PC4 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When PC4 is removed from the projection (frame 10), there is little difference between the clusters, suggesting that PC4 is important for distinguishing the experiments."}
nsSafeIncGraphic("./figures/ch3_fig4_jet_better_pc4.pdf")
```
<!-- JetClusterBad -->
```{r ch3fig5, fig.cap = "Frames from the radial tour manipulating PC3 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange).  When the contribution from PC3 is changed, there is little change in the separation of the clusters, suggesting that PC3 is not important for distinguishing the experiments."}
nsSafeIncGraphic("./figures/ch3_fig5_jet_worse_pc3.pdf")
```


### DIS cluster

<!-- introduce DIS cluster -->
Following @cook_dynamical_2018, to explore the DIS cluster, PCA is recomputed and the first six principal components, explaining 48% of the full sample variation, are used. The contributions of PC6 and PC2 are explored in Figures \@ref(fig:ch3fig6) and \@ref(fig:ch3fig7), respectively. Three experiments are examined: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange).

<!-- comparison of the DIS cluster -->
Both PC2 and PC6 contribute to the projection similarly. When PC6 is rotated into the projection, variation in the DIS HERA1+2 is greatly reduced. When PC2 is removed from the projection, dimuon SIDIS becomes more distinct. Even though both variables contribute similarly to the original projection their contributions have quite different effects on the structure of each cluster, and the distinction between clusters. Animations of all of the principal components can be viewed from the links: [PC1](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/discluster_manualtour_pc1.gif), [PC2](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/discluster_manualtour_pc2.gif), [PC3](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/discluster_manualtour_pc3.gif), [PC4](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/discluster_manualtour_pc4.gif), [PC5](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/discluster_manualtour_pc5.gif), and [PC6](https://github.com/nspyrison/spinifex_paper/blob/master/paper/gifs/discluster_manualtour_pc6.gif).

<!-- DISclusterGood -->
```{r ch3fig6, fig.cap = "Select frames from a radial tour exploring the sensitivity that PC6 has on the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). DIS HERA1+2 is distributed in a cross-shaped plane, and charm SIDIS occupies the center of this cross, and dimuon SIDIS is a linear cluster crossing DIS HERA1+2. As the contribution of PC6 is increased, DIS HERA1+2 becomes almost singular in one direction (frame 5), indicating that this cluster has very little variability in the direction of PC6."}
nsSafeIncGraphic("./figures/ch3_fig6_DIS_better_pc6.pdf")
```

<!-- DISclusterBad -->
```{r ch3fig7, fig.cap = "Frames from the radial tour exploring the sensitivity PC2 to the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). As the contribution of PC2 is decreased, dimuon SIDIS becomes more distinguishable from the other two clusters, indicating that in the absence of PC2 is important for separating this cluster from the others."}
nsSafeIncGraphic("./figures/ch3_fig7_DIS_worse_pc2.pdf")
```


## Discussion {#sec:discussion}

<!-- Summary of spinifex -->
Dynamic linear projections of numeric multivariate data, tours, play an important role in data visualization; they extend the dimensionality of visuals to peek into high-dimensional data and parameter spaces. This research has taken the manual tour algorithm, specifically the radial rotation, used in GGobi [@swayne_ggobi:_2003] to interactively rotate a variable into or out of a 2D projection, and modified it to create an animation that performs the same task. It is most useful for examining the importance of variables and how the structure in the projection is sensitive or not to specific variables. This functionality is made available in the package __spinifex__. Which also extends the geometric display and export formats interoperable with the __tourr__ package.

<!-- Summary of application -->
This work was motivated by problems in physics, and thus the usage was illustrated on data comparing experiments of hadronic collisions to explore the sensitivity of cluster structure to different principal components. These tools can be applied quite broadly to many multivariate data analysis problems.

<!-- Constraints -->
The manual tour is constrained in the sense that the effect of one variable is dependent on the contributions of other variables in the manip space. However, this can be useful to simplify a projection by removing variables without affecting the visible structure. Defining a manual rotation in high dimensions is possible using Givens rotations and Householder reflections as outlined in @buja_computational_2005. This would provide more flexible manual rotation but more difficult for a user because they have the choice (too much choice) of which directions to move. 


<!-- ## References -->

<!-- <div id="refs"></div> -->

<!-- Adds a bib section at the end of every chapter -->

<!--chapter:end:03-spinifex.Rmd-->

---
chapter: 4
knit: "bookdown::render_book"
---

# A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data {#ch-userstudy}

<!-- Segue -->
The previous chapter introduced the package __spinifex__ which gave us the means to perform radial tours. There is no evidence to support that the user-controlled steering of the radial tour leads to better perception than traditional methods. Therefore, this chapter discusses the user study to elucidate the efficacy of the radial tour.

<!-- Abstract -->
In Chapters \@ref(ch-introduction) and \@ref(ch-background) have introduced PCA, the grand tour, and radial tour. This chapter describes a within-participants user study evaluating efficacy of these techniques. A supervised classification task is devised where participants evaluate variable attribution of the separation between two classes. An accuracy measure is defined to use as the response variable. Data were collected from 108 crowdsourced participants, who performed two trials of each visual for 648 trials in total.

<!-- thesis_ns introduction -->
The user influence over a basis, uniquely available in the radial tour, is crucial to testing variable sensitivity to the structure visible in projection. If the contribution of a variable is reduced and the feature disappears, then it is said that the variable is sensitive to that structure. For example, Figure \@ref(fig:figClSep) shows two frames of simulated data. Panel (a) has identified separation between the two clusters. The contributions in panel (b) show no such cluster separation. The former has a large contribution to V2 in the direction of separation, while it is negligible in the right frame. Because of this it is said that V2 is sensitive to the separation of the clusters.

```{r figClSep, echo = F, out.width = "100%", fig.cap = "Illustration of cluster separation. Panel (a) shows clear separation in V2 and no separation in the direction of V3. While V1 and v4 have relatively small contributions to the frame. Panel (b) has a random basis with a minimal contribution from V2, and no separation between the cluster means is resolved."}
knitr::include_graphics("./figures/ch4_fig1_cl_sep.pdf")
```

<!--- black-box models-->
Knowing which variables to use is also important for statistical modeling and their interpretations. Models are becoming increasingly complex, and the nonlinear interactions of the terms cause an opaqueness to model interpretability. Exploratory Artificial Intelligence [XAI, @adadi_peeking_2018; @arrieta_explainable_2020] is an emerging field that extends the interpretability of such black-box models. Multivariate data visualization is essential for exploring features spaces and communicating interpretations of models [@biecek_dalex_2018; @biecek_explanatory_2021; @wickham_visualizing_2015].

<!-- Structure of the paper -->
The chapter is structured as follows. Section \@ref(sec:userstudy) describes the experimental factors, task, and accuracy measure used. The results of the study are discussed in Section \@ref(sec:results). Conclusions and potential future directions are discussed in Section \@ref(sec:conclusion). The software used for the study is described in Section \@ref(sec:spinifex).


## User study {#sec:userstudy}

<!-- Overview of visual -->
An experiment was constructed to assess the performance of the radial tour relative to the grand tour and PCA for interpreting the variable attribution contributing to separation between two clusters. <!-- Introduce experimental factors --> Data were simulated across three experimental factors: cluster shape, location of the cluster separation, and data dimensionality. Participant responses were collected using a web application and crowdsourced through prolific.co, [@palan_prolific_2018] an alternative to MTurk.


### Objective {#sec:objective}

<!-- Rational for visual levels -->
PCA will be used as a baseline for comparison as it is the most commonly used linear embedding. The grand tour will act as a secondary control that will help evaluate the benefit of animation without influencing its path. Lastly, the radial tour should perform best as it benefits from animation and user control.

<!-- Prior expectations -->
Then for some subset of tasks, we expect to find that the radial tour performs most accurately. In the appendix, section \@ref(sec:appendix), regresses on the log response time. Due to the absence of inputs, the grand tour may lead to faster response time than the alternatives since users can focus all of their attention on interpreting the fixed path. Conversely, we are less sure about the accuracy of such limited grand tours as there is no objective function in selecting the bases; it is possible that the random selection of the target bases altogether avoids bases showing cluster separation. However, given that the data dimensionality was modest, it seems plausible that the grand tour coincidentally regularly crossed frames with the correct information for the task.

<!-- Explicit hypothesis tests -->
An experimental factors and definition of an accuracy measure are given below. The null hypothesis can be stated as:

$$
\begin{align*}
&H_0: \text{accuracy does not change across visual method} \\
&H_\alpha: \text{accuracy does change across visual method}
\end{align*}
$$


### Experimental factors {#sec:expfactors}

<!-- Introduction to experimental factors -->
In addition to the visual, data are simulated across three experimental factors. First, the _location_ of the separation between clusters by mixing a signal and a noise variable at different ratios. Secondly, the _shape_ of the clusters reflects varying distributions of the data. And third, the _dimension_-ality of the data. The levels within each of factors are described below and Figure \@ref(fig:figExpFactors) gives a visual representation.

<!-- Illustration of experimental factors -->
```{r figExpFactors, out.width='100%', fig.cap = "Illustration of the experimental factors, the parameter space of the independent variables, the support of our study."}
nsSafeIncGraphic("./figures/ch4_fig3_exp_factors.pdf")
```

<!-- Location mixing -->
The _location_ of the separation of the clusters is at the heart of the measure. It would be good to test a few varying levels. To test the sensitivity, noise and signal-containing variables are mixed. The separation between clusters are mixed at the following percentages: 0/100% (not mixed), 33/66%, 50/50% (evenly mixed).

<!-- Shape, vc matrix -->
In selecting the _shape_ of the clusters, the convention given by @scrucca_mclust_2016 is followed. They describe 14 variants of model families containing three clusters. The name of the model family is the abbreviation of its respective volume, shape, and orientation of the clusters, the levels of which are either _E_qual or _V_ary. The models EEE, EEV, and EVV are used. For Instance, in the EEV model, the volume and shape of clusters are constant, while the shape's orientation varies. The EVV model is further modified by moving four-fifths of the data out in a "V" or banana-like shape.

<!-- Dimensionality -->
_Dimension_-ality is tested at two modest levels, namely, in four dimensions containing three clusters and six dimensions with four clusters. Such modest dimensionality is required to bound the difficulty and search space to keep the task realistic for crowdsourcing.


### Task and evaluation {#sec:task}

<!-- segue to task and evaluation -->
With our hypothesis formulated and data at hand, let us turn our attention to the task and how to evaluate it. Regardless of the visual method, the elements of the display are held constant, shown as a 2D scatterplot with an axis biplot to its left. Observations were supervised with the cluster level mapped to color and shape.

<!-- Geom, clusters, explicit task -->
Participants were asked to 'check any/all variables that contribute more than average to the cluster separation green circles and orange triangles,' which was further explained in the explanatory video as 'mark any and all variable that carries more than their fair share of the weight, or one quarter in the case of four variables'.

<!-- Instruction and video -->
The instructions iterated several times in the video was: 1) use the input controls to find a frame that contains separation between the clusters of green circles and orange triangles, 2) look at the orientation of the variable contributions in the gray circle (biplot axes orientation), and 3) select all variables that contribute more than uniformed distributed cluster separation in the scatterplot. Independent with experimental level, participants were limited to 60 seconds for each evaluation of this task. This restriction did not impact many participants as the 25th, 50th, 75th quantiles of the response time were about 7, 21, and 30 seconds respectively.

<!-- Evaluating measure -->
The evaluation measure of this task was designed with a few features in mind: 1) the sum of squares of the individual variable weights should be one, 2) symmetric about zero, that is, without preference to under- or over-guessing 3) heavier than linear weight with increasing distance from a uniform height. The following measure is defined for evaluating the task with these in mind.

Let a data $\textbf{X}_{n,~p,~k}$ be a simulation containing clusters of observations of different distributions. Where $n$ is the number of observations, $p$ is the number of variables, and $k$ indicates the cluster an observation belongs. Cluster membership is exclusive; an observation cannot belong to more than one cluster.

<!-- W, weights -->
The weights, $w$ as a vector explaining the variable-wise difference between two clusters. Namely, the difference of each variable between clusters, as a proportion of the total difference, less $1/p$, the expected cluster separation if it were uniformly distributed. <!-- R, participant responses -->Participant responses are a logical value for each variable - whether or not the participant thinks each variable separates the two clusters more than uniformly distributed separation.

<!-- __v2 measure sq__ -->
$$
\begin{equation*}
  w_{j} = \frac{(\overline{X}_{\cdot, j=1, k=1} - \overline{X}_{\cdot, 1, 2}, ~...~ 
    (\overline{X}_{\cdot, p, 1} - \overline{X}_{\cdot, p, 2})}
    {\sum_{j=1}^{p}(|\overline{X}_{\cdot, j, k=1} - \overline{X}_{\cdot, j, 2}|)} - \frac{1}{p} \\
\end{equation*}
\\
\text{Where accuracy, } A \text{, is defined as:} \\
\\
\begin{equation*}
  A = \sum_{j=1}^{p}I(j) \cdot sign(w_j) \cdot w^2
\end{equation*}
$$

Where $I(j)$ is the indicator function, the binary response for variable $j$. Figure \@ref(fig:figBiplotScoring) shows one frame of a simulation with its observed variable separation (wide bars), expected uniform separation (dashed line), and accuracy if selected (thin lines).

```{r, figBiplotScoring, out.width="100%", fig.cap = "Illustration of how accuracy is measured. (L), Scatterplot and biplot of PC1 by PC4 of a simulated data set (R) illustration of cluster separation between the means of the green circles and orange triangles. Bars indicate observed cluster separation and (red/green) lines show the accuracy weight of the variable if selected. The horizontal dashed line is $1 / p$, the expected value. The weights equal the signed square of the difference between each variable value and the dashed line."}
nsSafeIncGraphic("./figures/ch4_fig4_accuracy_measure.pdf")
```


### Visual design standardization {#sec:standardization}

<!-- Background for methodology, application here -->
The visuals are tested within-participant, with each visual being evaluated twice by each participant. The order that experimental factors are experienced is controlled with the assignment, as illustrated in Figure \@ref(fig:figParmeterizationExample). Below discusses the design standardization and input uniqueness within each visual.

<!-- Aesthetic standardization -->
The visualization methods were standardized wherever possible. Data were displayed as 2D scatterplots with biplots [@gabriel_biplot_1971], a visual with variable contributions inscribed on a unit circle. All aesthetic values (colors, shapes, sizes, absence of legend, and axis titles) were constant. Variable contributions were always shown left of the scatterplot embeddings with their aesthetic values consistent. What did vary between visuals were their inputs.

<!-- PCA -->
PCA inputs allowed users to select between the top four principal components for both axes regardless of the data dimensionality (four or six). Data were simulated to have cluster separation within the 2nd to 4th components. Cluster separation was sampled to not bury signal in 5th and 6th components (not selectable in PCA input) in the interest of simplicity and time.<!-- Grand tours --> There was no user input for the grand tour; users were instead shown a 15-second animation of the same randomly selected path. Participants could view the same clip up to four times within the time limit.<!-- Radial tours --> Radial tours were also displayed at five frames per second with a step size of 0.1 radians between interpolated frames. Users were able to swap between variables. Selecting a new variable resets the animation where the new variable is manipulated to a full, zero, and then back to its initial contribution. The complete animation of any variable takes about 20 seconds and is almost entirely in the projection frame at around six seconds. The starting basis was initialized to a half-clock design, where the variables were evenly distributed in half of the circle. This design was created to be variable agnostic while maximizing the independence of the variables.


### Data simulation

<!-- Clusters and correlation -->
Each dimension is originally distributed as $\mathcal{N}(0, 1)$, given the covariance set by the shape factor. Clusters were originally separated by a distance of two before location mixing. Signal variables had a correlation of 0.9 when they had equal orientation and -0.9 when their orientations varies. Noise variables were restricted to zero correlation. Each cluster is simulated with 140 observations and is offset in a variable that did not distinguish previous variables.
 
<!-- Apply shape and location transformations -->
Clusters of the EVV shape are transformed to the banana-chevron shape (illustrated in figure \@ref(fig:figExpFactors), shape row). Then location mixing is applied by post-multiplying a (2x2) rotation matrix to the signal variable and a noise variable for the clusters in question.<!-- Preprocess and replicate and save --> All variables are then standardized by standard deviation. The rows and columns are then shuffled randomly. The observation's cluster and order of shuffling are attached to the data and saved.

<!-- Iterating over visual -->
Each of these replications is then iterated with each level of the visual. For PCA, projections were saved for each of the 12 pairs of the top four principal components. A grand tour basis path is saved for each dimensionality level. The data from each simulation is then projected through its corresponding bases path. Each simulation's variable order was previously shuffled to randomize variables containing cluster separation. The radial tour starts at either the four or six variable "half-clock" basis, where each variable has a uniform contribution in the right half with no variable contributing in the opposite direction. This acts to minimize the dependence between variable contributions. A radial tour is then produced for each variable and saved as a `gif`.


### Randomized assignment

<!-- Introduction -->
Now, with simulation and their artifacts in hand, we explain how the experimental factors are assigned and illustrate how this is experienced from a participant's perspective.

<!-- Periods, exp factor assignment -->
The study is sectioned into three periods. Each period is linked to a randomized level of visual and location. The order of dimension and shape are of secondary interest and are held constant in increasing order of difficulty; four then six dimensions and EEE, EEV, then EVV-banana, respectively.

<!-- Training and evaluation -->
Each period starts with an untimed training task at the simplest remaining experimental levels; location = 0/100%, shape = EEE, and four dimensions with three clusters. This serves to introduce and familiarize participants with input and visual differences. After the training, the participant performs on two trials with the same visual and location level across the increasing difficulty of dimension and shape. The plot was removed after 60 seconds, though participants rarely reached this limit.

<!-- visual*location nested latin square -->
The order of the visual and location levels is randomized with a nested Latin square where all levels of the visuals are exhausted before advancing to the next level of location. That requires $3!^2 = 36$ participants to evaluate all permutations of the experimental factors once. This randomization controls for potential learning effects the participant may receive. Figure \@ref(fig:figParmeterizationExample) illustrates how an arbitrary participant experiences the experimental factors.

<!-- Nested latin square assignment -->
```{r figParmeterizationExample, out.width="100%", fig.cap = "Illustration of how a hypothetical participant 63 is assigned experimental factors. Each of the six visual order permutations is exhausted before iterating to the next permutation of location order."}
## This is a manual .pttx screen cap, .png ok.
nsSafeIncGraphic("./figures/ch4_fig5_randomization_MANUAL.PNG")
```

<!-- Pilot study; 3 even evaluations of each -->
Through pilot studies sampled by convenience (information technology and statistics Ph.D. students attending Monash University), it is estimated that three full evaluations are needed to properly power the study, for a total of $N = 3 \cdot 3!^2 = 108$ participants.


### Participants {#sec:articipants}

$N = 108$ participants were recruited via prolific.co [@palan_prolific_2018]. Participants are restricted based on their claimed education requiring that they have completed at least an undergraduate degree (some 58,700 of the 150,400 users at the time). This restriction is used on the premise that linear projections and biplot displays will not be regularly used for consumption by general audiences. There is also the implicit filter that Prolific participants must be at least 18 years of age and implicit biases of timezone, location, and language. Participants were compensated for their time at \pounds 7.50 per hour, whereas the mean duration of the survey was about 16 minutes. Previous knowledge or familiarity was minimal as validated in the follow-up survey. The appendix contains a heatmap distribution of age and education paneled across preferred pronouns of the participants that completed the survey, who are relatively young, well educated, and slightly more likely to identify as males.


### Data collection

<!-- App, data collection, network issues -->
Data were recorded in __shiny__ application and written to a Google Sheet after each third of the study. Especially at the start of the study, participants experienced adverse network conditions due to the volume of participants hitting the application with modest allocated resources. In addition to this, API read/write limitations further hindered data collection. To mitigate this, the number of participants were throttled and over-collect survey trials until three evaluations are collected for all permutation levels.

<!-- Preprocessing steps -->
The processing steps were minimal. The data were formatted and then filtered to only the latest three complete studies of each experimental factor, which should have experienced the least adverse network conditions. The bulk of the studies removed were partial data and a few over-sampled permutations. This brings us to the 108 studies described in the paper, from which models and aggregation tables were built. The post-study surveys were similarly decoded to human-readable format and then filtered to include only those 84 associated with the final 108 studies.

The code, response files, their analyses, and the study application are publicly available at; \url{https://github.com/nspyrison/spinifex_study}.


## Results {#sec:results}

To recap, the primary response variable is task accuracy, as defined in section \@ref(sec:task). The parallel analysis of the log response time is provided in the appendix. Two primary data sets were collected; the user study evaluations and the post-study survey. The former is the 108 participants with the experimental factors: visual, location of the cluster separation signal, the shape of variance-covariance matrix, and the dimensionality of the data. Experimental factors and randomization were discussed in section \@ref(sec:expfactors). The survey was completed by 84 of these 108 people. It collected demographic information (preferred pronoun, age, and education), and subjective measures for each visual (preference, familiarity, ease of use, and confidence).

Below a battery of mixed regression models is built to examine the degree of the evidence and the size of the effects from the experimental factors. Then, Likert plots and rank-sum tests to compare the subjective measures between the visuals.


### Accuracy

<!-- Introduce regression model, explaining accuracy, and random effect term -->
To quantify the contribution of the experimental factors to the accuracy a linear mixed-effects model is fitted. All models have a random effect term on the participant and the simulation. These terms explain the error attributed to the individual participant's effect and variation due to the random sampling data.

<!-- Building a battery of models -->
In building a set of models to test, a base model with only the visual term is compared with the full linear model term and progressively crossing an additional experimental factor. The models with three and four interacting variables are rank deficient; there is not enough varying information in the data to explain all interacting terms.

<!-- Y1 accuracy regression -->
$$
\begin{array}{ll}
\textbf{Fixed effects}           &\textbf{Full model} \\
\alpha                           &\widehat{Y} = \mu + \alpha_i + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha + \beta + \gamma + \delta &\widehat{Y} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha \cdot \beta + \gamma + \delta &\widehat{Y} = \mu + \alpha_i \cdot \beta_j + \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha \cdot \beta \cdot \gamma + \delta &\widehat{Y} = \mu + \alpha_i \cdot \beta_j \cdot \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha \cdot \beta \cdot \gamma \cdot \delta &\widehat{Y} = \mu + \alpha_i \cdot \beta_j \cdot \gamma_k \cdot \delta_l + \textbf{Z} + \textbf{W} + \epsilon
\end{array}
$$
$$
\begin{array}{ll}
\text{where }
&\alpha_i \text{, fixed term for visual}~|~i\in (\text{pca, grand, radial}) \\
&\beta_j  \text{, fixed term for location}~|~j\in (\text{0/100\%, 33/66\%, 50/50\%}) \text{ \% noise/signal mixing} \\
&\gamma_k \text{, fixed term for shape}~|~k\in (\text{EEE, EEV, EVV banana}) \text{ model shapes} \\
&\delta_l \text{, fixed term for dimension}~|~l\in (\text{4 variables \& 3 cluster, 6 variables \& 4 clusters}) \\
&\mu \text{ is the intercept of the model including the mean of random effect} \\
&\textbf{Z} \sim \mathcal{N}(0,~\tau), \text{ the error of the random effect of participant} \\
&\textbf{W} \sim \mathcal{N}(0,~\upsilon), \text{ the error of the random effect of simulation} \\
&\epsilon   \sim \mathcal{N}(0,~\sigma), \text{ the remaining error in the model} \\
\end{array}
$$


<!-- Y1 model comparisons -->
```{r marksCompTbl, fig.cap = "Use the caption arg in kable(), not this."}
## Set format and fonts for pdf vs html:
if(knitr::is_html_output()){
  fmt      <- "html"
  fnt      <- 12L
  mod_comp <- readRDS("./figures/ch4_tab1_model_comp_ls_html.rds")
  ## Escape HTML formating of * multiplication
  mod_comp$modelComp_MarksByEval$`Fixed effects` <-
      gsub("[*]", "\\\\*", mod_comp$modelComp_MarksByEval$`Fixed effects`)
  mod_comp$modelComp_TimeByEval$`Fixed effects`  <-
      gsub("[*]", "\\\\*", mod_comp$modelComp_TimeByEval$`Fixed effects`)
}else{
  fmt      <- "latex"
  fnt      <- 10L
  mod_comp <- readRDS("./figures/ch4_tab1_model_comp_ls_latex.rds")
}
esc_comp <- FALSE ## Comparisons, with bolding 
esc_coef <- TRUE  ## Coefficients, with % and *

## Return
kableExtra::kbl(
  mod_comp[[1]], format = fmt, align = c("l", rep("l", 2), rep("c", 5)),
  booktabs = TRUE, linesep = "", escape = esc_comp,
  caption = "Model performance of random effect models regressing accuracy. Each model includes a random effect term of the participant explaining the individual's influence on accuracy. Complex models perform better in terms of $R^2$ and RMSE, yet AIC and BIC penalize their large number of fixed effects in favor of the much simpler model containing only the visuals. Conditional $R^2$ includes the random effects, while marginal does not.") %>%
  kableExtra::kable_classic(font_size = fnt)
```


<!-- Y1 coefficients of ABcd -->
```{r marksCoefTbl, fig.cap = "Use the caption arg in kable(), not this."}
mod_coef <- readRDS("./figures/ch4_tab2_model_coef_ls.rds")
## accuracy [[1]], log time [[2]]

## return
kableExtra::kbl(
  x = mod_coef[[1]], format = fmt, 
  booktabs = TRUE, linesep = "", escape = esc_coef,
  caption = "The task accuracy model coefficients for $\\widehat{Y} = \\alpha \\cdot \\beta + \\gamma + \\delta$, with visual = pca, location = 0/100\\%, shape = EEE, and dim = 4 held as baselines. Visual being radial is the fixed term with the strongest evidence supporting the hypothesis. Interacting with the location term there is evidence suggesting radial performs worse with 33/66\\% mixing.") %>%
  kableExtra::pack_rows("visual", 2, 3) %>%
  kableExtra::pack_rows("fixed effects", 4, 8) %>%
  kableExtra::pack_rows("interactions", 9, 12) %>%
  kableExtra::kable_classic(font_size = fnt)
```

<!-- Model selection and coefficients -->
Table \@ref(tab:marksCompTbl) compares the model summaries across increasing complexity. The $\alpha \cdot \beta + \gamma + \delta$ model to is selected to examine in more detail. Table \@ref(tab:marksCoefTbl) looks at the coefficients for this model.

<!-- Conditional effects of variables -->
We also want to visually examine the conditional variables in the model. Figure \@ref(fig:figMarksABcd) examines violin plots of accuracy by visual with panels distinguishing location (vertical) and shape (horizontal). Use of the radial tour, on average, increases the accuracy, and especially so when the location of signal mixing is not 33/66%.

<!-- Violin plots and test overlay for Y1 visuals -->
```{r, figMarksABcd, out.width="100%", fig.cap = "Violin plots of terms of the model $\\widehat{Y} = \\alpha \\cdot \\beta + \\gamma + \\delta$. Overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked-sum tests suitable for handling discrete data. Participants are more confident and find the radial tour easier to use than the grand tour. Participants claim low familiarity, as expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task."}
nsSafeIncGraphic("./figures/ch4_fig6_ABcd_violins.pdf")
```


### Subjective measures

<!-- Introduce subjective measures from n=84 survey responses -->
The 84 evaluations of the post-study survey also collect four subjective measures for each visual. Figure \@ref(fig:figSubjectiveMeasures) shows the Likert plots, or stacked percentage bar plots, alongside violin plots with the same non-parametric, ranked sum tests previously used. Participants preferred to use radial for this task. Participants were also more confident of their answers and found radial tours easier than grand tours. All visuals have reportedly low familiarity, as expected from crowdsourced participants.

```{r figSubjectiveMeasures, out.width="100%", fig.show="asis", fig.cap = "The subjective measures of the 84 responses of the post-study survey, five discrete Likert scale levels of agreement (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests."}
nsSafeIncGraphic("./figures/ch4_fig7_subjective_measures.pdf")
```


## Conclusion {#sec:conclusion}

<!-- Context -->
Data visualization is an integral part understanding relationships in data, and how models are fitted. However, thorough exploration of data in high dimensions becomes difficult. Previous methods offer no means for an analyst to impact the projection basis. The manual tour provides a mechanism for changing the contribution of a selected variable to the basis. Giving analysts such control should facilitate the exploration of variable-level sensitivity to the identified structure.

<!-- Recap study -->
This paper discussed a with-in participant user study ($n=108$) comparing the efficacy of three linear projection techniques. The participants performed a supervised cluster task, explicitly identifying which variables contribute to separating two target clusters. This was evaluated evenly over four experimental factors. In summary, mixed model regression finds strong evidence that using the radial tour leads to a sizable accuracy increase. In the extended analysis, there is significant evidence for a change in response time, with PCA being fastest, then the grand tour, followed by the radial tour. The effect sizes on accuracy are large relative to the change from the other experimental factors, though smaller than the random effect of the participant. The radial tour was subjectively preferred, leading to more confidence in answers, and increased ease of use than the alternatives.

<!-- Discussion and going further -->
There are several ways that this study could be extended. In addition to expanding the support of the experimental factors, more exciting directions include: changing the task, visualizations used, and experience level of the target population. It is difficult to achieve good coverage given the number of possible permutations. Keep in mind the traffic volume and low effort of responses from participants when crowdsourcing.



<!-- ## References -->

<!-- <div id="refs"></div> -->

<!-- Adds a bib section at the end of every chapter -->

<!--chapter:end:04-userstudy.Rmd-->

---
chapter: 5
knit: "bookdown::render_book"
---

# Exploring Local Explanations of Nonlinear Models Using the Radial tour {#ch-cheem}

<!-- Segue -->
In the previous chapter discussed the within-participants user study comparing PCA, the grand tour, and the radial tour in a supervised variable attribution task. There was strong evidence that the radial tour leads to large increase in accuracy. Now the analyst can be more confident that the radial tour leads to better analysis of variable-level attribution to features identified in a projection.

Given the interpretability crisis of nonlinear models, it would be interesting to see if the radial tour can help. Specifically, we will investigate using the radial tour to explore variable sensitivity to the structure identified in linear local explanations of nonlinear models. That is under what range of variable importance does an explanation make sense, and when does it fail to be supported by the data. This can provide insight into why an observation is misclassified or otherwise has an extreme residual. The radial tour can also test how susceptible a variable's contribution is to discerning the predictions of two observations.

<!-- Abstract -->
The increased predictive power comes at the cost of interpretability, which has led to the emergence of eXplainable AI (XAI). XAI attempts to shed light on how models use predictors to arrive at a prediction with a point estimate of the linear feature importance in the vicinity of each instance. These can be considered linear projections and can be further explored interactively to understand better the interaction between features used to make predictions across the predictive model surface. Here we describe interactive linear interpolation used for exploration at any instance and illustrate with examples with categorical (penguin species, chocolate types) and quantitative (football salaries, house prices) output. The methods are implemented in the __R__ package __cheem__, available on CRAN.

<!-- ## Introduction {#sec:intro} -->

<!-- Segue -->
Chapter \@ref(ch-background) introduced predictive modeling, the interpretability crisis of nonlinear models, and local explanations --- approximations of linear variable importance in the vicinity of one observation.<!-- chapter structure --> The remainder of this chapter is organized as follows. The following Section, \@ref(sec:shap), induces the SHAP and tree SHAP local explanation. Section \@ref(sec:tour) explains the animations of continuous linear projections. Section \@ref(sec:cheemviwer) discusses the visual layout in the interactive interface, how they facilitate analysis, data preprocessing, and package infrastructure. Then Section \@ref(sec:casestudies) illustrates the application to supervised learning with categorical and quantitative output. Section \@ref(sec:cheemdiscussion) concludes with the insights gained and directions that might be explored in the future.


## SHAP and tree SHAP local explanations {#sec:shap}

<!-- SHAP -->
SHaply Additive exPlanations (SHAP) quantifies the feature contributions of one instance by examining the effect of other features on the predictions. The explanations of SHAP almost all refer to @shapley_value_1953's method to evaluate an individual's contribution to cooperative games by assessing the performance of this player in the presence or absence of other players. @strumbelj_efficient_2010 introduced the use of SHAP for local explanations in ML models. The attribution of feature importance depends on the sequence of the included features. The SHAP values are the mean contributions over different feature sequences. The approach is related to partial dependence plots [@molnar_interpretable_2020], used to explain the effect of a feature by predicting the response for a range of values on this feature after fixing the value of all other features to their mean. Partial dependence plots are a global approximation of the feature importance, while SHAP is specific to one instance. It could also be considered similar to examining the coefficients from all subsets regression, as described in @wickham_visualizing_2015, which helps to understand the relative importance of each feature in the context of all other candidate features.

```{r shapdistrbd, echo=F, fig.align='center', out.width="100%", fig.cap = "Illustration SHAP values for a random forest model FIFA 2020 player wages from nine skill predictors. A star offensive and defensive player are compared, L. Messi and V. van Dijk, respectively. Panel (a) shows breakdown plots of three sequences of the features, order, and magnitude change. Panel (b) shows the distribution of attribution for each feature across 25 sequences of predictors, with the mean displayed as a dot for each player. Offense and movement are important for Messi but not van Dijk, and conversely, defense and power are important for van Dijk but not Messi."}
nsSafeIncGraphic("./figures/ch5_fig1_shap_distr_bd.png")
```

<!-- tree SHAP -->
For the application, we use _tree SHAP_, a variant of SHAP that enjoys a lower computational complexity [@lundberg_consistent_2018]. Instead of aggregating over sequences of the features, tree SHAP calculates instance-level feature importance by exploring the structure of the decision trees. Tree SHAP is only compatible with tree-based models; random forests are used for illustration. The following section will use normalized SHAP values as a projection basis (call this the _attribution projection_) will have coefficients varied to further scrutinize the feature contributions.

<!-- Fifa example -->
Following the use case _Explanatory Model Analysis_ [@biecek_explanatory_2021], FIFA data is used to illustrate SHAP use. Consider soccer data from the FIFA 2020 season [@leone_fifa_2020]. There are 5000 instances of 9 skill measures (after aggregating highly correlated features). A random forest model is fit, regressing player's wages [2020 Euros] from their skill measurements. The SHAP values are compared for a star offensive player (L. Messi) and defensive player (V. van Dijk). The results are displayed in Figure \@ref(fig:shapdistrbd). A difference in the attribution of the feature importance across the two positions of the players can be expected. This would be interpreted as how the player's salary depends on this combination of skill sets. Plot (b) is a modified breakdown plot [@gosiewska_ibreakdown_2019] where the order of features is fixed, so the two instances can be more easily compared.

<!-- Segue -->
In summary, these plots highlight how local explanations bring interpretability to a model, at least in the vicinity of their instances. In this instance, two players with different positions receive different profiles of feature importance to explain the prediction of their wages.

<!-- ## Tours and the radial tour {#sec:tour} -->
<!-- Moved to ch2-background -->

## The cheem viewer {#sec:cheemviwer}

To explore the local explanations, an ensemble of plots [@unwin_ensemble_2018] is provided, called the _cheem viewer_. There are two primary plots: the __global view__ to give the context of all of the SHAP values, and the __radial tour view__ to explore the local explanations with user-controlled rotation. In addition, there are numerous user inputs, including feature selection for the radial tour and instance selection for making comparisons. There are different plots used for the categorical and quantitative responses. Figures \@ref(fig:classificationcase) and \@ref(fig:regressioncase) are screenshots showing the cheem viewer for the two primary tasks: classification (categorical response) and regression (quantitative response).


### Global view

<!-- Purpose -->
The global view provides the context of all instances and facilitates the exploration of the separability of the data- and attribution-spaces. Both of these spaces are of dimension $n\times p$, where $n$ is the number of instances and $p$ is the number of predictors. The attribution space corresponds to the local explanations for each instance, each a vector of $p$ values.

<!-- Approximations of the spaces, PC1:2 -->
A visualization is provided by the first two principal components of the data (left) and the attribution (middle) spaces. These single 2D projections will not reveal all of the structure of higher-dimensional space, but they are useful visual summaries. In addition, a plot of the observed against predicted response values is also provided (Figures \@ref(fig:classificationcase)b, \@ref(fig:regressioncase)a), to help identify instances poorly predicted by the model. <!-- Interactions --> For classification tasks, misclassified instances are circled in red if applicable. Linked brushing between the plots is provided, and a tabular display of selected points helps to facilitate exploration of the spaces and the model (shown in Figures \@ref(fig:classificationcase)a,c).

While the comparison of these spaces is interesting, a main purpose of the global view is to enable the selection of instances to explore the local explanations. The projection attribution of the primary instance (PI) is examined and typically viewed with an optional comparison instance (CI). These instances are highlighted as asterisk and $\times$, respectively.


### Radial tour

<!-- Local explanations as par coords -->
The local explanations for all observations are normalized (squared sum of values adds to 1), and thus, the relative importance of features can be compared across all instances. These are depicted as a vertical parallel coordinate plot, where each line connects one instance's feature attribution (Figures \@ref(fig:classificationcase)e and \@ref(fig:regressioncase)e). The attribution projections of the PI and CI are shown as dashed and dotted lines, respectively. From this plot,the range of importances across all instances can be interpreted. For classification, one would look at differences between groups on any feature. For example, Figure \@ref(fig:classificationcase)e suggests that `bl` is important for distinguishing the green class from the other two. For regression, one might generally observe which features have low values for all instances (not important), for example, `BMI` and `pwr` in Figure \@ref(fig:regressioncase)e, and which have a range of high and low values (e.g. `off`, `def`) suggesting important for some instances and not important for other instances.


<!-- Segue of PI to attribution projection -->
The overlaid bars on the parallel coordinate plot represent the attribution projection of the PI. (Remember that the PI is interactively selected from the global view). The attribution projection is an  approximation of the feature importance for the prediction of this instance. This combination of features best explains the difference between the mean response and an instance’s predicted value. It is not an indication of the local shape of the model surface. That is, it is not some indication of the tangent to the curve at this point.

<!-- Tour animation -->
The attribution projection of the PI is the initial 1D basis in a radial tour, displayed as a density plot for a categorical response (Figure \@ref(fig:classificationcase)f), and as scatterplots for a quantitative response (Figure \@ref(fig:regressioncase)f). The PI and CI are indicated by vertical dashed and dotted lines, respectively. The user uses the radial tour to vary the contribution of the selected feature between 0-1. Doing so tests the sensitivity of structure (class separation or strength of relationship) to the feature's contribution. For classification, if the separation between classes diminishes when the feature contribution is reduced then this suggests that the feature is important for the class separation. For regression, if the relationship scatterplot weakens when the feature contribution is reduced then this suggests that the feature is important for accurately predicting the response. <!-- The default feature selected has the largest discrepancy between the attribution of the PI and CI. The data (scaled by standard deviation away from the mean) is projected through the current basis --- the horizontal position of Fig. \@ref(fig:classificationcase) f and Fig. \@ref(fig:regressioncase) f.-->


### Classification task

Selecting a misclassified instance as PI and a correctly classified point nearby in data space as CI makes it easier to examine the features most responsible for the error. The global view (Figure \@ref(fig:classificationcase)c) displays the model confusion matrix. The radial tour is 1D, plotted as a density where color indicates class. A scroll bar here enables the user to vary the contribution of each feature to explore the sensitivity of the separation to that feature.

```{r classificationcase, echo=F, out.width = "100%", fig.align="center", fig.cap = "Overview of the cheem viewer for classification tasks. Global view inputs, (a), set the PI, CI, and color statistic. Global view, (b) PC1 by PC2 approximations of the data space and attribution space. (c) prediction by observed y (visual of the confusion matrix for classification tasks). Points are colored by predicted class, and red circles indicate misclassified instances. Radial tour inputs (d) select features to include and which feature is changed in the tour. (e) shows a parallel coordinate display of the distribution of the feature attributions while bars depict contribution for the current basis. The black bar is the variable being changed in the radial tour. Panel (f) is the resulting projection of the data indicated as density in the classification case."}
nsSafeIncGraphic("./figures/ch5_fig2_app_classification.PNG")
```


### Regression task

Selecting an inaccurately predicted instance as PI and an accurately predicted instance, with similar feature values, as CI is a useful way to understand how the model is failing or not. The global view (Figure \@ref(fig:regressioncase)a) shows a scatterplot of the observed vs predicted values, which should exhibit a strong relationship if the model is a good fit. The points can be colored by a statistic, residual, a measure of outlyingness (log Mahalanobis distance), or correlation, to help with understand where the model fits better or worse.

In the radial tour view, the observed response and the residuals (vertical) are plotted against the attribution projection of the PI (horizontal). The attribution projection can be interpreted similarly to the predicted value from the global view plot. It represents a linear combination of the features, and a good fit would be indicated when there is a strong relationship seen with the observed values. This can be viewed as a local linear approximation if the fitted model is nonlinear. As the contribution of a feature is varied, if the value of the PI does not change much, it would indicate that the prediction for this instance is NOT sensitive to that feature. Conversely, if the predicted value varies substantially, the prediction is very sensitive to that feature, suggesting that the feature is very important for the PI's prediction.

```{r regressioncase, echo=F, out.width="100%", fig.cap="Overview of the cheem viewer for regression task highlighting the differences from the classification task and interactive features. Panel (a) PCA of the data and attributions spaces, (b), residual plot, predictions by observed values. Four points are selected points and highlighted in the PC spaces and tabularly displayed. Coloring on a statistic (c) highlights structure organized in the attribution space. Interactive tabular display (d) populates when instances are selected. Contribution of the 1D basis affecting the horizontal position (e) parallel coordinate display of the feature attribution from all observations, and horizontal bars show the contribution to the current basis. Regression projection (f) uses the same horizontal projection and fixes the vertical positions to the observed y and residuals (left and right)."}
nsSafeIncGraphic("./figures/ch5_fig3_app_regression_interactions.PNG")
```


### Interactive features

<!-- Reactive vs exploration interactions -->
The application has several reactive inputs that affect the data used, aesthetic display, and tour manipulation. These reactive inputs make the software flexible and extensible. The application also has more exploratory interactions to help link points across displays and reveal structure found in different spaces.

<!-- Exploratory interactions -->
A tooltip displays instance number/name and classification information while the cursor hovers over a point. Linked brushing allows the selection of points (left click and drag) where those points will be highlighted across plots. The information corresponding to the selected points is populated on a dynamic table. These interactions aid exploration of the spaces and, finally, identification of a primary and comparison instance.


### Preprocessing

It is vital to mitigate the render time of visuals, especially when users may want to iterate many times. All computational operations should be prepared before runtime. The work remaining when an application is run solely reacts to inputs and rendering visuals and tables. Below discusses the steps and details of the reprocessing.

(ref:citeRf) [@liaw_classification_2002]
(ref:citeTs) [@kominsarczyk_treeshap_2021]
\begin{itemize}
	\item \textbf{Data:} predictors and response are unscaled complete numerical matrix. Most models and local explanations are scale-invariant.
	\item \textbf{Model and explanation:} any model can be used with this method. Currently, random forest models are applied via the package \textbf{randomForest} (ref:citeRf), compatibility tree SHAP. Modest hyperparameters are used, namely: 125 trees, number features randomly sampled at each split, mtry = $\sqrt{p}$ or $p/3$ for classification and regression, and minimum size of terminal nodes $max(1, n/500)$ or $max(5, n/500)$ for classification and regression. Tree SHAP is calculated for \emph{each} instance using the package \textbf{treeshap} (ref:citeTs). This implementation aggregates exhaustively over all trees' attribution, and do not to fit interactions of features. 
	\item \textbf{Cheem view:} after the model and full explanation space are calculated,each feature is scaled by standard deviations away from the mean to achieve common support for visuals. Statistics for mapping to color are computed on the scaled spaces. Interactive tabular display reports the original values.
\end{itemize}

<!-- Note on time of execution -->
The time to preprocess the data will vary significantly with the model and local explanation. For reference, the FIFA data, 5000 instances of nine explanatory features, took 2.5 seconds to fit a random forest model of modest hyperparameters. Extracting the tree SHAP values of each instance took 270 seconds combined. PCA and statistics of the features and attributions took 2.8 seconds. These runtimes were from a non-parallelized R session on a modern laptop, but suffice to say that most of the time will be spent on the local attribution. An increase in model complexity or data dimensionality will quickly become an obstacle. Its reduced computational complexity makes tree SHAP a good candidate to start. (Alternatively, the package __fastshap__ [@greenwell_fastshap_2020] claims extremely low runtimes, attributed to fewer calls to the prediction function, partial implementation in C++, and efficient use of logical subsetting.)


### Package infrastructure {#sec:infrastructure}

The above-described method and application are implemented as an open-source __R__ package, __cheem__ available on [CRAN](https://CRAN.R-project.org/package=cheem). Preprocessing was facilitated with models created via __randomForest__ [@liaw_classification_2002] and explanations calculated with __treeshap__ [@kominsarczyk_treeshap_2021]. The application was made with __shiny__ [@chang_shiny_2021]. The tour visual is built with __spinifex__ [@spyrison_spinifex_2020]. Both views are created first with first with __ggplot2__ [@wickham_ggplot2_2016] and then rendered as interactive `html` widgets with __plotly__ [@sievert_interactive_2020]. __DALEX__ [@biecek_dalex_2018] and the free ebook, _Explanatory Model Analysis_ [@biecek_explanatory_2021] were a huge boon to understanding local explanations and how to apply them.


### Installation and getting started

The package can be installed from GitHub using the following __R__ code:

```{r eval=FALSE, echo=TRUE}
# Install remotes if absent
if(require("remotes") == FALSE) install.packages("remotes")
remotes::install.packages("cheem", dependencies = TRUE)
library("cheem")
run_app()
```

To process your own data, you will need to use the `treeshap` package, which can be installed from GitHub:

```{r eval=FALSE, echo=TRUE}
remotes::install_github('ModelOriented/treeshap')
```

Follow the examples provided with the package to compute the local explainers, (see `?cheem_ls`). The application expects the return of call from `cheem_ls()` which is then saved to an .rds file with `saveRDS()`. Alternatively, the cheem viewer shiny app can be directly accessed at [ebsmonash.shinyapps.io/cheem_initial/](https://ebsmonash.shinyapps.io/cheem_initial/).


## Case studies {#sec:casestudies}

To illustrate the use of the cheem method, it is applied to modern datasets, two classification examples and then two of regression.


### Palmer penguin, species classification

The Palmer penguins data [@gorman_ecological_2014; @horst_palmerpenguins_2020] was collected on three species of penguins foraging near Palmer Station, Antarctica. The data was publicly available to substitute for the overly-used iris data and is quite similar in form. After removing incomplete instances, there are 333 instances of four physical measurements, bill length (`bl`), bill depth (`bd`), flipper length (`fl`), body mass (`bm`), for this illustration. A random forest model was fit with species as the response feature.

(ref:casepenguins) Examining the SHAP values for a random forest model classifying Palmer penguin species. The PI is a Gentoo (purple) Chinstrap (orange) penguin that is misclassified as a Chinstrap (orange), marked as an asterisk in (a), and the dashed vertical line in (b). The radial view shows varying the contribution of `fl` from the initial attribution projection (b, left), which produces a linear combination where the PI is more probably (higher density value) a Chinstrap than a Gentoo (b, right). (The animation of the radial tour is at [vimeo.com/666431172](https://vimeo.com/666431172).)
```{r casepenguins, echo=F, out.width="100%", fig.cap = "(ref:casepenguins)"}
nsSafeIncGraphic("./figures/ch5_fig4_case_penguins.png")
```

Figure \@ref(fig:casepenguins) shows plots from the cheem viewer for exploring the random forest model on the penguins data. Panel (a) shows the global view, and panel (b) shows several 1D projections generated with the radial tour. Penguin 243, a Gentoo (purple), is the PI because it has been misclassified as a Chinstrap (orange).

(ref:casepenguinsblfl) Checking what is learned from the cheem viewer. This is a plot of flipper length (`fl`) and bill length (`bl`), where an asterisk highlights the PI. A Gentoo (purple) misclassified as a Chinstrap (orange). The PI has an unusually small `f_l` length which is why it is confused with a Chinstrap.
```{r casepenguinsblfl, echo=F, out.width="100%", fig.cap = "(ref:casepenguinsblfl)"}
nsSafeIncGraphic("./figures/ch5_fig5_case_penguins_BlFl.png")
```

There is more separation visible in the attribution space than the data space, as would be expected. The predicted vs observed plot reveals a handful of misclassified instances. A Gentoo has been wrongly labeled as a Chinstrap is selected for illustration. The PI is a misclassified point (represented by the asterisk in the global view and a dashed vertical line in the tour view). The CI is a correctly classified point (represented by an $\times$ and a vertical dotted line).

The radial tour starts from the attribution projection of the misclassified instance (b, left). The important features identified by SHAP in the (wrong) prediction for this instance are mostly `bl` and `bd` with small contributions of `fl` and `bm`. This projection is a view where the Gentoo (purple) looks much more likely for this instance than Chinstrap. That is, this combination of features is not particularly useful because the PI looks very much like other Gentoo penguins. To explore this, the radial tour is used to vary the contribution of flipper length (`fl`). (In our exploration, this was the third feature explored. It is typically useful to explore the features with larger contributions, here `bl` and `bd`, but when doing this, nothing was revealed about how the PI differed from other Gentoos). On varying `fl` as it contributes more to the projection (b, right), more, and more, this penguin looks like a Chinstrap. This suggests that `fl` should be considered an important feature for explaining the (wrong) prediction.

Figure \@ref(fig:casepenguinsblfl) confirms that flipper length (`fl`) is important for the confusion of the PI as a Chinstrap. Here, flipper length and body length are plotted, and  the PI can be seen to be closer to the Chinstrap group in these two features, mostly because it has an unusually low value of flipper length relative to other Gentoos. From this view, it makes sense that its a hard instance to account for as decision trees can only partition only vertical and horizontal lines.


### Chocolates, milk/dark chocolate classification


The chocolates dataset consists of 88 instances of ten nutritional measurements determined from their labels and labeled as either milk or dark. Dark chocolate is considered healthier than milk. The data was collected by students during the Iowa State University class STAT503 from nutritional information from the manufacturer's website and normalized to 100g equivalents. The data is available in the __cheem__ package. A random forest model is used for the classification of chocolate type.

It could be interesting to examine the nutritional properties of any dark chocolates that have been misclassified as milk. A reason to do this is that a dark chocolate nutritionally more like milk should not be considered a healthy alternative. It is interesting to explore which of the nutritional features contribute most to misclassification.

(ref:casechocolates) Examining the local interpretation for a PI which is dark (orange) chocolate incorrectly predicted to be milk (green). From the attribution projection, this chocolate correctly looks more like dark more than milk, which suggests that the local explanation does not help understand the prediction for this instance. So, the contribution of Sugar is varied -- reducing it corresponds primarily with increasing Fiber. When Sugar is zero, Fiber is contributing strongly towards the left. In this particular view, the PI is closer to the bulk of the milk chocolates, suggesting that the prediction put a lot of importance on Fiber. This chocolate is a rare dark chocolate without any Fiber leading to it being mistaken for a milk chocolate. (A video of the tour animation can be found at [vimeo.com/666431143](https://vimeo.com/666431143).)
```{r casechocolates, echo=F, out.width="100%", fig.cap = "(ref:casechocolates)"}
nsSafeIncGraphic("./figures/ch5_fig6_case_chocolates.png")
```

This type of exploration is shown in Figure \@ref(fig:casechocolates), where a chocolate labeled dark but predicted to be milk is chosen as the PI (instance 22). It is compared with a CI that is a correctly classified dark chocolate (instance 7). The PCA plot, and the tree SHAP PCA plots (a) show a big difference between the two chocolate types but with confusion for a handful of instances. The misclassifications are more apparent in the observed vs predicted plot, and can be seen to be mistaken in both ways: milk to dark and dark to milk.

The attribution projection for chocolate 22 suggests that Fiber, Sugars, and Calories are most responsible for its incorrect prediction. The way to read this plot is to see that Fiber has a large negative value while Sugars and Calories have reasonably large positive values. In the density plot, instances on the very left of the display would have high values of Fiber (matching the negative projection coefficient) and low values of Sugars and Calories. The opposite would be interpreting a point with high values in this plot. The dark chocolates (orange) are mostly on the left, and this is a reason why they are considered to be healthier: high fiber and low sugar. The density of milk chocolates is further to the right, indicating that they generally have low fiber and high sugar.

The instance of interest (dashed line) can be viewed against the comparison instance (dotted line). Now one needs to pay different attention to the parallel plot of the SHAP values, which are local to a particular instance, and the density plot, which is the same projection of all instances as specified by the SHAP values of the instance of interest.

The feature contributions to the two different predictions can be quickly compared in the parallel coordinate plot. The instance of interest differs with the comparison primarily on the Fiber feature, which suggests that this is the reason for the incorrect prediction.

From the density plot, which is the attribution projection corresponding to the instance of interest, both instances are more like dark chocolates. Varying the contribution of Sugars and altogether removing it from the projection, is where the difference becomes apparent. When primarily Fiber is examined, instance 22 looks more like a milk chocolate.

(ref:casechocolatesinverse) Examining the local interpretation for a PI which is milk (green) chocolate incorrectly predicted to be dark (orange). In the attribution projection, the PI could be either milk or dark. Sodium and Fiber have the largest differences in attributed feature importance, both with low values relative to other milk chocolates. The lack of use of these variables is suspected to contribute to the mistake, so the contribution of Sodium is varied. If Sodium had a larger contribution to the prediction (like in this view). the PI would look more like other milk chocolates. (A video of the tour animation can be found at [vimeo.com/666431148](https://vimeo.com/666431148).)
```{r casechocolatesinverse, echo=F, out.width="100%", fig.cap = "(ref:casechocolatesinverse)"}
nsSafeIncGraphic("./figures/ch5_fig7_case_chocolates_inverse.png")
```

<!-- segue and selection for chocolates inverse case -->
It would also be interesting to explore the inverse case. This would describe which features lead to a milk chocolate being misclassified as dark and how those attributions differ from the previous misclassification. Chocolate 84 is just this case, and is compared with a correctly predicted milk chocolate (instance 71). This exploration is shown in Figure \@ref(fig:casechocolatesinverse).

<!-- treeSHAP pca, PCP, tour -->
The difference of position in the tree SHAP PCA with the previous case is quite large; this gives an approximate feel that the attribution should be quite different. Looking at the initial contribution, this is found to be the case. Previously Fiber was very important while it is absent from the attribution in this case. Conversely, Calories from Fat and Total Fat are highly attributed here, while unimportant in the preceding case.

Comparing the attribution with the CI (dotted line), discrepancies in Sodium and Fiber are identified. The contribution of Sodium is selected to be varied. The instance looks slightly more like its observed milk than predicted dark chocolate even in the initial projection. The misclassification appears least supported when the basis reaches sodium attribution of typical dark chocolate.


### FIFA, wage regression

The 2020 season FIFA data [@leone_fifa_2020; @biecek_dalex_2018] contains many skill measurements of soccer/football players and wage information. From a correlation matrix plot, nine higher-level skill groupings were identified and aggregated. A random forest model if fit from these aggregations and regress player wages [2020 euros]. The model was fit from 5000 instances before being thinned to 500 players to mitigate occlusion and render time. Continuing from the exploration in section \@ref(sec:explanations), we are interested to see the difference in attribution based on the exogenous player position. That is, the model should be able to use multiple linear profiles to better predict the wages from different field positions of players. A leading offensive fielder (L. Messi) is compared with that of a top defensive fielder (V. van Dijk). The same instances were used in figure \@ref(fig:shapdistrbd).

(ref:casefifa) FIFA 2020 data, a random forest model, regresses wages [2020 Euros] from nine aggregated skill measurements. The PI is a star offensive player (L. Messi) compared with a top defensive player (V. van Dijk). Three features with low attribution from both players are removed. The attribution projection starts with the selected instance on the right. The contribution to defense (`def`) is varied. The star offensive player is not distinguished in the horizontal direction. At this point, defensive players have been rotated to the highest horizontal value. (A video of the animated radial tour can be found at [vimeo.com/666431163](https://vimeo.com/666431163).)
```{r casefifa, echo=F, out.width = "100%", fig.cap = "(ref:casefifa)"}
nsSafeIncGraphic("./figures/ch5_fig8_case_fifa.png")
```

With figure \@ref(fig:casefifa), tests the support of the local explanation. Offensive and reaction skills (`off` and `rct`) are both crucial to explaining a star offensive player. If either of them were rotated out, the other will be rotated into frame, maintaining a far-right position. However, when varying the defensive skills, the other skills are rotated out of the frame.

As the contribution of defensive skills increases, Messi's is no longer separated from the group. Players with high values in defensive skills are now the rightmost points. In terms of what-if analysis, the difference between the data mean and his predicted wages would be halved if Messi's tree SHAP attributions at these levels.


### Ames housing 2018, sales price regression

Ames 2018, housing data was subset to North Ames (the neighborhood with the most house sales). The remaining are 338 house sales. A random forest model has regressed this price with the features Lot Area (`LtA`), Overall Quality (`Qlt`), Year the house was Built (`YrB`), Living Area (`LvA`), number of Bathrooms (`Bth`), number of Bedrooms (`Bdr`), total number of Rooms (`Rms`), Year the Garage was Built (`GYB`), and Garage Area (`GrA`). Using interaction from the global view, a house with an extreme negative residual and an accurate instance with similar prediction are selected.

(ref:caseames) Exploring an instance with a large residual as the PI from fitting sales price [USD] to other variables in the Ames housing 2018. The sale price of the PI was under-predicted. The local explanation indicates a sizable attribution to Lot Area (`LtA`). The CI has a similar predicted sales price and smaller residual and has minimal attribution to Lot Area. In the attribution projection, the PI has a higher sales price than the CI. Reducing the contribution of lot area brings these two prices in line. This suggests if the model did not consider Lot Area, then the two houses would be quite similar. That is, the large residual is due to a lack of factoring in the lot area for the prediction of PI's sales price. (A video showing the animation is at [vimeo.com/666431134](https://vimeo.com/666431134).)
```{r caseames, echo=F, out.width="100%", fig.cap = "(ref:caseames)"}
nsSafeIncGraphic("./figures/ch5_fig9_case_ames2018.png")
```

Figure \@ref(fig:caseames) selects the house sale 74, a sizable under prediction with a large Lot Area contribution. The CI has a similar predicted price though the prediction was accurate and gives almost no attribution to lot size. The attribution projection is places instances with high Living Areas to the right. The contribution of Living Area control the contribution of this feature. As the contribution of lot area decreases, the predictive power decreases for the PI, while the CI remains stationary. This large of importance in the Living Area is relatively uncommon. Boosting tree models may be more resilient to such an under-prediction as up-weighting this residual would force its inclusion in the final model.


## Discussion {#sec:cheemdiscussion}

New tools to assist with the interpretability of black-box models is increasingly important. This chapter provides a technique that builds on local interpretations to explore the feature importance local to an instance. The local interpretations form an attribution projection from which feature contributions are varied using a radial tour. Several diagnostic plots are provided to assist with understanding the sensitivity of the prediction to particular features. A global view shows the data space, explanation space, model fit. The user can interactively select instances to compare, contrast, and study further.

The approach has been illustrated on four data examples using random forest models and using the tree SHAP local explanation. In the penguins example, we showed how the misclassification of a penguin arose due to it having an unusually small flipper size compared to others of its species. This was verified by making a follow-up plot of the data, including this variable. The chocolates example shows how a dark chocolate was misclassified primarily due to it value on Fiber, and a milk chocolate was misclassified as dark due to its lowish Sodium value. For the FIFA example, we show how low Messi's salary would be if it depended on defensive skills. In the Ames housing data, an inaccurate prediction for a house was likely due to the Lot Area not being effectively used.

The approach is manually intensive and thus only feasible for investigating a few instances. The approach is to select instances that the model has not done well and compare it with an instance where it did fit well.  The radial tour launches from the attribution projection to enable exploration of the sensitivity of the prediction to any feature. It can be helpful to make additional plots of the features and responses in order to cross-check interpretations made from the cheem viewer. This methodology provides an additional tool in the box for studying model fitting.

An implementation is provided in the open-source __R__ package __cheem__, available on [CRAN](https://CRAN.R-project.org/package=cheem). Example data sets are provided, and you can upload your data after model fitting and computing the local explanations. In theory, this approach would work with any black-box model but the implementation currently only calculates tree SHAP for tree-based models supported by __treeshap__ (tree based models from __randomForest__, __ranger__, __gbm__, __xgboost__, __lightgbm__, or __catboost__). Tree SHAP was selected because of its computational efficiency. The SHAP and oscillation explanations could be added with the use of the `DALEX::explain()` and would be an excellent direction to extend the work [@biecek_dalex_2018; @biecek_explanatory_2021].

<!-- Attribution space does tend to be more separable than data space at least in the first couple principal components. Different statistics should be explored to convey a clearer understanding what structure the explanation distinguishes. It is curious that the attribution space the same dimensionality of the data with a seemingly better separation. It sounds like a candidate to fit another model. However, such an attempt should want to be vigilant not to over-fit the training data.-->


<!-- ## References -->

<!-- <div id="refs"></div> -->

<!-- Adds a bib section at the end of every chapter -->

<!--chapter:end:05-cheem.Rmd-->

---
chapter: 6
knit: "bookdown::render_book"
---

# Conclusion {#ch-conclusion}

<!-- Summary of work and importance -->
Most data are multivariate. This thesis makes important contributions to interactive visualization of data where all variables are quantitative. The methods are built on dynamic animation of linear projections, called tours. The thesis developed the radial tour, illustrating that it improved understanding variable importance in higher dimensional data and can be used to better understand black-box models for XAI.

<!-- Context -->
<!--  We know that visualizing data is more robust than numerical summarization alone. It allows the analyst to get a feel for the data rapidly, check for erroneous values, and confirm model assumptions. But visualizing data spaces becomes increasingly complex as dimensionality increases. Static linear dimension reduction has been widely used to extend the dimensionality of spaces viewed. Dynamic animations of linear projections, tours, further increase the perceptible information of linearly reduced spaces. Manual tours novelly allow the analyst to steer contributions of the basis. The work outlined in this thesis makes several contributions to multivariate data visualization focusing on manual tours. -->

<!-- Chapter \@ref(ch-spinifex) introduced the __spinifex__ package, which facilitates user-controlled manual tours and layered composition and exporting animations of any tour, interoperable with __tourr__. The radial, manual tour sizably improves the accuracy on a variable attribution in a cluster separation task compared with PCA and the grand tour. Chapter \@ref(ch-userstudy) covers the within-participants user study that led to this conclusion. Finally, I apply the radial tour to increase the interpretability of nonlinear models by using it to explore the support of local explanations in the package __cheem__ is discussed in Chapter \@ref(ch-cheem). -->


## Contributions

The contributions of this thesis can be split into scientific knowledge and software.


### Scientific knowledge

<!-- spinifex -->
Chapter \@ref(ch-spinifex) clarifies the radial tour methodology, specifically the use of Rodrigues' rotation formula [@rodrigues_lois_1840] to solve the rotation matrix with the definition for 1 and 2D tours. This sets up a scaffolding to extend the manual tour to three dimensions with another rotation angle to span the manipulation space. This work also supports manual tours by illustrating use cases on several high-energy physics data sets.

<!-- user study -->
Chapter \@ref(ch-userstudy), defines a task and accuracy measure for a variable attribution of the separation of two clusters. The $n=108$ crowdsourced user study compares the performance from PCA, the grand tour, and the radial tour. This is measured across three experimental factors of the data simulation. Mixed model regression finds considerable evidence for a sizable improvement in accuracy from the radial tour, which participants also subjectively prefer.

<!-- cheem -->
Chapter \@ref(ch-cheem) covers cheem analysis. This extends the interpretability of nonlinear models by exploring local explanation with the radial tour. The global view gives a full observation summary of data space, attribution space, and residual plot side-by-side as an coordinated view. From this, an analyst identifies a primary observation to explore the explanation in detail. The normalized attribution this point becomes the starting basis for a radial tour. By vary the contributions of variables, an analyst tests the contribution's sensitivity to the predictive power identified in the explanation. We provide usage and discussion from four contemporary datasets.


### Software

<!-- spinifex -->
The __R__ package __spinifex__ facilitates the creation of manual tours, which allow an analyst control over the contributions of a variable. It handles data transformations and the identification of various starting bases. It creates a framework for the layered display of tours interoperable with the __tourr__ package. Building the geometric display will feel at home to __ggplot2__ users. After composition, tours can be animated and exported as interactive `html` widgets or fixed animations as `gif`, or `mp4` files. Vignettes and an interactive application help users rapidly understand the concepts of facilitated work. The impact of __spinifex__ can be seen in two ways. My contributions to __spinifex__ and __tourr__ won the ACEMS Impact and Engagement Award, 2018. Furthermore, the package is available on [CRAN](https://CRAN.R-project.org/package=spinifex) with vignettes and version notes on its [pkgdown](https://nspyrison.github.io/spinifex/) site. It has been downloaded over 14,400 times from CRAN between 09 April 2019 and 28 November 2021.

<!-- cheem -->
The __cheem__ package facilitates the tree SHAP local explanations from tree-based models. Given a compatible model, functions perform the preprocessing to calculate the local explain of all observations with several statics that help describe the separability of data and attribution space. This processed object then feeds two novel visuals. The global view helps analysts interactively identify an observation to look at in more detail. A custom display of the radial tour then helps to evaluate the sensitivity of the variable contributions to the structure identified in the explanation. An interactive graphical user interface uses these visuals to facilitate the outlined cheem analysis. Several
preprocess datasets are included and also allows analysts to upload their data after processing. This package was recently uploaded to [CRAN](https://CRAN.R-project.org/package=cheem) and has a corresponding [pkgdown site](https://nspyrison.github.io/cheem/).


## Limitations

Below, we discuss a number of limitations with this work in chapter order. The following section echos this order and discusses possible directions to address these limitations.

<!-- 1_Manual tours in 1- & 2D -->
Manual tours (and radial tours) are limited in several ways. For instance, the work currently lists rotation matrices for 1- and 2D manual tours.<!-- 2_only 1var at a time--> Another limitation is that they only change one variable at a time. This can be cumbersome and timely if many variables need to be zeroed or otherwise changed.<!-- 3_Ink tank display --> The radial tour moves in three segments (full contribution-no contribution-initial contribution). It may be more approachable to directly relate the fraction of the slider to the magnitude of the variable's contribution.

<!-- __spinifex, layered composition -->
<!-- 4_Layered tour composition --> 
Setting aside the manual tour, there are several extensions to the layered composition of tours in __spinifex__, such as extending the type of geometric display. Because the manual tour is currently defined for $d \in [1,2]$ projections, the geometric display for $d>2$ __tourr__-made tours are under-supported.<!-- 5_Sterescopic 3D & XR --> Most tour implementations are made with 2D monitors in mind. It would be nice to have implementations for extended reality with a stereoscopic head-mounted display.

<!-- 6_User study -->
The user study evaluating the radial tour has several intrinsic limitations. It only considered discrete 2d PCA, grand tour, and the manual tour for supervised cluster separation for various levels of experimental factors affecting the data.
<!-- >> 7_Pedagogical side of manual tours for newcomers; not on limitation side, mention more on the future work side. -->

<!--8_cheem, and model/explanation types-->
The cheem analysis was illustrated on random forest models using the tree SHAP explanations. The __cheem__ package handles several other tree-based models, though the analysis should be generalized to a wider base of models and compatible explanations.<!--9_data:quantitative matrices--> We also focus on quantitative matrices. This could be generalized to accommodate text, image, or time-series data.<!--10_Extending explanations and a user study-->
There is also no comparison evaluating the value of cheem analysis. It would be interesting to measure the benefit of cheem over local explanations or other observation-level evaluations of a model. 


## Future work

This section purposes possible directions to address or extend from the limitations outlined above.

<!-- __Manual tours -->
<!-- 1_3D manual tour -->
Chapter \@ref(ch-spinifex) included the scaffolding to extend manual tours beyond 2D. Namely, this would require the use Rodrigues' rotation formula [@rodrigues_lois_1840] to defining another angle of rotation. The 3D projection would initialize a 4D manipulation space and use three input angles to control the contribution in the first three components. Another display dimension may benefit the detection and understanding of the higher dimensional structure, while we would also expect longer interaction time and less intuitive input.

<!-- 2_Manipulating multiple variables -->
In addition to the manual tour controlling the contribution of a single variable, it may be insightful to change the contributions of several variables at once (effectively manipulating a linear combination of variables). This may increase manipulation speed or prove to be unintuitive to input. Alternatively, an automated approach may help clean up variables with small contributions. A sort of dimension "reduction tour", could append several manual tours that sequentially zero the contributions of variables contributing less than some threshold, which may prove to expedite analysis, especially for approaching a feature's intrinsic dimensionality. This approach may be better as an initialization step before render time. This would abstract away some of the business and monotony of dealing with many variables allowing an analyst to focus on variables tangibly impacting projection.

<!-- 3_Ink tank display -->
Currently, the radial tour creates three segments (increase-decrease-increase of magnitude). An "ink tank" display for a manual tour may be more intuitive than the current approach. For this, the  magnitude of variable contribution would match the progress of an animation slider. The first frame would contain zero variable contribution, and the last would have a complete contribution. The starting frame could be the original contribution that would also be exaggerated or annotated to refer against.

<!-- 6_Pedagogical side of manual tours for newcomers. -->
This last point is adjacent to the pedagogical side of tours. The user-steering of the manual tour provides a way to play with projections and test hypotheses making it a good candidate as a learning tool. An interactive application built for learning and exploring projection techniques would be a great introductory tool.

<!-- 4_geom/protos for d>2 -->
Extending the output dimensions of some tours is relatively easy to do. The display in __spinifex__  has focused on $d \in [1, 2]$. Additional functions could be added to facilitate the geometric display of parallel coordinate, Chernoff faces, glyph-based, or pixel-based visuals. For the reasons mentioned in Chapter \@ref(ch-background), these displays are potentially best used with data with relatively few observations and many variables.

<!-- 5_2D tour composition --> 
There are also several extensions to the display of 1 & 2D tours including: tabular displaying the numeric values of the basis, drawing of lines around convex and alpha hulls, and a _high-density region_ displays with progressive density rugs, or a combination of point and density contour display where the bulk of the data is shown as density contour, while the outermost observations are displayed as points [@hyndman_computing_1996; @ohara-wild_gghdr_2022].

<!-- 6_Sterescopic 3D & XR -->
It may be interesting to experience tours as 3D scatterplots in extended reality with stereoscopically true head tracking may be fruitful. @nelson_xgobi_1999 explore 2D tours in virtual reality. Other works view 3D scatterplot tours on 2D displays [@yang_3d_1999; @yang_interactive_2000]. It would be interesting to see modern implementations using WebGL, Mozilla A-frame, or Unity. One concern would be keeping hardware and software as generalized as possible.

<!-- 7_User study -->
There are some ways that the user-study evaluating the radial tour could be extended. Besides changing the support of the experimental factors to the user study, it would be more interesting to compare different tasks or other visualization techniques. The performed user study crowdsourced participants with little exposure to linear projections. It would be interesting to compare the results from more experienced participants.

<!-- 8_cheem, and model/explantion types -->
The outlined cheem analysis can be generally applied models and local explanations. While the package __cheem__ currently calculates tree SHAP for tree-based models supported by __treeshap__ [@kominsarczyk_treeshap_2021]. This could be generalized more broadly to other models and local explanations. Those facilitated by `DALEX::explain()` seems to be an excellent direction to extend [@biecek_dalex_2018; @biecek_explanatory_2021]. However, processing runtime is a looming obstacle that is exasperated when moving away from computationally efficient explanations. Alternatively, other statistics may better show the structure identified in the attribution space from the explanations.

<!-- 9_cheem, scope/context of data -->
In the cheem analysis, we had focused primarily on continuous numeric predictors. Perhaps this analysis could be extended to image, text, or time series analysis. The global view may remain helpful in summary and identification while observation-level exploration would likely need to change to fit the context of the data, be it saliency map, word-level contextual sentiment analysis, or other. <!--The presence of covariates in these cases may prove essential to having meaningful variable importance to test variable sensitivity of the structure of the explanation. -->

<!-- 10_Extending explanations and a user study -->
A user study would help elucidate the benefit of cheem analysis over local explanations or observation-specific analysis of a model. Our analysis can highlight the unique attribution of a selected observation against peers and to test the sensitivity of that attribution. Perhaps a task identifying variable sensitivity to a prediction may be appropriate.



<!-- XXX TODO: more grep searches for broken stuff '??', '-cap', '00', 'ref' -->
<!-- XXX TODO: more astrogrep 'paper', convert to chapter or equiv -->
<!-- XXX TODO: Does Cheem chapter still use instance/feature over observation/variable? -->


<!--chapter:end:06-conclusion.Rmd-->

# Bibliography {-}

<div id="refs"></div>


# (APPENDIX) Appendix {-#ch-appendix}
<!-- # Appendix {#ch-appendix} -->

<!-- Does something for LaTeX output -->
\appendix

# Supplementary material for radial tour user study


## Accompanying radial tour application {#sec:spinifex}

An accompanying application illustrates the radial tour. The __R__ package, __spinifex__, [@spyrison_spinifex_2020] is an open-source and now contains a __shiny__ [@chang_shiny_2021] application allowing users to apply various preprocessing tasks and interactively explore their data via interactive radial tour. Example datasets are provided with the ability to upload data. The `html` widget produced is a more interactive variant relative to the one used in the user study. Screen captures and more details are provided in the appendix. Run the following __R__ code will run the application locally.

```{r getting_started, eval=FALSE, echo=TRUE}
## Download:
install.packages("spinifex", dependencies = TRUE)
## Run interactive app demonstrating the radial tour:
spinifex::run_app()

## Set format and fonts for pdf vs html:
if(knitr::is_html_output()){
  fmt      <- "html"
  fnt      <- 12L
  mod_comp <- readRDS("./figures/ch4_tab1_model_comp_ls_html.rds")
  ## Escape HTML formatting of * multiplication
  mod_comp$modelComp_MarksByEval$`Fixed effects` <-
      gsub("[*]", "\\\\*", mod_comp$modelComp_MarksByEval$`Fixed effects`)
  mod_comp$modelComp_TimeByEval$`Fixed effects`  <-
      gsub("[*]", "\\\\*", mod_comp$modelComp_TimeByEval$`Fixed effects`)
}else{
  fmt      <- "latex"
  fnt      <- 10L
  mod_comp <- readRDS("./figures/ch4_tab1_model_comp_ls_latex.rds")
}
esc_comp <- FALSE ## Comparisons, with bolding 
esc_coef <- TRUE  ## Coefficients, with % and *
```

```{r radialTourAppPg1, out.width="100%", fig.show="asis", fig.cap = "Process data tab, interactively loads or select data, check which variables to project, and optionally scale columns by standard deviation."}
nsSafeIncGraphic("./figures/ch4_zapp_fig4_app_pg1.PNG")
```

In the initial tab, Figure \@ref(fig:radialTourAppPg1), users upload their own (.csv, .rds, or .rda) data or select from predefined data sets. The numeric columns appear as a list of variables to include in the projection. Below that, a line displays whether or not missing rows were removed. Scaling by standard deviation is included by default, as this is a common transformation used to explore linear projections of spaces. Summaries of the raw data and processed numeric data are displayed to illustrate how the data was read and its transformation.

```{r radialTourAppPg2, out.width="100%", fig.show="asis", fig.cap = "Radial tour tab, interactively create radial tours, changing the manipulation variable, color, or shape of the resulting manual tour. Here, the palmer penguins data is being explored, bill length was selected to manipulate as it is the only variable separating the green cluster from the orange. By mapping shape to island of observation, the green species can be noted to live on all three islands, while the other species live on only one island."}
nsSafeIncGraphic("./figures/ch4_zapp_fig5_app_pg2.PNG")
```

The second tab, Figure \@ref(fig:radialTourAppPg2) contains interaction for selecting the manipulation variable, and non-numeric columns can be used to change the color and shape of the data points in the projection. The radial tour is created in real-time, animated as an interactive __plotly__ `html` widget. The application offers users a fast, intuitive introduction elucidating what the radial tour does and some of the features offered.


## Extended analysis {#sec:appendix}

<!-- segue to extended analysis -->
This section covers peripheral and extended analysis. First, the demographics of the participants is covered. Then a parallel modeling analysis on log response time is conducted. Lastly, the effect ranges and marginal effects of the random effect of the participants and data simulation are examined.


### Survey participant demographics {-}

The target population is relatively well-educated people, as linear projections may prove difficult for generalized consumption. Hence Prolific.co participants are restricted to those with an undergraduate degree (58,700 of the 150,400 users at the study time). From this cohort, 108 performed a complete study. Of these participants, 84 submitted the post-study survey, represented in the following heatmap. All participants were compensated for their time at \pounds 7.50 per hour, with a mean time of about 16 minutes. Figure \@ref(fig:figSurveyDemographics) shows a heat map of the demographics for these 84 participants.

```{r, figSurveyDemographics, out.width="100%", fig.cap = "Heatmaps of survey participant demographics; counts of age group by completed education as faceted across preferred pronoun. Our sample tended to be between 18 and 35 years of age with an undergraduate or graduate degree."}
nsSafeIncGraphic("./figures/ch4_zapp_fig1_survey_demograpics.pdf")
```


### Response time regression

<!-- Time as secondary interest, Y2 -->
As a secondary explanatory variable response time is considered. Response time is first log transformed to remove its right skew. The same modeling procedure is repeated for this response. 1) Compare the performance of a battery of all additive and multiplicative models. Table \@ref(tab:timeCompTbl) shows the higher level performance of these models over increasing model complexity. 2) Select the model with the same effect terms, $\alpha \cdot \beta + \gamma + \delta$, and examine its coefficients, displayed in Table \@ref(tab:timeCoefTbl).

<!-- Y2 model comparisons, continue to use ABcd -->
```{r timeCompTbl, fig.cap = "Use the caption arg in kable(), not this."}
kableExtra::kbl(
  mod_comp[[2]], format = fmt, align = c("l", rep("l", 2), rep("c", 5)),
  booktabs = TRUE, linesep = "", escape = esc_comp,
  caption = "Model performance regressing on log response time [seconds], $\\widehat{Y_2}$ random effect models, where each includes random effect terms for participants and simulations. There is a simplar trade-off where AIC/BIC prefer the simplest factor model, while $R^2$ and RMSE are the largest in the full multiplicative model. The model $\\alpha \\cdot \\beta + \\gamma + \\delta$ model is selected to examine further as it has relatively high marginal $R^2$ while having much less complexity than the complete interaction model. Conditional $R^2$ includes the random effects, while marginal does not.") %>%
  kableExtra::kable_classic(font_size = fnt)
```

<!-- Y2 coeffiecients -->
```{r timeCoefTbl, fig.cap = "Use the caption arg in kable(), not this."}
kableExtra::kbl(
  mod_coef[[2]], booktabs = TRUE, linesep = "", format = fmt, escape = esc_coef,
  caption = "Model coefficients for log response time [seconds] $\\widehat{Y_2} = \\alpha \\cdot \\beta + \\gamma + \\delta$, with factor = pca, location = 0/100\\%, shape = EEE, and dim = 4 held as baselines. Location = 50/50\\% is the fixed term with the strongest evidence and takes less time. In contrast, the interaction term location = 50/50\\%:shape = EEV has the most evidence and takes much longer on average.") %>%
  kableExtra::pack_rows("Factor", 2, 3) %>%
  kableExtra::pack_rows("Fixed effects", 4, 8) %>%
  kableExtra::pack_rows("Interactions", 9, 12) %>%
  kableExtra::kable_classic(font_size = fnt)
```


### Random effect ranges {-}

<!-- Random effect terms specify source of the error -->
The random effect terms further clarify the source of the error. Below is a comparison the effect ranges attributed to the participant and to the simulations next to their marginal effect on the response, a sort of upper bound of the error they could explain. This was performed for the models regressing accuracy and then log response time.

<!-- Random effects vs Mean Mark CI by participant and sim -->
The residual plots have no noticeable nonlinear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure \@ref(fig:figEffectRange) illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95\% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at $\alpha = .95$, while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95\% confidence intervals participation and simulation mean accuracy, respectively.

Residual plots have no noticeable nonlinear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure \@ref(fig:figEffectRange) illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95\% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at $\alpha = .95$, while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95\% confidence intervals participation and simulation mean accuracy, respectively.

```{r figEffectRange, out.width="100%", fig.show="asis", fig.cap="Accuracy model: (T) Estimated effect ranges of the random effect terms participant and data simulation of the accuracy model, $\\widehat{Y_1} = \\alpha \\cdot \\beta + \\gamma + \\delta$. Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about two-thirds of the range of the data without the model. All intervals for $\\alpha = .95$ confidence."}
nsSafeIncGraphic("./figures/ch4_zapp_fig2_effect_range.pdf")
```

Similarly, figure \@ref(fig:figTeffectRange) shows the Gelman simulations and marginal effects of the simulation and participants for the model with the same terms regressing on log response time.

```{r figTeffectRange, out.width="100%", fig.show="asis", fig.cap = "Log response time model: (T) The effect ranges of Gelman resimulation on posterior distributions for the time model, $\\widehat{Y_2} = \\alpha \\cdot \\beta + \\gamma + \\delta$. These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log time by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: $e^{1} = 2.7$, $e^{2.75} = 15.6$, $e^{3.75} = 42.5$ seconds. Of the simulations on the right, the bottom has a large variation in response time, relative to the effect ranges which means that the variation is explained in the terms of the model and not by the simulation itself."}
nsSafeIncGraphic("./figures/ch4_zapp_fig3_T_effect_range.pdf")
```



<!--chapter:end:90-appA.Rmd-->

# Overall appendix

<!-- !!!LATEX TABLES WILL NOT WORK IN HTML, need to use kbl... -->
```{r}
glossary_df <- data.frame(
  Term = c("observation", "variable", "data", "basis", "biplot", 
           "projection", "tour", "Geodesic interpolation",
           "Intrinsic data dimensionality", "Nonlinear model", "Local explanation"),
  Notation = c(
    "$n$", "$p$", "$X_{n \\times p}$", "$A_{p \\times d}$",
    "", "$Y_{n \\times d} = X_{n \\times p} \\cdot A_{p \\times d}$", 
    "", "", "$iid$", "", ""),
  Alias = c(
    "instance, item, row (of data)", "feature, column (of data)",
    "", "", "", "embedding", "", "", "", "", ""),
  Description = c(
    "A unit being measured across the variables.",
    "A measure taken across all observations.",
    "$n$ observations of $p$ variables, a complete quantitative matrix.",
    "Of linear projections, an othorgonal component mapping of $p$ down to $d$ dimensions.",
    "Visual representation of the basis, showing the direction and magnitude the variable contribute inscribed in a unit circle.", 
    "The resulting space the data multiplied by the basis.",
    "A dynamic linear projection animated over small changes to the projection basis.",
    "Creating intermediate basis frames along the shortest path of possible bases.",
    "The minimal dimensionality data can be represented by.",
    "A model with numerous, polynomial, or interacting terms that can be difficult to interpret.",
    "Approximation of the linear variable importance of a model in the vicinity of one observation.")
)

vimeo_link_df <- data.frame(
  Reference = c(
    "Figure \\@ref(fig:ch1fig3)", "Figure \\@ref(fig:ch2fig4)", 
    "Figure \\@ref(fig:casepenguins)", "Figure \\@ref(fig:casechocolates)", 
    "Figure \\@ref(fig:casechocolatesinverse)", "Figure \\@ref(fig:casefifa)", 
    "Figure \\@ref(fig:caseames)"),
  Description = c(
    "radial tour, penguins", "grand tour, penguins", "cheem,  penguins", 
    "cheem,  chocolates", "cheem,  chocolates (inverse)", "cheem, fifa", 
    "cheem, ames housing 2018"),
  Link = c("[vimeo.com/676723431](https://vimeo.com/676723431)",
           "[vimeo.com/676723441](https://vimeo.com/676723441)",
           "[vimeo.com/666431172](https://vimeo.com/666431172)",
           "[vimeo.com/666431143](https://vimeo.com/666431143)",
           "[vimeo.com/666431148](https://vimeo.com/666431148)",
           "[vimeo.com/666431163](https://vimeo.com/666431163)",
           "[vimeo.com/666431134](https://vimeo.com/666431134)")
)

supp_mats_df <- data.frame(
  Context = c(
    #"spinifex", 
    "spinifex", "spinifex", 
    #"cheem", 
    "cheem", "thesis", "thesis", "thesis"),
  Description = c(
    #"CRAN Link", 
    "vignette, Getting started with spinifex", 
    "vignette, Ggproto api", 
    #"CRAN Link", 
    "vignette, Getting started with cheem", 
    "repository", "thesis, pdf format", "thesis, html format"),
  Link = c(
    #"[CRAN.R-project.org/package=spinifex](https://CRAN.R-project.org/package=spinifex)",
    "[nspyrison.github.io/spinifex/articles/getting-started-with-spinifex.html](https://nspyrison.github.io/spinifex/articles/getting-started-with-spinifex.html)",
    "[nspyrison.github.io/spinifex/articles/ggproto-api.html](https://nspyrison.github.io/spinifex/articles/ggproto-api.html)",
    #"[CRAN.R-project.org/package=cheem](https://CRAN.R-project.org/package=cheem)",
    "[nspyrison.github.io/cheem/articles/getting-started-with-cheem.html](https://nspyrison.github.io/cheem/articles/getting-started-with-cheem.html)",
    "[github.com/nspyrison/thesis_ns](https://github.com/nspyrison/thesis_ns)",
    "[github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf](https://github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf)",
    "[https://nspyrison.github.io/thesis_ns/](https://nspyrison.github.io/thesis_ns/)")
)

## Set format and fonts for pdf vs html:
if(knitr::is_html_output()){
  fmt <- "html"
  fnt <- 12L
  esc <- FALSE ## HTML likes FALSE in vimeolinks
}else{
  fmt <- "latex"
  fnt <- 10L
  esc <- TRUE #FALSE ## latex needs \ escaping on urls to use false.
  #supp_mats_df$Link <- gsub("_", "\_", supp_mats_df$Link) 
}
```

## Glossary {#sec-glossary}

```{r glossary, fig.cap = "Use the caption arg in kable(), not this."}
kableExtra::kbl(
    glossary_df, format = fmt, align = rep("l", 4),
    booktabs = TRUE, longtable = TRUE, linesep = "", escape = esc,
    caption = "Glossary of terms") %>%
  kableExtra::kable_classic(font_size = fnt)
```


## Animated tour links

```{r vimeolinks, fig.cap = "Use the caption arg in kable(), not this."}
kableExtra::kbl(
    vimeo_link_df, format = fmt, align = rep("l", 3),
    booktabs = TRUE, longtable = TRUE, linesep = "", escape = esc,
    caption = "Animated tour links") %>%
  kableExtra::kable_classic(font_size = fnt)
```


## Supplementary material

```{r suppmats, fig.cap = "Use the caption arg in kable(), not this."}
kableExtra::kbl(
    supp_mats_df, format = fmt, align = rep("l", 3),
    booktabs = TRUE, longtable = TRUE, linesep = "", escape = esc,
    caption = "Supplementary material") %>%
  kableExtra::kable_classic(font_size = fnt)
```


<!--
### Tour taxonomy; path generation {#sec:path_generation}

A fundamental aspect of tours is the path of rotation. There are four primary distinctions of tour path generation [@buja_computational_2005]: random choice, data-driven, precomputed choice, and manual control.

* Random choice, *grand tour*, constrained random walks $p$-space. Paths are constrained for changes in direction small enough to maintain continuity and aid in user comprehension
    + torus-surface [@asimov_grand_1985]
    + at-random [@asimov_grand_1985]
    + random-walk [@asimov_grand_1985]
    + *local tour* [@wickham_tourr_2011], a sort of grand tour on a leash, such that it goes to a nearby random projection before returning to the original position and iterating to a new nearby projection.
* _guided tour_, optimizes an objective function/index of the projection using projection pursuit (PP) [@hurley_analyzing_1990], including the following implemented indexes:
    + holes [@cook_projection_1993] - moves points away from the center.
    + cmass [@cook_projection_1993] - moves points toward the center.
    + lda [@lee_projection_2005] - linear discriminant analysis, seeks a projection where 2 or more classes are most separated.
    + pda [@lee_projection_2010] - penalized discriminant analysis for use in highly correlated variables when classification is needed.
    + convex [@laa_using_2019] - the ratio of the area of convex and alpha hulls.
    + skinny [@laa_using_2019] - the ratio of the perimeter distance to the area of the alpha hull.
    + stringy [@laa_using_2019] - based on the minimum spanning tree (MST), the diameter of the MST over the length of the MST.
    + dcor2D [@grimm_mbgraphic:_2017; @laa_using_2019] - distance correlation that finds linear and nonlinear dependencies between variables.
    + splines2D [@grimm_mbgraphic:_2017; @laa_using_2019] - measure of nonlinear dependence by fitting spline models.
    + other user-defined objective indices can be applied to the framework provided in the *tourr* package @wickham_tourr_2011.
    + Another data-drive tour is the *dependence tour*, a combination of $n$ independent 1D tours. A vector describes the axis each variable will be displayed on. for example $c(1, 1, 2, 2)$ is a 4- to 2D tour with the first 2 variables on the first axis, and the remaining on the second.
        - *correlation tour* [@buja_data_1987], a special case of the dependence tour, analogous to canonical correlation analysis.
* Precomputed choice, *planned tour*, in which the path has already been generated or defined.
    + *little tour* [@mcdonald_interactive_1982], where every permutation of variables is stepped through in order, analogous to brute-force or exhaustive search.
    + a saved path of any other tour, typically an array of basis targets to interpolate between.
* Manual control, *manual tour*, a constrained rotation on selected manipulation variable and magnitude [@cook_manual_1997]. Typically used to explore the local area after identifying an interesting feature, perhaps via guided tour.
    + radial, fix angle of contribution, change magnitude radially.
    + oblique, along an oblique path of a dragged cursor


### Interpolation

NOTE: Search 'Interpolator' in Wickham’s tourr paper
After target bases are identified, the frames in-between need to be filled in. There are several methods to do so:

* Geodesic - via Gram-Schmidt process
* Givens rotations
* Householder reflections
.

### Tour software

Tours have yet to be widely adopted, due in part, to the fact that print and static pdf output does not accommodate dynamic viewing. Conceptual abstraction and technically density have also hampered user growth. Due to low levels of adoption and the rapid advancement of technology support and maintenance of such implementations give them a particularly short life span. Despite the small user base, there have been a fair number of tour implementations, including:
<!-- See Wickham’s thesis and C2 paper for partial lists. 

* spinifex [github.com/nspyrison/spinifex](https://github.com/nspyrison/spinifex) -- R package, all platforms.
* tourr [@wickham_tourr_2011] -- R package, all platforms.
* CyrstalVision [@wegman_visual_2003] -- for Windows.
* GGobi [@swayne_ggobi:_2003] -- for Linux and Windows.
* DAVIS [@huh_davis:_2002] -- Java based, with GUI.
* ORCA [@sutherland_orca:_2000] -- Extensible toolkit built in Java.
* VRGobi [@nelson_xgobi_1999] -- for use with the C2, tours in stereoscopic 3D displays.
* ExplorN [@carr_explorn:_1996] -- for SGI Unix.
* ExploRe [@hardle_xplore:_1995]
* XGobi [@swayne_xgobi:_1991] -- for Linux, Unix, and Windows (via emulation).
* XLispStat [@tierney_lisp-stat:_1990] -- for Unix and Windows.
* Explor4 [@carr_explor4:_1988] -- Four-dimensional data using stereo-ray glyphs.
* Prim-9 [@asimov_grand_1985;@fisherkeller_prim-9:_1974] -- on an internal operating system.
* liminal
* cheem
-->


<!--chapter:end:91-appB.Rmd-->

<!-- HTML version:  Print bibliography--> 
<!-- !!! printing references before Appendix, not using this -->
<!-- `r if (knitr::is_html_output()) '# Bibliography {-}'` -->


<!--chapter:end:99-bib.Rmd-->

