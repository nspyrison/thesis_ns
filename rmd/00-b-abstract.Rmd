---
knit: "bookdown::render_book"
---

# Abstract {-}

Visualizing data space is crucial to exploratory data analysis, checking model assumptions, and validating model performance. Yet visualization quickly becomes difficult as the dimensionality of the data or features increases. Traditionally, static, low-dimensional linear embeddings are used to mitigate this complexity. Such embedded space is a lossy approximation of the full space. However, viewing many embeddings with interactive supporting views, maximizes the information conveyed. Data visualization _tours_ are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis.

Tours are categorized by the path of their bases. _Manual tours_ allow for User-Controlled Steering (UCS) of bases path, where the contributions of individual variables can be controlled. First I create a free, open-source __R__ package, __spinifex__ that facilitates the creation of such tours. These manipulations of the variables can be precomputed or made in real-time. The animations are interoperable with the existing package __tourr__ and can be rendered with recent graphics interfaces __plotly__ and __gganimate__. The former offers interactive use with HTML widgets while the latter can render to static formats such as .gif or .mp4 files. An interactive application is included to illustrate the use of the manual tour.

Theoretically, UCS should enable an analyst to better explore the variable attribution to the structure identified in an embedding. To test this I conduct a within-participant, crowd-sourced user study. The primary variable of interest is the visualization method where manual tours are compared against the benchmarks of Principal Component Analysis (PCA) and an alternative tour variant, the grand tour. Each of the $n=108$ participants performs two trials with each visual for 648 total trials. The task is a supervised classification problem asking participants which variables attribute to the separation of 2 clusters. I find strong evidence to support that use of the radial tour leads to a large improvement in the accuracy of the variable attribution for this task.

Modern modeling techniques are sometimes referred to as black-box models due to the uninterpretable nature of model terms which are often many and non-linear. Recent research in Explainable Artificial Intelligence (XAI) tries to bring interpretability to these models through the use of _local explanations_. Local explanations are a class of techniques that approximate the linear-variable importance at one point in the data. I purpose interactively exploring data- and explanation-spaces side-by-side to identify two observations to compare. Then the explanations can be evaluated to see how well they hold up under the varying contributions with the manual tour. I have created the free open-sourced __R__ package __cheem__ provides preprocessing defaults and an interactive application to explore.

<!-- 
The following line is required to re-set page numbering after preliminary material. Do not remove
-->
\clearpage\pagenumbering{arabic}\setcounter{page}{0}
