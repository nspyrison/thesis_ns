<!-- Short abstract for MGRO/Bridges: -->
<!-- currently 98 words, may need to be cut to 100 -->
<!--
As the dimensionality of data increases, so does the difficulty of comprehensive visualization. Traditional linear projections view discrete pairs of linear components. Tours are a class of linear projections that animate over small changes to the projection. The manual tour uniquely enables an analyst to steer a path of bases. This thesis discusses a package that facilitates their creation. A user study finds the manual tour outperforms traditional visualizations on a variable attribution task. This work introduces a novel approach to examine the support of nonlinear model explanations with the radial tour. An accompanying package facilitates this analysis.
-->

<!-- at 408 words out of 500, fine-->
# Abstract {-}

<!-- EDA, motivation, linear projections, tours -->
Visualizing data is crucial for exploratory data analysis, checking assumptions, and validating model performance. However, visualization quickly becomes complex as the dimensionality of the data or features increases. Traditionally, linear projections have been used to view discrete pairs of components to mitigate this complexity. Data visualization _tours_ are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis. The permanence of observations between nearby frames potentially conveys more information than discrete orthogonal frames alone.

<!-- manual tours and spinifex -->
Tours are categorized by the path of their bases. _Manual tours_ uniquely allow for user-controlled steering of a path of bases, where the contributions of individual variables can be changed. The _radial tour_ is a specific case of the manual tour, which freezes the angle of movement but allows the magnitude to be varied. The radial tour is central to the work covered in this thesis. Chapter \@ref(ch-spinifex) clarifies the theoretical basis of the radial tour. The details of implementation and illustration of its use are provided. It introduces an open-source __R__ package that facilitates creating these tours with various display choices and user controls.

<!-- user study -->
Allowing the analyst to steer a path in the radial tour should enable a better understanding of the variable importance to any structure revealed in a projection. Chapter \@ref(ch-userstudy) discusses a within-participant user study comparing the radial tour with current practices: principal component analysis (PCA) and the original tour type without steering. The $n=108$ crowdsourced participants performed a variable attribution task describing the separation between clusters. The results find that the radial tour leads to a more accurate variable attribution. Participants also reported that the radial tour was their preferred visualization method.

<!-- cheem -->
Nonlinear modeling techniques are sometimes referred to as black-box models due to the difficulty of interpreting the model terms. Recent research in Explainable Artificial Intelligence (XAI) tries to bring interpretability to these models through _local explanations_. Local explanations are a class of techniques that approximate the linear-variable importance for prediction at one point in the data. Chapter \@ref(ch-cheem) provides a new approach for exploring the variable sensitivity of local explanations using the radial tour. Local explanations can be considered projection bases. The radial tour is used to vary the contribution of a variable to assess its importance for any particular prediction. This novel analysis is illustrated using four contemporary data examples covering classification and regression. An accompanying __R__ package provides a graphical user interface (GUI) for conducting this analysis.

