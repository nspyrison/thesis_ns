<!-- Short abstract for MGRO/Bridges: -->
<!-- currently 120 words, may need to be cut to 100 -->
<!--
As the dimensionality of data increases, so does the difficulty of visualizing them. Traditional linear dimension reduction views discrete pairs of linear components. Tours are a class of linear projections that animate over continuous changes to the projection basis. This thesis discusses an R package that facilitates the creation of manual tours and layered composition for all tours. A user study is conducted finding radial tour outperforms alternative visualizations on a variable attribution task describing the separation of two clusters. Local explanations increase the interpretability of non-linear models by approximating the variable importance at the vicinity of one observation. This work introduces a novel analysis and accompanying R package to evaluates the support of these explanations with the manual tour.
-->

# Abstract {-}

<!-- EDA, motivation, linear projections, tours -->
Visualizing data space is a crucial aspect of exploratory data analysis, checking assumptions, and validating model performance. However, visualization quickly becomes complex as the dimensionality of the data or features increases. Traditionally, linear projections have viewed discrete pairs of components to mitigate this complexity. Data visualization _tours_ are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis. The permanence of observations between nearby frames potentially conveys more information than discrete orthogonal frames alone.

<!-- manual tours and spinifex -->
Tours are categorized by the path of their bases. _Manual tours_ uniquely allow for user-controlled steering of bases path, where the contributions of individual variables can be changed. Chapter \@ref(ch-spinifex) clarifies the theoretical work for the manual tour. It introduces an open-source __R__ package, that facilitates creating these tours and the layered composition interoperably with existing packages. These compositions can then be animated with recent graphics interfaces. <!--An interactive application, vignettes, and example code illustrate the use of the manual tour.-->

<!-- user study -->
Theoretically, the analyst steering of the basis in the manual tour should enable better understand of the variable attribution to the structure in an embedding. Chapter \@ref(ch-userstudy) discusses a within-participant user study comparing the manual tour with Principal Component Analysis (PCA) and an alternative tour variant, the grand tour. The $n=108$ crowdsourced participants perform a variable attribution task describing the separation of two clusters. There is considerable support that the use of the manual tour leads to a sizable increase in the accuracy for this task. The manual tour is also subjectively the most preferred of the three visualizations.

<!-- cheem -->
Non-linear modeling techniques are sometimes referred to as black-box models due to the uninterpretable nature of model terms. Recent research in Explainable Artificial Intelligence (XAI) tries to bring these models interpretability through _local explanations_. Local explanations are a class of techniques that approximate the linear-variable importance at one point in the data. Chapter \@ref(ch-cheem) purposes a novel analysis to explore the variable sensitivity of local explanations. Given a non-linear model, calculate a local explanation for each observation. Explore data space and explanation space side-by-side with a residual plot to identify an observation to further explore. From the linear importance of this observation use the manual tour to explore the variable sensitivity to the structure of the explanation. An accompanying __R__ package to streamlines preprocessing and facilitates this analysis.

<!-- 
The following line is required to re-set page numbering after preliminary material. Do not remove
-->
\clearpage\pagenumbering{arabic}\setcounter{page}{0}
