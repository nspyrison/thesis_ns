---
chapter: 6
knit: "bookdown::render_book"
---

# Conclusion {#ch-conclusion}

<!-- Context -->
We know that visualizing data is more robust than numerical summarization alone.  It provides a means to get a feel for the data rapidly, check for erroneous values, and confirm model assumptions. But visualizing data spaces becomes increasingly complex as dimensionality increases. Static linear dimension reduction has been widespread in extending the dimensionality of spaces viewed. Dynamic animations of linear projections, tours, further increase the perceptible information of linearly reduced spaces. Previously we have not had the means to test the sensitivity of individual variables' contribution to the structure in one embedding. Chapter \@ref(ch-spinifex) introduced the __spinifex__ package, which facilitates user-controlled manual tours and layered composition and exporting animations of any tour, interoperable with __tourr__. The radial, manual tour sizably improves the accuracy on a variable attribution cluster separation task compared with PCA and the grand tour. Chapter \@ref(ch-userstudy) covers the within-participants user study that led to this conclusion. Finally, I apply the manual tour to increase the interpretability of non-linear models by using it to explore their local explanations in the package __cheem__ is discussed in Chapter \@ref(ch-cheem).


## Contributions
<!-- ## Software development -->

This study makes two major contributions to extending knowledge in the domain of data visualization.


### Knowledge

First, I clarify the use of Rodrigues' rotation formula to solve the rotation matrix with the definition of two manipulation angles. This sets up a scaffolding to extend the manual tour to three dimensions with another angle of rotation. We also support the use of  manual tours by illustrating use cases on high-energy physics data.

Then I define a task and accuracy measure for a variable attribution of the separation of two clusters. We conducted a crowdsourced user study comparing the performance from PCA, the grand tour, and the radial tour. We find considerable evidence for a sizable improvement in accuracy with radial tour, which is subjectively most preferred by participants.

Lastly, I purpose the cheem analysis to explore the variable support of local explanations from black-box models. After calculating the local explanations of all observations, compare data space, attribution space, and model information side-by-side as an ensemble  graphic. From this, identify a primary and comparison observation explore the explanations in detail. The normalized attribution of the primary point becomes the starting basis for a radial tour. Then vary the contributions of variables, testing their contribution's sensitivity to the predictive discernment identified in the explanation.


### Software

<!-- spinifex -->
The __R__ package __spinifex__ facilitates the creation of manual tours, which allow an analyst control over the contributions of a variable. It handles variable transformations and the identification of various bases. It creates a framework for layered composition of tours interoperable with the previous __tourr__ package. The layer composition will feel at home to __ggplot2__ users. After composition tours can be animated and exported as interactive HTML widgets or fixed animations as .gif, or .mp4 files. Vignettes and interactive application help users rapidly understand the concepts and scope of the package. The impact of __spinifex__ can be seen in two ways. My contributions to __spinifex__ and __tourr__ won the ACEMS Impact and Engagement Award, 2018. Further, the package is available on [CRAN](https://CRAN.R-project.org/package=spinifex)  with vignettes and version notes on its [pkgdown](https://nspyrison.github.io/spinifex/) site. It has been downloaded over 14,400 times from CRAN between 09 April 2019 and 28 November 2021.

<!-- cheem -->
The second software contribution is the __cheem__ package. It facilitates the tree SHAP local explanations from tree-based models. The global view visualizes data space, explanation space, and model information as an ensemble graphic with linked brushing. After observations of interest have been identified in the full context, their local explanation is explored with the radial tour. Doing so allows the support of the explanation to be tested. An interactive application uses these visuals to facilitate the cheem analysis. Several preprocess datasets are included and allows analysts to upload their data after processing. This package was recently uploaded to [CRAN](https://CRAN.R-project.org/package=cheem) and has a corresponding [pkgdown site](https://nspyrison.github.io/cheem/).


## Limitations and future work

<!-- Manual tour extension -->
The manual tour only controls the contribution to one variable at a time. This can become cumbersome and time-consuming as dimensionality increases. In addition to the manual tour controlling the contribution of a single variable, it may be insightful to change the contributions of several variables at once (manipulating a linear combination). Alternatively, some sort of dimension reduction tour, appending several manual tours together that zero the contributions of variables contributing less than some threshold, may prove to expedite analysis, especially for approaching a feature's intrinsic dimensionality.

<!-- 3D and function vis -->
It is trivial to ask for another embedding dimension in component spaces and other tours. However, the manual tour would require the additional input, the depth of the selected variable. Which then has to be rotated in a 4D manipulation space. I have supplied the scaffolding for this task. Namely, this would require applying another angle of rotation with Rodrigues' rotation formula on the current 3D rotation matrix. Another display dimension may benefit the detection and understanding of the higher dimensional structure though the input of three angles may prove less natural and harder to capture.

<!-- Ink tank display -->
The radial tour's current three direction segments take a bit to unpack. It may be more approachable to directly relate the position of the slider to the magnitude of the manipulation variable. The display order of the manual tour could be changed to more of an _ink tank_ display, where the first frame would contain zero variable contribution, and the last would have a total contribution. The starting frame would be the original contribution that would also want to be exaggerated or annotated to reference against.

<!-- 2.5d & XR -->
It may be interesting to experience tours as 3D scatterplots in extended reality with stereoscopically true head tracking may be fruitful. @nelson_xgobi_1999 explore 2D tour is in virtual reality. Other works view 3D scatterplot tours on 2D displays [@yang_3d_1999; @yang_interactive_2000]. It would be interesting to see modern implementations using WebGL, Mozilla A-frame, or Unity. One concern would be keeping hardware and software as generalized as possible.

<!-- Layered tour composition --> 
Setting aside the manual tour, there are several extensions to the layered composition of tours in __spinifex__, such as extending the type of protos available, such as adding a text table of the basis, convex hulls, alpha hulls, and a 'high density region' display where the bulk of the data is shown as density contour, while the outermost observations are displayed as points [@hyndman_computing_1996].

<!-- User study -->
Besides changing the support of the experimental factors to the user study, it would be more interesting to try different tasks or compare other visualization techniques. We crowdsourced undergraduate participants with little exposure to linear projections. It would be interesting to compare the results from more familiar and experienced participants.

<!-- cheem, models and explanations -->
The outlined cheem analysis can be generally applied models and local explanations. The package __cheem__ currently calculates tree SHAP for tree-based models supported by __treeshap__. This could be generalized more broadly to other models and local explanations. Those facilitated by `DALEX::explain()` seems to be a good direction to extend [@biecek_dalex_2018; @biecek_explanatory_2021]. However, processioning runtime would quickly become a formidable obstacle. Alternatively, other statistics may better show the structure identified by explanations.

<!-- cheem, scope of use -->
In __cheem__, we had focused primarily on continuous numeric predictors. Perhaps this analysis could be extended to image, text, or time series analysis. The presence of  covariates in these cases may prove essential to having meaningful variable importance to test variable sensitivity of the structure of the explanation.

<!-- Reminders from 13 Jan meeting with Julie and 20 Jna meeting with KM: -->
<!-- XXX TODO: Esp in the abstract blurb of the content chapters: make sure not to list outcomes -->
<!-- XXX TODO: keep moving chapter introduction, background and further work to their respective thesis chapters -->
<!-- XXX TODO: keep doing grep 'paper' and opt for study or chapter -->
<!-- XXX TODO: keep doing grep for broken links and references '??', '-cap', '00', 'ref' -->

