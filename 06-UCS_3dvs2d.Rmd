---
chapter: 6
knit: "bookdown::render_book"
---

# Does 3D UCS provide benefits over UCS in 2D? {#ch:UCS_3dvs2d}

<!-- Display types come in a plethora of sizes and technologies each is unique and optimized for specific uses and viewing conditions. It's a rapidly changing and shifting environment with a plethora of applications. Which and how to best use 2D computer minters will generate as many varied opinions as people asked. The question is only exaggerated when 3D display devices are considered. -->

@wagner_filho_immersive_2018 performed an $n=30$ empirical study of PCA embedded projections, and perception error across 4 tasks and 3 display types: 2D, 3D, and immersive. Overall task error was less in 3D and immersive relative to 2D. According to user Likert-scale 2D is slightly easier to navigate and slightly more comfortable. On the flip-side 3D and immersive are slightly easier to interact and moderately easier to find information.

The bulk of past touring endeavors have existed whole in 2D, with the exceptions of @nelson_xgobi_1998 and @arms_benefits_1999 whom performed a small ($n=15$) experimental study comparing tasks performed across 2D and 3D touring displays. The XGobi interface was used on a standard 2D monitor while VR-Gobi (on the C2 setup) was used VR display without head tracking. The accuracy 3 tasks: clustering, intrinsic data dimensionality and radial sparseness was recorded along with the speed of a data brushing task. Accuracy was the same for the dimensionality task, while the d3 display out performed 2D on clustering, and even more so on the radial sparsity. However, time taken to brush a cluster was less than half the time in 2D display as compared with 3D. 

The results of @wagner_filho_immersive_2018, @nelson_xgobi_1998 and, @arms_benefits_1999 cast positive light on 3D and immerse spaces improving perception of project high dim data. After implementing touring and UCS in 3D spaces (**RO C**), I plan to explore the efficacy of doing so with the following empirical study: comparison of 3D touring across display dimension in 4 instances: standard 2D monitor, stereoscopic 3D monitor (on a zSpace 200), and head-mounted VR goggle (HTC Vive), and immersion in a CAVE environment. Implementation in the game engine Unity will allow for a standardized user interface. 3 tasks of structure perception will be conducted across 2 data sets of high energy physics data already in publication [@wang_visualizing_2018; @cook_dynamical_2018] and discussed in chapter \ref{ch:spinifex}. Task order will be randomly assigned to minimize learning bias. Participants will perform the 3 tasks, on each of the display devices, for each of the data sets. Time, and accuracy will be tracked, and participants will be asked to fill out a small survey with demographics data and subjective experience on a 5-point Likert scale. The design space of this study includes display type, task type, familiarity with 3D, familiarity with linear projections.
