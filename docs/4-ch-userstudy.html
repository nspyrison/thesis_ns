<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data | Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models</title>
  <meta name="description" content="Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data | Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models" />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data | Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data | Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models" />
  
  
  

<meta name="author" content="Nicholas S Spyrison" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="3-ch-spinifex.html"/>
<link rel="next" href="5-ch-cheem.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="template/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><strong><a href="./"> </a></strong></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html"><i class="fa fa-check"></i>Abstract</a>
<ul>
<li class="chapter" data-level="" data-path="abstract.html"><a href="abstract.html#publications-and-papers-during-candidature-not-part-of-this-thesis"><i class="fa fa-check"></i>Publications and papers during candidature not part of this thesis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="acknowledgments.html"><a href="acknowledgments.html"><i class="fa fa-check"></i>Acknowledgments</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="1-ch-introduction.html"><a href="1-ch-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1-ch-introduction.html"><a href="1-ch-introduction.html#research-questions"><i class="fa fa-check"></i><b>1.1</b> Research questions</a></li>
<li class="chapter" data-level="1.2" data-path="1-ch-introduction.html"><a href="1-ch-introduction.html#methodology"><i class="fa fa-check"></i><b>1.2</b> Methodology</a></li>
<li class="chapter" data-level="1.3" data-path="1-ch-introduction.html"><a href="1-ch-introduction.html#contributions"><i class="fa fa-check"></i><b>1.3</b> Contributions</a></li>
<li class="chapter" data-level="1.4" data-path="1-ch-introduction.html"><a href="1-ch-introduction.html#thesis-structure"><i class="fa fa-check"></i><b>1.4</b> Thesis structure</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="2-ch-background.html"><a href="2-ch-background.html"><i class="fa fa-check"></i><b>2</b> Background</a>
<ul>
<li class="chapter" data-level="2.1" data-path="2-ch-background.html"><a href="2-ch-background.html#scatterplot-matrices"><i class="fa fa-check"></i><b>2.1</b> Scatterplot matrices</a></li>
<li class="chapter" data-level="2.2" data-path="2-ch-background.html"><a href="2-ch-background.html#parallel-coordinate-plots"><i class="fa fa-check"></i><b>2.2</b> Parallel coordinate plots</a></li>
<li class="chapter" data-level="2.3" data-path="2-ch-background.html"><a href="2-ch-background.html#dimension-reduction"><i class="fa fa-check"></i><b>2.3</b> Dimension reduction</a></li>
<li class="chapter" data-level="2.4" data-path="2-ch-background.html"><a href="2-ch-background.html#tours-animated-linear-projections"><i class="fa fa-check"></i><b>2.4</b> Tours, animated linear projections</a></li>
<li class="chapter" data-level="2.5" data-path="2-ch-background.html"><a href="2-ch-background.html#evaluating-multivariate-data-visualization"><i class="fa fa-check"></i><b>2.5</b> Evaluating multivariate data visualization</a></li>
<li class="chapter" data-level="2.6" data-path="2-ch-background.html"><a href="2-ch-background.html#non-linear-models"><i class="fa fa-check"></i><b>2.6</b> Non-linear models</a></li>
<li class="chapter" data-level="2.7" data-path="2-ch-background.html"><a href="2-ch-background.html#sec:explanations"><i class="fa fa-check"></i><b>2.7</b> Local explanations</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="3-ch-spinifex.html"><a href="3-ch-spinifex.html"><i class="fa fa-check"></i><b>3</b> spinifex: an R package for creating user-controlled animated linear projections</a>
<ul>
<li class="chapter" data-level="3.1" data-path="3-ch-spinifex.html"><a href="3-ch-spinifex.html#sec:algorithm"><i class="fa fa-check"></i><b>3.1</b> Algorithm</a></li>
<li class="chapter" data-level="3.2" data-path="3-ch-spinifex.html"><a href="3-ch-spinifex.html#oblique-cursor-movement"><i class="fa fa-check"></i><b>3.2</b> Oblique cursor movement</a></li>
<li class="chapter" data-level="3.3" data-path="3-ch-spinifex.html"><a href="3-ch-spinifex.html#sec:pkgstructure"><i class="fa fa-check"></i><b>3.3</b> Package structure</a></li>
<li class="chapter" data-level="3.4" data-path="3-ch-spinifex.html"><a href="3-ch-spinifex.html#sec:usecases"><i class="fa fa-check"></i><b>3.4</b> Use cases</a></li>
<li class="chapter" data-level="3.5" data-path="3-ch-spinifex.html"><a href="3-ch-spinifex.html#sec:discussion"><i class="fa fa-check"></i><b>3.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html"><i class="fa fa-check"></i><b>4</b> A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data</a>
<ul>
<li class="chapter" data-level="4.1" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html#sec:background"><i class="fa fa-check"></i><b>4.1</b> Background</a></li>
<li class="chapter" data-level="4.2" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html#sec:userstudy"><i class="fa fa-check"></i><b>4.2</b> User study</a></li>
<li class="chapter" data-level="4.3" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html#sec:results"><i class="fa fa-check"></i><b>4.3</b> Results</a></li>
<li class="chapter" data-level="4.4" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html#sec:conclusion"><i class="fa fa-check"></i><b>4.4</b> Conclusion</a></li>
<li class="chapter" data-level="4.5" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html#sec:spinifex"><i class="fa fa-check"></i><b>4.5</b> Accompanying tool: radial tour application</a></li>
<li class="chapter" data-level="4.6" data-path="4-ch-userstudy.html"><a href="4-ch-userstudy.html#sec:appendix"><i class="fa fa-check"></i><b>4.6</b> Extended analysis</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="5-ch-cheem.html"><a href="5-ch-cheem.html"><i class="fa fa-check"></i><b>5</b> Exploring Local Explanations of Non-linear Models Using Animated Linear Projections</a>
<ul>
<li class="chapter" data-level="5.1" data-path="5-ch-cheem.html"><a href="5-ch-cheem.html#shap-and-tree-shap-local-explanations"><i class="fa fa-check"></i><b>5.1</b> SHAP and tree SHAP local explanations</a></li>
<li class="chapter" data-level="5.2" data-path="5-ch-cheem.html"><a href="5-ch-cheem.html#sec:tour"><i class="fa fa-check"></i><b>5.2</b> Tours and the radial tour</a></li>
<li class="chapter" data-level="5.3" data-path="5-ch-cheem.html"><a href="5-ch-cheem.html#sec:cheemviwer"><i class="fa fa-check"></i><b>5.3</b> The cheem viewer</a></li>
<li class="chapter" data-level="5.4" data-path="5-ch-cheem.html"><a href="5-ch-cheem.html#sec:casestudies"><i class="fa fa-check"></i><b>5.4</b> Case studies</a></li>
<li class="chapter" data-level="5.5" data-path="5-ch-cheem.html"><a href="5-ch-cheem.html#sec:cheemdiscussion"><i class="fa fa-check"></i><b>5.5</b> Discussion</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="6-ch-conclusion.html"><a href="6-ch-conclusion.html"><i class="fa fa-check"></i><b>6</b> Conclusion</a>
<ul>
<li class="chapter" data-level="6.1" data-path="6-ch-conclusion.html"><a href="6-ch-conclusion.html#contributions-1"><i class="fa fa-check"></i><b>6.1</b> Contributions</a></li>
<li class="chapter" data-level="6.2" data-path="6-ch-conclusion.html"><a href="6-ch-conclusion.html#limitations-and-future-work"><i class="fa fa-check"></i><b>6.2</b> Limitations and future work</a></li>
</ul></li>
<li class="divider"></li>
<li><strong><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></strong></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="ch-userstudy" class="section level1" number="4">
<h1><span class="header-section-number">Chapter 4</span> A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data</h1>
<!-- Segue -->
<p>The previous chapter introduced the package <strong>spinifex</strong> which gave us the means to perform radial tours. Now we have the means to perform radial tours, we want now investigate whether we should be confident that this method with user control will lead to better analysis than traditional alternatives. Therefore, this chapter discusses the user study to elucidate the efficacy of the radial tour.</p>
<!-- Abstract -->
<p>Principal component analysis is a long-standing go-to method for exploring multivariate data. Data visualization <em>tours</em> are a class of linear projections animated over small changes in the projection basis. The grand tour selects target bases at random to animate between. Alternatively, the manual tour rotates the contribution of a selected variable offering analysts a unique means to control the basis. This chapter describes a within-participants user study evaluating the radial tour’s efficacy compared with principal component analysis and the grand tour. We devise a supervised classification task where participants evaluate variable attribution of the separation between two classes. We define an accuracy measure as the response variable. Data were collected from 108 crowdsourced participants, who performed two trials of each visual for 648 trials in total.</p>
<!-- ## Introduction -->
<!-- Segue -->
<p>In Chapter <a href="2-ch-background.html#ch-background">2</a> we discuss comparisons across display dimensions of component spaces, empirical measurements describing the distortions from non-linear spaces, and note a absence of comparing competing visualization methods.<!-- Overview of the study --> We are particularly interested in assessing the effectiveness of the new radial tour relative to common practice with PCA, and relative to a grand tour. The radial tour is particularly useful for understanding variable importance relative to structure visible in a scatterplot. If the contribution of a variable is reduced and the structure disappears, then that variable makes an important role in the presence of that structure in the data. For example, if in the scatterplot cluster can be seen, but the gap between them is reduced when a variable is removed it means that the clustering is due, at least partially, to that variable. Understanding which variables are important is a key aspect of interpretability of models.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig1"></span>
<img src="figures/ch4_fig1_cl_sep.pdf" alt="Illustrastion of cluster separation. Panel (a) shows clear separation in V2, no separation in V1, V3 has negligable contribution to the frame. The contributions of V2 is then swapped with V3 in panel (b). There is no separation between the cluster means in V3, and the separation contained in V2 no longer influences the frame." width="100%"  />
<p class="caption">
Figure 4.1: Illustrastion of cluster separation. Panel (a) shows clear separation in V2, no separation in V1, V3 has negligable contribution to the frame. The contributions of V2 is then swapped with V3 in panel (b). There is no separation between the cluster means in V3, and the separation contained in V2 no longer influences the frame.
</p>
</div>
<!--- Black-box models-->
<p>Knowing which variables to use is also important for statistical modeling and their interpretations. Models are becoming increasingly complex <!--involving many interacting, or otherwise non-linear terms--> causing an opaqueness to their interpretability. Exploratory Artificial Intelligence <span class="citation">(XAI, <a href="6-ch-conclusion.html#ref-adadi_peeking_2018" role="doc-biblioref">Adadi and Berrada 2018</a>; <a href="6-ch-conclusion.html#ref-arrieta_explainable_2020" role="doc-biblioref">Arrieta et al. 2020</a>)</span> is an emerging field that attempts to bring transparency to such black-box models by offering techniques to increase their interpretability. Multivariate data visualization is essential for exploring features spaces and communicating interpretations of models <span class="citation">(<a href="6-ch-conclusion.html#ref-biecek_dalex_2018" role="doc-biblioref">Biecek 2018</a>; <a href="6-ch-conclusion.html#ref-biecek_explanatory_2021" role="doc-biblioref">Biecek and Burzykowski 2021</a>; <a href="6-ch-conclusion.html#ref-wickham_visualizing_2015" role="doc-biblioref">Hadley Wickham, Cook, and Hofmann 2015</a>)</span>.</p>
<!-- Structure of the chapter -->
<p>The chapter is structured as follows. Section <a href="4-ch-userstudy.html#sec:background">4.1</a> discusses several visualization methods and orthogonal and observation-based visuals before arriving at the three linear dimension reduction techniques compared in the study. Section <a href="4-ch-userstudy.html#sec:userstudy">4.2</a> describes the experimental factors, task, and accuracy measure used. The results of the study are discussed in Section <a href="4-ch-userstudy.html#sec:results">4.3</a>. Conclusions and potential future directions are discussed in Section <a href="4-ch-userstudy.html#sec:conclusion">4.4</a>. The software used for the study is described in Section <a href="4-ch-userstudy.html#sec:spinifex">4.5</a>.</p>
<div id="sec:background" class="section level2" number="4.1">
<h2><span class="header-section-number">4.1</span> Background</h2>
<p>Before discussing PCA, the grand tour, and the radial tour, this section covers orthogonal views and observation-based visuals of the full variable space. Consider data to be a complete matrix of <span class="math inline">\(n\)</span> observations across <span class="math inline">\(p\)</span> variables, <span class="math inline">\(X_{n \times p}\)</span>.</p>
<div id="scatterplot-matrix" class="section level3" number="4.1.1">
<h3><span class="header-section-number">4.1.1</span> Scatterplot matrix</h3>
<p>One could consider looking at <span class="math inline">\(p\)</span> histograms or univariate densities. Doing so will miss features in two or more dimensions. A scatterplot matrix <span class="citation">(<a href="6-ch-conclusion.html#ref-chambers_graphical_1983" role="doc-biblioref">Chambers et al. 1983</a>)</span> is a <span class="math inline">\(p \times p\)</span> matrix with univariate densities on the diagonal and all combinations of pairs of variables in off-diagonal elements. Figure <a href="4-ch-userstudy.html#fig:ch4fig2">4.2</a> shows a scatterplot matrix of the first four components of simulated data. Such displays do not scale well with dimension, quickly becoming dense. Scatterplot matrices also display information in two orthogonal dimensions; features in three dimensions will never be fully resolved.</p>
</div>
<div id="parallel-coordinates-plot" class="section level3" number="4.1.2">
<h3><span class="header-section-number">4.1.2</span> Parallel coordinates plot</h3>
<!-- PCP -->
<p>Another common way to display multivariate data is with a parallel coordinates plot <span class="citation">(<a href="6-ch-conclusion.html#ref-ocagne_coordonnees_1885" role="doc-biblioref">Ocagne 1885</a>)</span>, which shows observations by quantile or normalized values for each variable connected by lines to the quantile value in subsequent variables. Parallel coordinates plots and other observations-based visuals, such as pixel plots or Chernoff faces scale well with dimensions but poorly with observations. These are perhaps best used when there are more variables than observations.</p>
<p>Observations-based visuals have a couple of issues. They are asymmetric across variable ordering, leading to different conclusions or features being focused on due to variable order. Another notable observation-based visual is the graphical channel used to convey information. Munzner suggests that position is the visual channel that is most perceptible to humans <span class="citation">(<a href="6-ch-conclusion.html#ref-munzner_visualization_2014" role="doc-biblioref">Munzner 2014</a>)</span>. In the case of parallel coordinates plots, the horizontal axes span variables rather than the values of one variable; the loss of a display dimension to be used by most discerning visual channel should not be taken lightly.</p>
<!-- Turning to Linear DR -->
<p>At some point, we will be forced to turn to dimension reduction to scale well. Non-linear transformations bend and distort spaces are not entirely accurate or faithful to the original variable space. In light of this, we preclude non-linear techniques and instead decide on PCA, the grand tour, and the radial tour.</p>
</div>
<div id="principal-component-analysis" class="section level3" number="4.1.3">
<h3><span class="header-section-number">4.1.3</span> Principal component analysis</h3>
<p>PCA is a good baseline of comparison for linear projections because of its frequent and broad use across disciplines. PCA defines new components, linear combinations of the original variables, ordered by decreasing variation through the help of eigenvalue matrix decomposition. While the resulting dimensionality is the same size, the benefit comes from the ordered nature of the components. The data can be said to be approximated by the first several components. The exact number is subjectively selected given the variance contained by each component, typically guided using a scree plot <span class="citation">(<a href="6-ch-conclusion.html#ref-cattell_scree_1966" role="doc-biblioref">Cattell 1966</a>)</span>. Features with sizable signal regularly appear in the leading components that commonly approximate data. However, this is not always the case, and component spaces should be fully explored to look for signal in components that hold less variation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig2"></span>
<img src="figures/ch4_fig2_pca_splom.png" alt="Scatterplot matrix of the first four principal components simulated data in six dimensions. An analyst would have to view both PC1 by PC2 and PC1 by PC4 to have a thorough take on which variables attribute to the separation between clusters." width="100%"  />
<p class="caption">
Figure 4.2: Scatterplot matrix of the first four principal components simulated data in six dimensions. An analyst would have to view both PC1 by PC2 and PC1 by PC4 to have a thorough take on which variables attribute to the separation between clusters.
</p>
</div>
</div>
<div id="animated-linear-projections-tours" class="section level3" number="4.1.4">
<h3><span class="header-section-number">4.1.4</span> Animated linear projections, tours</h3>
<!-- tours intro -->
<p>A data visualization <em>tour</em> animates many linear projections over small changes in the projection basis. One of the insightful features of the tour is the object permanence of the data points; one can track the relative changes of observations as the basis moves, as opposed to discretely jumping to an orthogonal view with no intermediate information. Types of tours are distinguished by the selection of their basis paths <span class="citation">(<a href="6-ch-conclusion.html#ref-lee_state_2021" role="doc-biblioref">Lee et al. 2021</a>; <a href="6-ch-conclusion.html#ref-cook_grand_2008" role="doc-biblioref">Cook et al. 2008</a>)</span>. To contrast with the discrete orientations of PCA, we compare continuous linear projection changes with grand and radial tours.</p>
<div id="grand-tours" class="section level4" number="4.1.4.1">
<h4><span class="header-section-number">4.1.4.1</span> Grand tours</h4>
<!-- Grand tour -->
<p>Target bases are selected randomly in a grand tour <span class="citation">(<a href="6-ch-conclusion.html#ref-asimov_grand_1985" role="doc-biblioref">Asimov 1985</a>)</span>. These target bases are then geodesically interpolated for a smooth, continuous path. The grand tour is the first and most widely known tour. The random selection of target bases makes it a general unguided exploratory tool. The grand tour will make a good comparison that has continuity of data points similar to the radial tour but lacks the user control enjoyed by PCA and radial tours.</p>
</div>
<div id="manual-and-radial-tours" class="section level4" number="4.1.4.2">
<h4><span class="header-section-number">4.1.4.2</span> Manual and radial tours</h4>
<!-- Segue, highlighting lack of control -->
<p>Whether an analyst uses PCA or the grand tour, they cannot influence the basis. They cannot explore the structure identified or change the contribution of the variables. This user-control-steering is a key aspect of <em>manual</em> tours that should facilitate testing variable attribution.</p>
<!-- Manual tour -->
<p>The manual tour <span class="citation">(<a href="6-ch-conclusion.html#ref-cook_manual_1997" role="doc-biblioref">Cook and Buja 1997</a>)</span> defines its basis path by manipulating the basis contribution of a selected variable. A manipulation dimension is appended onto the projection plane, giving a full contribution to the selected variable. The target bases are then chosen to rotate this newly created manipulation space. This manipulation space similarly orthogonally restrained, the data is projected through its interpolated frames and rendered into an animation. When the contribution of one variable changes, the contributions of the other variables must also change, maintaining the orthonormality of the basis and space. A key feature of the manual tour is that it allows users to control the variable contributions to the basis. Such manipulations can be queued in advance or selected in real-time for human-in-the-loop analysis <span class="citation">(<a href="6-ch-conclusion.html#ref-karwowski_international_2006" role="doc-biblioref">Karwowski 2006</a>)</span>. Manual navigation is relatively time-consuming due to the vast volume of resulting view space and the abstract method of steering the projection basis. It is advisable first to identify a basis of particular interest and then use the manual tour as a more directed, local exploration tool to explore the sensitivity of a variable’s contribution to the feature of interest.</p>
<!-- Radial tour variant -->
<p>To simplify the task and keep its duration realistic, we consider a variant of the manual tour called a <em>radial</em> tour. In a radial tour, the selected variable can change its magnitude but not the angle of contribution; it must move along the direction of its original contribution radius. The radial tour benefits from both continuity of the data alongside grand tours and allows the user to steer via choosing the variable to rotate.</p>
<!-- spinifex -->
<p>Manual tours have been recently made available in the <strong>R</strong> package <strong>spinifex</strong> <span class="citation">(<a href="6-ch-conclusion.html#ref-spyrison_spinifex_2020" role="doc-biblioref">Spyrison and Cook 2020</a>)</span>, which facilitates manual tours (and radial variant). It also provides an interface for a layered composition of tours and exporting to .gif and .mp4 with <strong>gganimate</strong> <span class="citation">(<a href="6-ch-conclusion.html#ref-pedersen_gganimate_2020" role="doc-biblioref">Pedersen and Robinson 2020</a>)</span> or .html widget with <strong>plotly</strong> <span class="citation">(<a href="6-ch-conclusion.html#ref-sievert_interactive_2020" role="doc-biblioref">Sievert 2020</a>)</span>. It is also compatible with tours made by <strong>tourr</strong> <span class="citation">(<a href="6-ch-conclusion.html#ref-wickham_tourr:_2011" role="doc-biblioref">Hadley Wickham et al. 2011</a>)</span>. Now that we have a readily available means to produce various tours, we want to see how they fare against traditional discrete displays commonly used with PCA.</p>
</div>
</div>
</div>
<div id="sec:userstudy" class="section level2" number="4.2">
<h2><span class="header-section-number">4.2</span> User study</h2>
<!-- Overview of visual -->
<p>An experiment was constructed to assess the performance of the radial tour relative to the grand tour and PCA for interpreting the variable attribution contributing to separation between two clusters. <!-- Introduce experimental factors --> Data were simulated across three experimental factors: cluster shape, location of the cluster separation, and data dimensionality. Participant responses were collected using a web application and crowdsourced through prolific.co, <span class="citation">(<a href="6-ch-conclusion.html#ref-palan_prolific_2018" role="doc-biblioref">Palan and Schitter 2018</a>)</span> an alternative to MTurk.</p>
<div id="sec:objective" class="section level3" number="4.2.1">
<h3><span class="header-section-number">4.2.1</span> Objective</h3>
<!-- Rational for factor levels -->
<p>PCA will be used as a baseline for comparison as it is the most common linear embedding. The grand tour will act as a secondary control that will help evaluate the benefit of animation without influencing its path. Lastly, the radial tour should perform best as it benefits both from animation and user-control.</p>
<!-- Prior expectations -->
<p>Then for some subset of tasks, we expect to find that the radial tour performs most accurately. In the appendix, section <a href="4-ch-userstudy.html#sec:appendix">4.6</a>, we also regress on the last response time. Due to the absence of inputs, we expect the grand tour to perform faster than the alternatives since users can focus all of their attention on interpreting the fixed path. Conversely, we are less sure about the accuracy of such limited grand tours as there is no objective function in selecting the bases; it is possible that the random selection of the target bases altogether avoid bases showing cluster separation. However, given that the data dimensionality was modest, it seems plausible that the grand tour coincidentally regularly crossed frames with the correct information for the task.</p>
<!-- Explicit hypothesis tests -->
<p>We measure the accuracy and response time over the support of the discussed experimental factors. The null hypothesis can be stated as:</p>
<p><span class="math inline">\(~~~~H_0: \text{task accuracy does not change across visualization method} \\\)</span>
<span class="math inline">\(~~~~~H_\alpha: \text{task accuracy does change across visualization method} \\\)</span></p>
</div>
<div id="sec:expfactors" class="section level3" number="4.2.2">
<h3><span class="header-section-number">4.2.2</span> Experimental factors</h3>
<!-- Introduction to experimental factors -->
<p>In addition to visual factor, we simulate the data across three aspects. First the <em>location</em> of the difference between clusters by mixing a signal and a noise variable at different ratios, we vary the number of variables and their magnitude of cluster separation. Secondly the <em>shape</em> of the clusters, to reflect varying distributions of the data. And third, the <em>dimension</em>-ality of the data. Below we describe the levels within each factor, while Figure <a href="4-ch-userstudy.html#fig:ch4fig3">4.3</a> gives a visual representation of the levels.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig3"></span>
<img src="figures/ch4_fig3_exp_factors.png" alt="Illustration of the experimental factors, the parameter space of the independent variables, the support of our study." width="100%"  />
<p class="caption">
Figure 4.3: Illustration of the experimental factors, the parameter space of the independent variables, the support of our study.
</p>
</div>
<!-- Location mixing -->
<p>The <em>location</em> of the separation of the clusters is at the heart of the measure. It would be good to test a few varying levels. To test the sensitivity to this, we mix a noise variable with the signal-containing variable. The difference in the clusters is mixed at the following percentages: 0/100% (not mixed), 33/66%, 50/50% (evenly mixed).</p>
<!-- Shape, vc matrix -->
<p>In selecting the <em>shape</em> of the clusters, we follow the convention given by <span class="citation"><a href="6-ch-conclusion.html#ref-scrucca_mclust_2016" role="doc-biblioref">Scrucca et al.</a> (<a href="6-ch-conclusion.html#ref-scrucca_mclust_2016" role="doc-biblioref">2016</a>)</span>, where 14 variants of model families containing three clusters are defined. The name of the model family is the abbreviation of its respective volume, shape, and orientation of the clusters, the levels of which are either _E_qual or _V_ary. We use the models EEE, EEV, and EVV. For Instance, in the EEV model, the volume and shape of clusters are constant, while the shape’s orientation varies. The latter model is further modified by moving four-fifths of the data out in a “V” or banana-like shape.</p>
<!-- Dimensionality -->
<p><em>Dimension</em>-ality is tested at two modest levels, namely, in four dimensions containing three clusters and six dimensions with four clusters. Such modest dimensionality is required to bound the difficulty and search space to keep the task realistic for crowdsourcing.</p>
</div>
<div id="sec:task" class="section level3" number="4.2.3">
<h3><span class="header-section-number">4.2.3</span> Task and evaluation</h3>
<!-- segue to task and evaluation -->
<p>With our hypothesis formulated and data at hand, let us turn our attention to the task and how to evaluate it. Regardless of the visual method, the elements of the display are held constant, shown as a 2D scatterplot with an axis biplot to its left. Observations were supervised with the cluster level mapped to color and shape.</p>
<!-- Geom, clusters, explicit task -->
<p>Participants were asked to ‘check any/all variables that contribute more than average to the cluster separation green circles and orange triangles,’ which was further explained in the explanatory video as ‘mark any and all variable that carries more than their fair share of the weight, or one quarter in the case of four variables.’</p>
<!-- Instruction and video -->
<p>The instructions iterated several times in the video was: 1) use the input controls to find a frame that contains separation between the clusters of green circles and orange triangles, 2) look at the orientation of the variable contributions in the gray circle (biplot axes orientation), and 3) select all variables that contribute more than uniformed distributed cluster separation in the scatterplot. Independent with experimental level, participants were limited to 60 seconds for each evaluation of this task. This restriction did not impact many participants as the 25th, 50th, 75th quantiles of the response time were about 7, 21, and 30 seconds respectively.</p>
<!-- Evaluating measure -->
<p>The evaluation measure of this task was designed with a few of features in mind: 1) the sum of squares of the individual variable weights should be one, 2) symmetric about zero, that is, without preference to under- or over-guessing 3) heavier than linear weight with increasing distance from a uniform height. With these in mind, we define the following measure for evaluating the task.</p>
<p>Let a data <span class="math inline">\(\textbf{X}_{n,~p,~k}\)</span> be a simulation containing clusters of observations of different distributions. Where <span class="math inline">\(n\)</span> is the number of observations, <span class="math inline">\(p\)</span> is the number of variables, and <span class="math inline">\(k\)</span> indicates the number of the cluster an observation belongs. Cluster membership is exclusive; an observation cannot belong to more than one cluster.
<!-- W, weights -->
We define weights, <span class="math inline">\(w\)</span> as a vector explaining the variable-wise difference between two clusters. Namely, the difference of each variable between clusters, as a proportion of the total difference, less <span class="math inline">\(1/p\)</span>, the amount of difference each variable would hold if it were uniformly distributed. <!-- R, participant responses -->Participant responses are a logical value for each variable - whether or not the participant thinks each variable separates the two clusters more than uniformly distributed separation.</p>
<!-- __Current measure:__ -->
<p><span class="math display">\[\begin{align*}
  w_{j} &amp;=\frac{(\overline{X}_{\cdot, j=1, k=1} - \overline{X}_{\cdot, 1, 2}, ~...~ 
    (\overline{X}_{\cdot, p, 1} - \overline{X}_{\cdot, p, 2})}
    {\sum_{j=1}^{p}(|\overline{X}_{\cdot, j, k=1} - \overline{X}_{\cdot, j, 2}|)} - \frac{1}{p} \shortintertext{Where accuracy, A, is defined as:}
  A &amp;= \sum_{j=1}^{p}I(j) \cdot sign(w_j) \cdot w^2
\end{align*}\]</span></p>
<p>Where <span class="math inline">\(I(j)\)</span> is the indicator function, the binary response for variable <span class="math inline">\(j\)</span>. Figure <a href="4-ch-userstudy.html#fig:ch4fig4">4.4</a> shows one frame of a simulation with its observed variable separation (wide bars), expected uniform separation (dashed line), and accuracy if selected (thin lines).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig4"></span>
<img src="figures/ch4_fig4_accuracy_measure.png" alt="(L), PCA biplot of the components showing the most cluster separation with (R) illustration of the magnitude of cluster separation is for each variable (bars) and the weight of the variable accuracy if selected (red/green lines). The horizontal dashed line is $1 / p$, the amount of separation each variable would have if evenly distributed. The weights equal the signed square of the difference between each variable value and the dashed line." width="100%"  />
<p class="caption">
Figure 4.4: (L), PCA biplot of the components showing the most cluster separation with (R) illustration of the magnitude of cluster separation is for each variable (bars) and the weight of the variable accuracy if selected (red/green lines). The horizontal dashed line is <span class="math inline">\(1 / p\)</span>, the amount of separation each variable would have if evenly distributed. The weights equal the signed square of the difference between each variable value and the dashed line.
</p>
</div>
</div>
<div id="sec:standardization" class="section level3" number="4.2.4">
<h3><span class="header-section-number">4.2.4</span> Visual design standardization</h3>
<!-- Background for methodology, application here -->
<p>The factors are tested within-participant, with each visual being evaluated twice by each participant. The order that experimental factors are experienced is controlled with the assignment, as illustrated in Figure <a href="4-ch-userstudy.html#fig:ch4fig5">4.5</a>. Below we cover the visual design standardization and the input and display within each factor.</p>
<!-- Aesthetic standardization -->
<p>The visualization methods were standardized wherever possible. Data were displayed as 2D scatterplots with biplots <span class="citation">(<a href="6-ch-conclusion.html#ref-gabriel_biplot_1971" role="doc-biblioref">Gabriel 1971</a>)</span>, a visual with variable contributions inscribed on a unit circle. All aesthetic values (colors, shapes, sizes, absence of legend, and axis titles) were constant. Variable contributions were always shown left of the scatterplot embeddings with their aesthetic values consistent. What did vary between factors were their inputs.</p>
<!-- PCA -->
<p>PCA inputs allowed users to select between the top four principal components for both the <span class="math inline">\(x\)</span>- and <span class="math inline">\(y\)</span>-axes regardless of the data dimensionality (four or six). Data was simulated to have cluster separation within the 2nd to 4th components. Cluster separation was sampled to not burying signal in 5th and 6th components (not selectable in PCA input), in the interest of simplicity and time. <!-- Grand tours -->There was no user input for the grand tour; users were instead shown a 15-second animation of the same randomly selected path. Participants could view the same clip up to four times within the time limit. <!-- Radial tours -->Radial tours were also displayed at five frames per second with a step size of 0.1 radians between interpolated frames. Users were able to swap between variables. Selecting a new variable resets the animation where the new variable is manipulated to a full, zero, and then back to its initial contribution. The complete animation of any variable takes about 20 seconds and is almost entirely in the projection frame at around six seconds. The starting basis was initialized to a half-clock design, where the variables were evenly distributed in half of the circle. This design was created to be variable agnostic while maximizing the independence of the variables.</p>
</div>
<div id="data-simulation" class="section level3" number="4.2.5">
<h3><span class="header-section-number">4.2.5</span> Data simulation</h3>
<!-- Clusters and correlation -->
<p>Each dimension is originally distributed as <span class="math inline">\(\mathcal{N}(0, 1)\)</span>, given the covariance set by the shape factor. Clusters were originally separated by a distance of two before location mixing. Signal variables had a correlation of 0.9 when they had equal orientation and -0.9 when their orientations vary. Noise variables were restricted to zero correlation. Each cluster is simulated with 140 observations and is offset in a variable that did not distinguish previous variables.</p>
<!-- Apply shape and location transformations -->
<p>Clusters of the EVV shape are transformed to the banana-chevron shape (illustrated in figure <a href="4-ch-userstudy.html#fig:ch4fig3">4.3</a>, shape row). Then location mixing is applied by post-multiplying a (2x2) rotation matrix to the signal variable and a noise variable for the clusters in question.<!-- Preprocess and replicate and save --> All variables are then standardized by standard deviation. The rows and columns are then shuffled randomly. The observation’s cluster and order of shuffling are attached to the data and saved.</p>
<!-- Iterating over factor -->
<p>Each of these replications is then iterated with each level of the factor. For PCA, projections were saved for each of the 12 pairs of the top four principal components. We first save two basis paths of differing dimensions for the grand tour before each replication is projected through the common basis path. Each simulation’s variable order was previously shuffled effectually randomizing cluster separation shown, while mitigating bias from fringe selection of target bases. The resulting animations were saved as .gif files. The radial tour starts at either the four or six variable “half-clock” basis, where each variable has a uniform contribution in the right half with no variable contributing in the competing opposite direction. This acts to minimize the dependence between variable contributions. A radial tour is then produced for each variable and saved as a .gif.</p>
</div>
<div id="randomized-factor-assignment" class="section level3" number="4.2.6">
<h3><span class="header-section-number">4.2.6</span> Randomized factor assignment</h3>
<!-- Introduction -->
<p>Now, with simulation and their artifacts in hand, we explain how the experimental factors are assigned and illustrate how this is experienced from a participant’s perspective.</p>
<!-- Periods, exp factor assignment -->
<p>We section the study into three periods. Each period is linked to a randomized level of factor visualization and the location. The order of dimension and shape are of secondary interest and are held constant in increasing order of difficultly; four then six dimensions and EEE, EEV, then EVV-banana, respectively.</p>
<!-- Training and evaluation -->
<p>Each period starts with an untimed training task at the simplest remaining experimental levels; location = 0/100%, shape = EEE, and four dimensions with three clusters. This serves to introduce and familiarize participants with input and visual differences. After the training, the participant performs on two trials with the same factor and location level across the increasing difficulty of dimension and shape. The plot was removed after 60 seconds, though this limit was rarely reached by participants.</p>
<!-- Factor*location nested latin square -->
<p>The order of the factor and location levels is randomized with a nested Latin square where all levels of the visual factor are exhausted before advancing to the next level of location. That means we need <span class="math inline">\(3!^2 = 36\)</span> participants to evaluate all permutations of the experimental factors once. This randomization controls for potential learning effects the participant may receive. Figure <a href="4-ch-userstudy.html#fig:ch4fig5">4.5</a> illustrates how an arbitrary participant experiences the experimental factors.</p>
<!-- Nested latin square assignment -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig5"></span>
<img src="figures/ch4_fig5_randomization_MANUAL.PNG" alt="Illustration of how a hypothetical participant 63 is assigned experimental factors. Each of the 6 factor order permutations is exhausted before iterating to the next permutation of location order." width="100%"  />
<p class="caption">
Figure 4.5: Illustration of how a hypothetical participant 63 is assigned experimental factors. Each of the 6 factor order permutations is exhausted before iterating to the next permutation of location order.
</p>
</div>
<!-- Pilot study; 3 even evaluations of each -->
<p>Through pilot studies sampled by convenience (information technology and statistics Ph.D. students attending Monash University), we predict that we need three full evaluations to properly power our study; we set out to crowdsource <span class="math inline">\(N = 3 \cdot 3!^2 = 108\)</span> participants.</p>
</div>
<div id="sec:articipants" class="section level3" number="4.2.7">
<h3><span class="header-section-number">4.2.7</span> Participants</h3>
<p>We recruited <span class="math inline">\(N = 108\)</span> participants via prolific.co <span class="citation">(<a href="6-ch-conclusion.html#ref-palan_prolific_2018" role="doc-biblioref">Palan and Schitter 2018</a>)</span>. We filtered participants based on their claimed education requiring that they have completed at least an undergraduate degree (some 58,700 of the 150,400 users at the time); we apply this filter under the premise that linear projections and biplot displays will not be regularly used for consumption by general audiences. There is also the implicit filter that Prolific participants must be at least 18 years of age and implicit biases of timezone, location, and language. Participants were compensated for their time at 7.50 per hour, whereas the mean duration of the survey was about 16 minutes. We cannot preclude previous knowledge or experience with the factors but validate this assumption in the follow-up survey asking about familiarity with the factors. The appendix contains a heatmap distribution of age and education paneled across preferred pronouns of the participants that completed the survey, who are relatively young, well educated, and slightly more likely to identify as males.</p>
</div>
<div id="data-collection" class="section level3" number="4.2.8">
<h3><span class="header-section-number">4.2.8</span> Data collection</h3>
<!-- App, data collection, network issues -->
<p>Data were recorded by a <strong>shiny</strong> application and written to a Google Sheet after each third of the study. Especially at the start of the study, participants experienced adverse network conditions due to the volume of participants hitting the application with modest allocated resources. In addition to this, API read/write limitations further hindered data collection. To mitigate this, we throttled the number of participants and over-collect survey trials until we received our target three evaluations of all permutation levels.</p>
<!-- Preprocessing steps -->
<p>The processing steps were minimal. First, we format to an analysis-ready form, decoding values to a more human-readable state, and add a flag indicating whether the survey had complete data. We filter to only the latest three complete studies of each experimental factor, which should have experienced the most minor adverse network conditions. The bulk of the studies removed were partial data and a few over-sampled permutations. This brings us to the 108 studies described in the chapter, from which models and aggregation tables were built. The post-study surveys were similarly decoded to human-readable format and then filtered to include only those 84 associated with the final 108 studies.</p>
<p>The code, response files, their analyses, and the study application are publicly available at on GitHub; .</p>
</div>
</div>
<div id="sec:results" class="section level2" number="4.3">
<h2><span class="header-section-number">4.3</span> Results</h2>
<p>To recap, the primary response variable is task accuracy, as defined in section <a href="4-ch-userstudy.html#sec:task">4.2.3</a>. The parallel analysis of the log response time is provided in the appendix. We have two primary data sets; the user study evaluations and the post-study survey. The former is the 108 participants with the explanatory variables: visual factor, location of the cluster separation signal, the shape of variance-covariance matrix, and the dimensionality of the data. Experimental factors and randomization were discussed in section <a href="4-ch-userstudy.html#sec:expfactors">4.2.2</a>. The survey was completed by 84 of these 108 people. It collected demographic information (preferred pronoun, age, and education), and subjective measures for each factor (preference, familiarity, ease of use, and confidence).</p>
<p>Below we build a battery of mixed regression models to explore the degree of the evidence and the size of the effects from the experimental factors. The, we use likert plots and rank-sum tests to compare the subjective measures between the visual factors.</p>
<div id="accuracy-regression" class="section level3" number="4.3.1">
<h3><span class="header-section-number">4.3.1</span> Accuracy regression</h3>
<!-- Introduce regression model, explaining accuracy, and random effect term -->
<p>To more thoroughly examine explanatory variables, we regress against accuracy. All models have a random effect term on the participant and the simulation. These terms explain the error that can be attributed to the effect of the individual participant and variation due to the random sampling data.</p>
<!-- Building a battery of models -->
<p>In building a set of models to test, we include all single term models with all independent terms. We also include an interaction term for factor and location, allowing for the slope of each location to change across each level of the factor. For comparison, an overly complex model with all interaction terms is included. The matrices for models with more than a two terms is rank deficient; there is not enough varying information in the data to explain all interacting terms.</p>
<!-- Y1 accuracy regression -->
<p><span class="math display">\[
\begin{array}{ll}
\textbf{Fixed effects}           &amp;\textbf{Full model} \\
\alpha                           &amp;\widehat{Y} = \mu + \alpha_i + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha + \beta + \gamma + \delta &amp;\widehat{Y} = \mu + \alpha_i + \beta_j + \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha \cdot \beta + \gamma + \delta &amp;\widehat{Y} = \mu + \alpha_i \cdot \beta_j + \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha \cdot \beta \cdot \gamma + \delta &amp;\widehat{Y} = \mu + \alpha_i \cdot \beta_j \cdot \gamma_k + \delta_l + \textbf{Z} + \textbf{W} + \epsilon \\
\alpha \cdot \beta \cdot \gamma \cdot \delta &amp;\widehat{Y} = \mu + \alpha_i \cdot \beta_j \cdot \gamma_k \cdot \delta_l + \textbf{Z} + \textbf{W} + \epsilon
\end{array}
\]</span>
<span class="math display">\[
\begin{array}{ll}
\text{where }
&amp;\alpha_i \text{, fixed term for factor}~|~i\in (\text{pca, grand, radial}) \\
&amp;\beta_j  \text{, fixed term for location}~|~j\in (\text{0/100\%, 33/66\%, 50/50\%}) \text{ \% noise/signal mixing} \\
&amp;\gamma_k \text{, fixed term for shape}~|~k\in (\text{EEE, EEV, EVV banana}) \text{ model shapes} \\
&amp;\delta_l \text{, fixed term for dimension}~|~l\in (\text{4 variables \&amp; 3 cluster, 6 variables \&amp; 4 clusters}) \\
&amp;\mu \text{ is the intercept of the model including the mean of random effect} \\
&amp;\textbf{Z} \sim \mathcal{N}(0,~\tau), \text{ the error of the random effect of participant} \\
&amp;\textbf{W} \sim \mathcal{N}(0,~\upsilon), \text{ the error of the random effect of simulation} \\
&amp;\epsilon   \sim \mathcal{N}(0,~\sigma), \text{ the remaining error in the model} \\
\end{array}
\]</span></p>
<!-- Y1 model comparisons -->
<table class="table table-striped" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:ch4tab1">Table 4.1: </span>Model performance of random effect models regressing accuracy. Each model includes a random effect term of the participant explaining the individual’s influence on accuracy. Complex models perform better in terms of <span class="math inline">\(R^2\)</span> and RMSE, yet AIC and BIC penalizes their large number of fixed effects in favor of the much simpler model containing only the visual factor. Conditional <span class="math inline">\(R^2\)</span> includes the random effects, while marginal does not.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Fixed effects
</th>
<th style="text-align:left;">
No. levels
</th>
<th style="text-align:left;">
No. terms
</th>
<th style="text-align:center;">
AIC
</th>
<th style="text-align:center;">
BIC
</th>
<th style="text-align:center;">
R2 cond.
</th>
<th style="text-align:center;">
R2 marg.
</th>
<th style="text-align:center;">
RMSE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
a
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:center;">
1000
</td>
<td style="text-align:center;">
1027
</td>
<td style="text-align:center;">
0.180
</td>
<td style="text-align:center;">
0.022
</td>
<td style="text-align:center;">
0.462
</td>
</tr>
<tr>
<td style="text-align:left;">
a+b+c+d
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:center;">
1026
</td>
<td style="text-align:center;">
1075
</td>
<td style="text-align:center;">
0.187
</td>
<td style="text-align:center;">
0.030
</td>
<td style="text-align:center;">
0.460
</td>
</tr>
<tr>
<td style="text-align:left;">
a*b+c+d
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
12
</td>
<td style="text-align:center;">
1036
</td>
<td style="text-align:center;">
1103
</td>
<td style="text-align:center;">
0.198
</td>
<td style="text-align:center;">
0.043
</td>
<td style="text-align:center;">
0.457
</td>
</tr>
<tr>
<td style="text-align:left;">
a*b*c+d
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
28
</td>
<td style="text-align:center;">
1069
</td>
<td style="text-align:center;">
1207
</td>
<td style="text-align:center;">
0.238
</td>
<td style="text-align:center;">
0.080
</td>
<td style="text-align:center;">
0.447
</td>
</tr>
<tr>
<td style="text-align:left;">
a*b*c*d
</td>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
54
</td>
<td style="text-align:center;">
1125
</td>
<td style="text-align:center;">
1380
</td>
<td style="text-align:center;">
0.282
</td>
<td style="text-align:center;">
0.111
</td>
<td style="text-align:center;">
0.438
</td>
</tr>
</tbody>
</table>
<!-- Y1 coefficients of ABcd -->
<table class="table table-striped" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:ch4tab2">Table 4.2: </span>The task accuracy model coefficients for <span class="math inline">\(\widehat{Y} = \alpha \cdot \beta + \gamma + \delta\)</span>, with factor = grand, location = 0/100%, and shape = EEE held as baselines. Factor being radial is the fixed term with the strongest evidence supporting the hypothesis. When crossing the visual factor there is some evidence suggesting radial performs worse with 33/66% mixing. The model fit is based on the 648 evaluations by the 108 participants.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Std. Error
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
t value
</th>
<th style="text-align:right;">
Pr(&gt;|t|)
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
0.03
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
44.2
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:right;">
0.66
</td>
<td style="text-align:left;">
</td>
</tr>
<tr grouplength="2">
<td colspan="7" style="border-bottom: 1px solid;">
<strong>factor</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorpca
</td>
<td style="text-align:right;">
-0.15
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
622.4
</td>
<td style="text-align:right;">
-1.74
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorradial
</td>
<td style="text-align:right;">
0.22
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
618.6
</td>
<td style="text-align:right;">
2.46
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:left;">
<ul>
<li></td>
</tr>
<tr grouplength="5">
<td colspan="7" style="border-bottom: 1px solid;">
<strong>fixed effects</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Location33/66%
</td>
<td style="text-align:right;">
0.10
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
84.9
</td>
<td style="text-align:right;">
1.09
</td>
<td style="text-align:right;">
0.28
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Location50/50%
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
83.0
</td>
<td style="text-align:right;">
0.58
</td>
<td style="text-align:right;">
0.56
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
ShapeEEV
</td>
<td style="text-align:right;">
0.04
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
11.5
</td>
<td style="text-align:right;">
0.79
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Shapebanana
</td>
<td style="text-align:right;">
-0.03
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
11.5
</td>
<td style="text-align:right;">
-0.48
</td>
<td style="text-align:right;">
0.64
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Dim6
</td>
<td style="text-align:right;">
-0.06
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:right;">
11.5
</td>
<td style="text-align:right;">
-1.39
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:left;">
</td>
</tr>
<tr grouplength="4">
<td colspan="7" style="border-bottom: 1px solid;">
<strong>interactions</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorpca:Location33/66%
</td>
<td style="text-align:right;">
0.06
</td>
<td style="text-align:right;">
0.13
</td>
<td style="text-align:right;">
587.3
</td>
<td style="text-align:right;">
0.49
</td>
<td style="text-align:right;">
0.63
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorradial:Location33/66%
</td>
<td style="text-align:right;">
-0.28
</td>
<td style="text-align:right;">
0.13
</td>
<td style="text-align:right;">
577.6
</td>
<td style="text-align:right;">
-2.14
</td>
<td style="text-align:right;">
0.03
</td>
<td style="text-align:left;">
<ul>
<li></td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorpca:Location50/50%
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
0.13
</td>
<td style="text-align:right;">
589.6
</td>
<td style="text-align:right;">
0.68
</td>
<td style="text-align:right;">
0.50
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorradial:Location50/50%
</td>
<td style="text-align:right;">
-0.10
</td>
<td style="text-align:right;">
0.13
</td>
<td style="text-align:right;">
588.0
</td>
<td style="text-align:right;">
-0.77
</td>
<td style="text-align:right;">
0.44
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul>
<!-- Model selection and coefficients -->
<p>Table <a href="4-ch-userstudy.html#tab:ch4tab1">4.1</a> compares the model summaries across increasing complexity. We select the <span class="math inline">\(\alpha \cdot \beta + \gamma + \delta\)</span> model to explore in more detail. Table <a href="4-ch-userstudy.html#tab:ch4tab2">4.2</a> looks at the coefficients for this model.</p>
<!-- Conditional effects of variables -->
<p>We also want to visually explore the conditional variables in the model. Figure <a href="4-ch-userstudy.html#fig:ch4fig6">4.6</a> explores violin plots of accuracy by factor while faceting on the location (vertical) and shape (horizontal). Use of the radial visual, on average, increases the accuracy, and especially so when the location of signal mixing is not 33/66%.</p>
<!-- Violin plots and test overlay for Y1 factors -->
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig6"></span>
<img src="figures/ch4_fig6_ABcd_violins.png" alt="Violin plots of terms of the model $\widehat{Y} = \alpha \cdot \beta + \gamma + \delta$. Overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked-sum tests suitable for handling discrete data. Participants are more confident and find the radial tour easier to use than the grand tour. Participants claim low familiarity, as we expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task." width="100%"  />
<p class="caption">
Figure 4.6: Violin plots of terms of the model <span class="math inline">\(\widehat{Y} = \alpha \cdot \beta + \gamma + \delta\)</span>. Overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked-sum tests suitable for handling discrete data. Participants are more confident and find the radial tour easier to use than the grand tour. Participants claim low familiarity, as we expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task.
</p>
</div>
</div>
<div id="subjective-measures" class="section level3" number="4.3.2">
<h3><span class="header-section-number">4.3.2</span> Subjective measures</h3>
<!-- Introduce subjective measures from n=84 survey responses -->
<p>The 84 evaluations of the post-study survey also collect four subjective measures for each factor. Figure <a href="4-ch-userstudy.html#fig:ch4fig7">4.7</a> shows the Likert plots, or stacked percentage bar plots, alongside violin plots with the same non-parametric, ranked sum tests previously used. Participants preferred to use radial for this task. Participants were also more confident of their answers and found radial tours easier than grand tours. All factors have reportedly low familiarity, as expected from crowdsourced participants.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4fig7"></span>
<img src="figures/ch4_fig7_subjective_measures.png" alt="The subjective measures of the 84 responses of the post-study survey, five discrete Likert scale levels of agreement (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests." width="100%"  />
<p class="caption">
Figure 4.7: The subjective measures of the 84 responses of the post-study survey, five discrete Likert scale levels of agreement (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests.
</p>
</div>
</div>
</div>
<div id="sec:conclusion" class="section level2" number="4.4">
<h2><span class="header-section-number">4.4</span> Conclusion</h2>
<!-- Context -->
<p>Data visualization is an integral part of EDA. However, thorough exploration of data in high dimensions become difficult. Previous methods offer no means for an analyst to impact the projection basis. The manual tour provides a mechanism for changing the contribution of a selected variable to the basis. Giving analysts such control should facilitate the exploration of variable-level sensitivity to the identified structure. We find strong evidence that using the radial tour improves the accuracy relative to PCA or the grand tour on the supervised cluster task assigning variable attribution to the separation of the two clusters.</p>
<!-- Recap study -->
<p>This chapter discussed a with-in participant user study (<span class="math inline">\(n=108\)</span>) comparing the efficacy of three linear projection techniques. The participants performed a supervised cluster task, explicitly identifying which variables contribute to separating two target clusters. This was evaluated evenly over four experimental factors. In summary, we find strong evidence that using the radial tour leads to a sizable accuracy increase. In the appendix we find evidence for a small change in response time, with PCA being fastest, then the grand tour followed by the radial tour. The effect sizes on accuracy are large relative to the change from the other experimental factors, though smaller than the random effect of the participant. The radial tour was subjectively preferred, leading to more confidence in answers, and increased ease of use than the alternatives.</p>
</div>
<div id="sec:spinifex" class="section level2" number="4.5">
<h2><span class="header-section-number">4.5</span> Accompanying tool: radial tour application</h2>
<p>We have produced an application to illustrate the radial tour to accompany this study. The <strong>R</strong> package, <strong>spinifex</strong>, <span class="citation">(<a href="6-ch-conclusion.html#ref-spyrison_spinifex_2020" role="doc-biblioref">Spyrison and Cook 2020</a>)</span> is free, open-source and now contains a <strong>shiny</strong> <span class="citation">(<a href="6-ch-conclusion.html#ref-chang_shiny_2020" role="doc-biblioref">Chang et al. 2020</a>)</span> application that allows users to apply various preprocessing tasks and interactively explore their data via interactive radial tour. Example datasets are provided with the ability to upload data. The .html widget produced is a more interactive variant relative to the one used in the user study. Screen captures and more details are provided in the appendix. Run the following <strong>R</strong> code will run the application locally.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="4-ch-userstudy.html#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="do">## Download:</span></span>
<span id="cb3-2"><a href="4-ch-userstudy.html#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;spinifex&quot;</span>, <span class="at">dependencies =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-3"><a href="4-ch-userstudy.html#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="do">## Run interactive app demonstrating the radial tour:</span></span>
<span id="cb3-4"><a href="4-ch-userstudy.html#cb3-4" aria-hidden="true" tabindex="-1"></a>spinifex<span class="sc">::</span><span class="fu">run_app</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4zappfig4"></span>
<img src="figures/ch4_zapp_fig4_app_pg1.PNG" alt="Process data tab, interactively loads or select data, check which variables to project, and optionally scale columns by standard deviation." width="100%"  />
<p class="caption">
Figure 4.8: Process data tab, interactively loads or select data, check which variables to project, and optionally scale columns by standard deviation.
</p>
</div>
<p>In the initial tab, Figure <a href="4-ch-userstudy.html#fig:ch4zappfig4">4.8</a>, users upload their own (.csv, .rds, or .rda) data or select from predefined data sets. The numeric columns appear as a list of variables to include in the projection. Below that, a line displays whether or not missing rows were removed. Scaling by standard deviation is included by default, as this is a common transformation used to explore linear projections of spaces. Summaries of the raw data and processed numeric data are displayed to illustrate how the data was read and its transformation.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4zappfig5"></span>
<img src="figures/ch4_zapp_fig5_app_pg2.PNG" alt="Radial tour tab, interactively create radial tours, changing the manipulation variable, and color or shape of the resulting manual tour. Here, the palmer penguins data is being explored, bill length was selected to manipulate as it is the only variable separating the green cluster from the orange. By mapping shape to island of observation, we also notice that the species in green live on all three islands, while the other species live only on one of the islands." width="100%"  />
<p class="caption">
Figure 4.9: Radial tour tab, interactively create radial tours, changing the manipulation variable, and color or shape of the resulting manual tour. Here, the palmer penguins data is being explored, bill length was selected to manipulate as it is the only variable separating the green cluster from the orange. By mapping shape to island of observation, we also notice that the species in green live on all three islands, while the other species live only on one of the islands.
</p>
</div>
<p>The second tab, Figure <a href="4-ch-userstudy.html#fig:ch4zappfig5">4.9</a> contains interaction for selecting the manipulation variable and non-numeric columns can be used to change the color and shape of the data points in the projection. The radial tour is created in real-time, animated as an interactive <strong>plotly</strong> .html widget. The application offers users a fast, intuitive introduction elucidating what the radial tour does and some of the features offered.</p>
</div>
<div id="sec:appendix" class="section level2" number="4.6">
<h2><span class="header-section-number">4.6</span> Extended analysis</h2>
<p>This section covers peripheral and extended analysis. First we explore the demographics of the participants. Then we extend a parallel modeling analysis on log response time. Lastly, we look at the effect ranges and marginal effects of the random effect of the participants and data simulation.</p>
<div id="survey-participant-demographics" class="section level3 unnumbered">
<h3>Survey participant demographics</h3>
<p>The target population is relatively well-educated people, as linear projections may prove difficult for generalized consumption. Hence we restrict Prolific.co participants to those with an undergraduate degree (58,700 of the 150,400 users at the study time). From this cohort, 108 performed a complete study. Of these participants, 84 submitted the post-study survey, represented in the following heatmap. All participants were compensated for their time at 7.50 per hour, with a mean time of about 16 minutes. Figure <a href="4-ch-userstudy.html#fig:ch4zappfig1">4.10</a> shows a heat map of the demographics for these 84 participants.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4zappfig1"></span>
<img src="figures/ch4_zapp_fig1_survey_demograpics.png" alt="Heatmaps of survey participant demographics; counts of age group by completed education as faceted across preferred pronoun. Our sample tended to be between 18 and 35 years of age with an undergraduate or graduate degree." width="100%"  />
<p class="caption">
Figure 4.10: Heatmaps of survey participant demographics; counts of age group by completed education as faceted across preferred pronoun. Our sample tended to be between 18 and 35 years of age with an undergraduate or graduate degree.
</p>
</div>
</div>
<div id="response-time-regression" class="section level3" number="4.6.1">
<h3><span class="header-section-number">4.6.1</span> Response time regression</h3>
<!-- Time as secondary interest, Y2 -->
<p>As a secondary explanatory variable, we also want to look at time. First, we take the log transformation of time as it is right-skewed. We repeat the same modeling procedure: 1) Compare the performance of a battery of all additive and multiplicative models. Table <a href="4-ch-userstudy.html#tab:timeCompTbl">4.3</a> shows the higher level performance of these models over increasing model complexity. 2) Select the model with the same effect terms, <span class="math inline">\(\alpha \cdot \beta + \gamma + \delta\)</span>, and examine its coefficients, displayed in Table <a href="4-ch-userstudy.html#tab:timeCoefTbl">4.4</a>.</p>
<!-- Y2 model comparisons, continue to use ABcd -->
<table class="table table-striped" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:timeCompTbl">Table 4.3: </span>Model performance regressing on log response time [seconds], <span class="math inline">\(\widehat{Y_2}\)</span> random effect models, where each includes random effect terms for participants and simulations. We see the same trade-off where AIC/BIC prefer the simplest factor model, while <span class="math inline">\(R^2\)</span> and RMSE is the largest in the full multiplicative model. We again select the model <span class="math inline">\(\alpha \cdot \beta + \gamma + \delta\)</span> to explore further as it has relatively high marginal <span class="math inline">\(R^2\)</span> while having much less complexity than the complete interaction model. Conditional <span class="math inline">\(R^2\)</span> includes the random effects, while marginal does not.
</caption>
<thead>
<tr>
<th style="text-align:left;">
Fixed effects
</th>
<th style="text-align:left;">
No. levels
</th>
<th style="text-align:left;">
No. terms
</th>
<th style="text-align:center;">
AIC
</th>
<th style="text-align:center;">
BIC
</th>
<th style="text-align:center;">
R2 cond.
</th>
<th style="text-align:center;">
R2 marg.
</th>
<th style="text-align:center;">
RMSE
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
a
</td>
<td style="text-align:left;">
1
</td>
<td style="text-align:left;">
3
</td>
<td style="text-align:center;">
1000
</td>
<td style="text-align:center;">
1027
</td>
<td style="text-align:center;">
0.180
</td>
<td style="text-align:center;">
0.022
</td>
<td style="text-align:center;">
0.462
</td>
</tr>
<tr>
<td style="text-align:left;">
a+b+c+d
</td>
<td style="text-align:left;">
4
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:center;">
1026
</td>
<td style="text-align:center;">
1075
</td>
<td style="text-align:center;">
0.187
</td>
<td style="text-align:center;">
0.030
</td>
<td style="text-align:center;">
0.460
</td>
</tr>
<tr>
<td style="text-align:left;">
a*b+c+d
</td>
<td style="text-align:left;">
5
</td>
<td style="text-align:left;">
12
</td>
<td style="text-align:center;">
1036
</td>
<td style="text-align:center;">
1103
</td>
<td style="text-align:center;">
0.198
</td>
<td style="text-align:center;">
0.043
</td>
<td style="text-align:center;">
0.457
</td>
</tr>
<tr>
<td style="text-align:left;">
a*b*c+d
</td>
<td style="text-align:left;">
8
</td>
<td style="text-align:left;">
28
</td>
<td style="text-align:center;">
1069
</td>
<td style="text-align:center;">
1207
</td>
<td style="text-align:center;">
0.238
</td>
<td style="text-align:center;">
0.080
</td>
<td style="text-align:center;">
0.447
</td>
</tr>
<tr>
<td style="text-align:left;">
a*b*c*d
</td>
<td style="text-align:left;">
15
</td>
<td style="text-align:left;">
54
</td>
<td style="text-align:center;">
1125
</td>
<td style="text-align:center;">
1380
</td>
<td style="text-align:center;">
0.282
</td>
<td style="text-align:center;">
0.111
</td>
<td style="text-align:center;">
0.438
</td>
</tr>
</tbody>
</table>
<!-- Y2 coeffiecients -->
<table class="table table-striped" style="font-size: 12px; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:timeCoefTbl">Table 4.4: </span>Model coefficients for log response time [seconds] <span class="math inline">\(\widehat{Y_2} = \alpha \cdot \beta + \gamma + \delta\)</span>, with factor = PCA, location = 0/100%, and shape = EEE held as baselines. Location = 50/50% is the fixed term with the strongest evidence and takes less time. In contrast, the interaction term location = 50/50%:shape = EEV has the most evidence and takes much longer on average.
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Estimate
</th>
<th style="text-align:right;">
Std. Error
</th>
<th style="text-align:right;">
df
</th>
<th style="text-align:right;">
t value
</th>
<th style="text-align:right;">
Pr(&gt;|t|)
</th>
<th style="text-align:left;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
2.48
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
42.8
</td>
<td style="text-align:right;">
17.41
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
***
</td>
</tr>
<tr grouplength="2">
<td colspan="7" style="border-bottom: 1px solid;">
<strong>Factor</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorpca
</td>
<td style="text-align:right;">
0.23
</td>
<td style="text-align:right;">
0.12
</td>
<td style="text-align:right;">
567.6
</td>
<td style="text-align:right;">
1.97
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:left;">
<ul>
<li></td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorradial
</td>
<td style="text-align:right;">
0.39
</td>
<td style="text-align:right;">
0.12
</td>
<td style="text-align:right;">
571.9
</td>
<td style="text-align:right;">
3.29
</td>
<td style="text-align:right;">
0.00
</td>
<td style="text-align:left;">
**
</td>
</tr>
<tr grouplength="5">
<td colspan="7" style="border-bottom: 1px solid;">
<strong>Fixed effects</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Location33/66%
</td>
<td style="text-align:right;">
0.29
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
42.0
</td>
<td style="text-align:right;">
2.06
</td>
<td style="text-align:right;">
0.05
</td>
<td style="text-align:left;">
<ul>
<li></td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Location50/50%
</td>
<td style="text-align:right;">
0.07
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
40.5
</td>
<td style="text-align:right;">
0.54
</td>
<td style="text-align:right;">
0.59
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
ShapeEEV
</td>
<td style="text-align:right;">
-0.15
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
8.3
</td>
<td style="text-align:right;">
-1.61
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Shapebanana
</td>
<td style="text-align:right;">
-0.13
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:right;">
8.3
</td>
<td style="text-align:right;">
-1.42
</td>
<td style="text-align:right;">
0.19
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Dim6
</td>
<td style="text-align:right;">
0.14
</td>
<td style="text-align:right;">
0.08
</td>
<td style="text-align:right;">
8.3
</td>
<td style="text-align:right;">
1.90
</td>
<td style="text-align:right;">
0.09
</td>
<td style="text-align:left;">
</td>
</tr>
<tr grouplength="4">
<td colspan="7" style="border-bottom: 1px solid;">
<strong>Interactions</strong>
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorpca:Location33/66%
</td>
<td style="text-align:right;">
-0.24
</td>
<td style="text-align:right;">
0.18
</td>
<td style="text-align:right;">
580.9
</td>
<td style="text-align:right;">
-1.34
</td>
<td style="text-align:right;">
0.18
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorradial:Location33/66%
</td>
<td style="text-align:right;">
-0.48
</td>
<td style="text-align:right;">
0.18
</td>
<td style="text-align:right;">
583.1
</td>
<td style="text-align:right;">
-2.63
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:left;">
**
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorpca:Location50/50%
</td>
<td style="text-align:right;">
-0.12
</td>
<td style="text-align:right;">
0.18
</td>
<td style="text-align:right;">
578.6
</td>
<td style="text-align:right;">
-0.69
</td>
<td style="text-align:right;">
0.49
</td>
<td style="text-align:left;">
</td>
</tr>
<tr>
<td style="text-align:left;padding-left: 2em;" indentlevel="1">
Factorradial:Location50/50%
</td>
<td style="text-align:right;">
-0.08
</td>
<td style="text-align:right;">
0.18
</td>
<td style="text-align:right;">
580.9
</td>
<td style="text-align:right;">
-0.43
</td>
<td style="text-align:right;">
0.67
</td>
<td style="text-align:left;">
</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul>
</div>
<div id="random-effect-ranges" class="section level3 unnumbered">
<h3>Random effect ranges</h3>
<!-- Random effect terms specify source of the error -->
<p>The random effect terms further clarify the source of the error. Below we compare the effect ranges that can be attributed to the participant and to the simulations next to their marginal effect on the response, a sort of upper bound for the error they could explain. We look at the original accuracy model and then the model regressing log response time.</p>
<!-- Random effects vs Mean Mark CI by participant and sim -->
<p>The residual plots have no noticeable non-linear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure <a href="4-ch-userstudy.html#fig:ch4zappfig2">4.11</a> illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at <span class="math inline">\(\alpha = .95\)</span>, while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95% confidence intervals participation and simulation mean accuracy, respectively.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4zappfig2"></span>
<img src="figures/ch4_zapp_fig2_effect_range.png" alt="Accuracy model: (T) Estimated effect ranges of the random effect terms participant and data simulation of the accuracy model, $\widehat{Y_1} = \alpha \cdot \beta + \gamma + \delta$. Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about two-thirds of the range of the data without the model. All intervals for $\alpha = .95$ confidence." width="100%"  />
<p class="caption">
Figure 4.11: Accuracy model: (T) Estimated effect ranges of the random effect terms participant and data simulation of the accuracy model, <span class="math inline">\(\widehat{Y_1} = \alpha \cdot \beta + \gamma + \delta\)</span>. Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about two-thirds of the range of the data without the model. All intervals for <span class="math inline">\(\alpha = .95\)</span> confidence.
</p>
</div>
<p>Similarly, figure <a href="4-ch-userstudy.html#fig:ch4zappfig3">4.12</a> shows the Gelman simulations and marginal effects of the simulation and participants for <span class="math inline">\(Y_2\)</span>, the same model regressing on log response time.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ch4zappfig3"></span>
<img src="figures/ch4_zapp_fig3_T_effect_range.png" alt="Log response time model: (T) The effect ranges of Gelman resimulation on posterior distributions for the time model, $\widehat{Y_2} = \alpha \cdot \beta + \gamma + \delta$. These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log time by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: $e^{1} = 2.7$, $e^{2.75} = 15.6$, $e^{3.75} = 42.5$ seconds. Of the simulations on the right, the bottom has a large variation in response time, relative to the effect ranges which means that the variation is explained in the terms of the model and not by the simulation itself." width="100%"  />
<p class="caption">
Figure 4.12: Log response time model: (T) The effect ranges of Gelman resimulation on posterior distributions for the time model, <span class="math inline">\(\widehat{Y_2} = \alpha \cdot \beta + \gamma + \delta\)</span>. These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log time by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: <span class="math inline">\(e^{1} = 2.7\)</span>, <span class="math inline">\(e^{2.75} = 15.6\)</span>, <span class="math inline">\(e^{3.75} = 42.5\)</span> seconds. Of the simulations on the right, the bottom has a large variation in response time, relative to the effect ranges which means that the variation is explained in the terms of the model and not by the simulation itself.
</p>
</div>
<!-- ## References -->
<!-- <div id="refs"></div> -->
<!-- Adds a bib section at the end of every chapter -->

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="3-ch-spinifex.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="5-ch-cheem.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": false,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
