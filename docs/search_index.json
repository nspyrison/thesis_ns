[["index.html", "Interactive and dynamic visualization of high-dimensional data via animated linear projections Welcome", " Interactive and dynamic visualization of high-dimensional data via animated linear projections Nicholas S Spyrison Welcome This book is the PhD thesis covering my studies at Monash University, Australia. A pdf version can be found here, and the code creating it can be found on github. 2022-02-18 "],["abstract.html", "Abstract", " Abstract Visualizing data space is a crucial aspect of exploratory data analysis, checking assumptions, and validating model performance. However, visualization quickly becomes complex as the dimensionality of the data or features increases. Traditionally, linear projections have viewed discrete pairs of components to mitigate this complexity. Data visualization tours are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis. The permanence of observations between nearby frames potentially conveys more information than discrete orthogonal frames alone. Tours are categorized by the path of their bases. Manual tours uniquely allow for user-controlled steering of a path of bases, where the contributions of individual variables can be changed. The radial tour is a specific case of the manual tour, that freezes the angle of movement but allows the magnitude to be varied. This is used in the work reported here. Chapter 3 clarifies the theoretical basis of the radial tour. The details of implementation and illustration of its use are provided. It introduces an open-source R package, that facilitates creating these tours with a variety of display choices and user controls. Allowing the analyst to steer a path in the radial tour should enable a better understanding of the variable importance to any structure revealed in a projection. Chapter 4 discusses a within-participant user study comparing the radial tour with current practices: principal component analysis (PCA) and the original type of tour that has no steering. The \\(n=108\\) crowdsourced participants performed a variable attribution task describing the separation between clusters. The results find that the radial tour lead to more accurate variable attribution. Participants also reported that the radial tour was their preferred visualization method. Nonlinear modeling techniques are sometimes referred to as black-box models due to the uninterpretable nature of the model terms. Recent research in Explainable Artificial Intelligence (XAI) tries to bring these models interpretability through local explanations. Local explanations are a class of techniques that approximate the linear-variable importance for prediction at one point in the data. Chapter 5 provides a new approach for exploring the variable sensitivity of local explanations using radial tour. Local explanations can be considered projection bases. The radial tour is used to vary the contribution of an feature to assess the importance that feature for any particular prediction. This is illustrated using four contemporary data examples covering classification and regression. An accompanying R package provides a graphical user interface (GUI) for conducting this analysis. Nicholas Spyrison 2021-12-12 &gt; "],["acknowledgments.html", "Acknowledgments", " Acknowledgments I would like to express my sincere gratitude to my supervisors, Professor Dianne Cook and Professor Kimbal Marriott, for their support of my Ph.D studies and research, their subject expertise, and their careers of supervising and teaching in addition to performing research. Thank you for continuously pushing me and my research to new levels. I have enjoyed teaching data visualization, which has been strongly shaped by Dis practical, data-first, visualization-often approach. I will continue to hear Kims persistent question, what do we learn from this? as a reminder not to get lost in the details of implementation and regularly step back and analyze if this is the correct object to change. Thanks to the member of supervisory panel, Associate Professor Bernhard Jenny, Dr. Maxime Cordeil, and Dr. Shirui Pan for their time, engagement, and suggestions through the duration of this research. Special thanks to Jieyang Chong and Julie Holden for their proofreading and suggested language clarifications. I thank my fellow Ph.D students, NUMBAT and DVIA lab members, and Pomodoro partners, primarily on the occasion of stimulating discussions and the positive peer pressure of knowing others are around and working. Thanks immensely to those who empathized with me and others, especially through the hardships of studies and COVID-19. Gratitude to Ying Zhou for her enduring support through the thick of my studies and wavering mental health. Last but not least, I would like to thank my parents, Doug and Terry, for their continued support and airing my grievances at odd hours of the day. Thanks to Alan and Claire for their companionship and support now and in our more formative years. This research was supported in part by an Australian Government Research Training Program (RTP) Scholarship. "],["preface.html", "Preface", " Preface This thesis has been written using R Markdown with the bookdown package (Xie 2016). All materials required to compile the thesis are available at github.com/nspyrison/thesis_monash_phd. Versions are made available as html and pdf at nspyrison.github.io/thesis_ns/ and github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf, respectively. "],["1-ch-introduction.html", "Chapter 1 Introduction 1.1 Research questions 1.2 Methodology 1.3 Contributions 1.4 Thesis structure", " Chapter 1 Introduction Exploratory Data Analysis (EDA) is the process of the initial summarization and visualization of a dataset. EDA is a critical first step of checking for realistic values, identifying improper data formats, and revealing insights (Tukey 1977). Hadlet Wickham and Grolemund (2017) describe the analyst workflow into a series of discrete steps. The data is imported and cleaned before entering into an iterated cycle of transformation, visualization, and modeling. This work focuses the visualization step, specifically for quantitative multivariate data. The implementation of packages also facilitates transformation and modeling while these aspects are not the primary contributions. Multivariate data has become ubiquitous in contemporary data sets. Multivariate data is found in physics, biology, social sciences, and manufacturing to name a few (Wang et al. 2018; Huber et al. 2015; Brown 2015; Evans and Boreland 2017). As the number of variables in the data increases, it becomes increasingly difficult to visualize this space and reveal the structure of the data. This thesis addresses the visualization and analysis of multivariate data. One of the most common and successful approaches to visualize multivariate data is to use linear projection, which approximates \\(p\\)-dimensional data onto 1-3 display dimensions. In the same way that 3D object casts a 2D shadow, these projections cast one orientation of the data onto a lower plane. Linear projections defines new variables called components, essentially a linear combination, orientation of the original variables. A basis is the orthonormal matrix that maps the variable to the component output space. The basis of a linear projections is frequently illustrated with a biplot (Gabriel 1971). The biplot shows the magnitude and angle each variable contributes to the resulting display dimensions inscribed in a unit circle, such as in Figure 1.1. Traditional axes-based visuals look at 1-3D scatterplots of orthogonal variables. In contrast by viewing linear combinations of these variables on the axes can reveal features that exist in more than three dimension. (ref:ch1fig2-cap) Two linear projections of penguins data. Biplot circles depict the basis, the direction and magnitudes of the contributions of the variables. In the left frame, the direction of separation of the orange cluster is mainly in the direction that bl contributes, meaning that the variable is sensitive to the separation of this cluster. The purple clusters separation is attributed primarily to bd and fl and bm to a smaller extent. Many other linear orientations do not resolve structures of interest, such as cluster separation (right frame). The Palmer Penguin data (Gorman, Williams, and Fraser 2014; Horst, Hill, and Gorman 2020) measures four physical variables: bill length (bl), bill depth (bd), flipper length (fl), and body mass (bm) for three species of penguins. Figure 1.1: (ref:ch1fig2-cap) There are many features that an analyst may be interested in when analyzing multivariate data. Shape, spread, identifying clusters, outliers, and irregularities are the most common. Not all of the basis orientations of a data will reveal the features the data. Thus the choice of projection is important. Furthermore, the analyst is interested in understanding which combination of variables indicate the feature. For instance, Figure 1.1 shows two linear projections of penguin data. The color and shape of the data points distinguish the three penguin species. The linear projection used in the left frame contains a significant separation of the clusters, while the right frame does not show a discern differences in the species clusters. Therefore, it makes sense for an analyst to explore many projections with very different bases. However, it can be difficult to link observations across different projections with no relationship to one another. The tour is a dynamic visualization that overcomes this difficulty (Cook et al. 2008; Lee et al. 2021). It is a class of linear projections that animate over small changes to the projection basis. A key feature of the tour is the visual permanence and trackability of the points through the frames. In the shadow analogy, an object such as a barstool will cast a circular shadow if the light is directly above the seat. However, such a shadow does not give the observer sufficient information as it could arise from any number of shapes that contain circular profiles: spheres, cylinders, or circles. However, if the stool was rotated, its legs would show in the shadow quickly giving an intuitive interpretation of the object. Similarly, the rotation of a data object yields information about its structure. dont need interaction for Human-in-the-loop. Originally component spaces and the original tour have no means to inflence the basis or its path. Cook and Buja (1997) introduced the manual tour, offering user control over the basis. By selecting a variable and initializing an additional manipulation dimension to a projection, the contribution of the variable can be controlled through a rotation of the manipulation space. This user-controlled steering of the basis path enables the analyst to explore what happens to the structure when one variable is removed or the contribution of another is increased. The manual tour allows the analyst to control the angle and magnitude that a variable contributes to the projection. However, controlling the magnitude is generally more meaningful as angular manipulations effectively rotate the projection, changing the relative position but not the contributions of a variables. Because of this, this work focuses on a specific manual tour, the radial tour, where the angle of the manipulated variable is fixed, but the analyst can vary its magnitude, changing its radius. Figure 1.2 shows a radial tour of the penguins data varying the contribution of bill length. The left frame has a full contribution from bl, middle frames contains about half contribution while bill length has been removed in the the right frame. The separation between orange and green clusters was in the direction that bl contributed and when this contribution is removed so to is the separation of the clusters; we say this variable is sensitive to the separation of these two clusters. (ref:ch1fig3-cap) A radial tour changing the contribution of bill length (bl). When bill length has a considerable contribution, the clusters of orange and green are separated (left and middle). When its contribution is removed, the clusters overlap (right). Because of this, we say that bill length is sensitive to the separation of these two species. An animated version can be viewed at vimeo.com/676723431. Figure 1.2: (ref:ch1fig3-cap) 1.1 Research questions Discerning variable sensitivity to the structure is crucial to understanding which variables contribute to a feature being revealed. We conjecture that the user interaction afforded by the radial tour should allow for a more precise exploration of this structure by testing the variable sensitivity to that structure. The over-arching question of interest can, therefore, be stated as: Can the radial tour, with user-steering of the basis, help analysts understand the variable sensitivity of structure in the projection? While Cook and Buja (1997) sketched the theoretical basis for the manual (and hence radial) tour, some details are missing. Furthermore, we lack a publicly available implementation, fully-featured interface design, implementation notes, and have no evaluation of its performance over alternatives. RQ 1. How do we define and implement a user interface and interactions for the radial tours to add and remove variables smoothly from a 2D linear data projection? At present, the radial tour is not used by analysts. Instead, they would use a single projection to understand the structure, almost always the principal components analysis (PCA, Pearson 1901), which chooses the basis that shows the most variation. Another approach is to use a grand tour (Asimov 1985). The grand tour animates many interpolated frames between randomly selects target bases. Neither PCA nor the grand tour provides a means for manually manipulating a desired variables contribution to the basis. We wish to investigate if the basis-steering of the radial tour facilitates a better understanding of variable sensitivity to the structure. RQ 2. Does the use of the interactive radial tour improve analysts understanding of the relationship between variables and structure in 2D linear projections compared to existing approaches? Complex nonlinear models are also being applied more frequently to predict or classify with many predictors. While these models lead to increased accuracy over linear models, they suffer from a loss of the interpretability of their variables. One aspect of eXplainable Artificial Intelligence (XAI, Adadi and Berrada 2018; Arrieta et al. 2020) tries to preserve the interpretability of such models through local explanations. These explanations are essentially linear variable importance in the vicinity of one observation of a model. That is, the extent that variables help the model explain the difference between the observed means and this observations prediction. The user control from the radial tour potentially allows an analyst to better understand the model and the support of these local explanations. RQ 3. Can the radial tours be used in conjunction with local explanations to improve the interpretability of black-box models? 1.2 Methodology The research corresponding to RQ 1 entails algorithm &amp; software design (Kleinberg and Tardos 2006) adapts the algorithm from Cook and Buja (1997). To address RQ 2, we use experimental design (Winer 1962). We must define a task and measure suitable to evaluate the radial tour against alternatives. The experimental factors and their levels must be selected and randomly assigned to explore the efficacy of user-controlled radial tours compared with two benchmark methods. The research responding to RQ 3 involves design science (Hevner et al. 2004). It is not obvious how to combine a radial tour with a nonlinear model. A local explanation approximates the linear variable importance in the vicinity of one observation. We must develop a novel interactive visualization that accommodates two aspects. First, it should visually facilitate the selection of observations to explore. Secondly, extend the biplot to show the distribution of the local explanations and examine the variable sensitivity to the structure identified in the local explanation with the radial tour. 1.3 Contributions The contributions resulting from the research to address these research questions can be split into scientific knowledge and software contributions: 1.3.1 Scientific knowledge Radial tour algorithm Refined and clarified the steps to producing a radial tour based on the use of the Rodrigues rotation formula extends the approach from Rodrigues (1840). The algorithm makes radial tour in the animation and interactive systems simpler. Provides new examples of usage. A user study comparing the radial tours efficacy against two alternativesPCA and the grand tour, the first empirical evaluation of the radial tour. Creation of supervised classification task to assess the variable attribution to the separation of two clusters. As tested over experimental factors: location, shape, and dimensionality. Definition of an accuracy measure to evaluate this task. Results: strong evidence that the radial tour increases the accuracy of this task by a sizable amount and minor evidence to suggest a moderate increase in accuracy of the grand tour over PCA. Mixed model regression helps to attribution the source of the error accounting for the variability of participants skills and the difficulty of the simulation by chance. A novel interactive visualization using the radial tour to explore the variable sensitivity of local explanations from nonlinear models, part of XAI. A global view approximates the variable space, attribution space, and model information side-by-side serves to identify a primary observation of interest. This observations normalized variable attribution is used as a projection basis. Explore the support of the local explanation; using the radial tour, the variable sensitivity to the structure identified test the range of contributions supporting the explanation. 1.3.2 Software spinifex, an R package for transforming data, performing manual tours, and extend the display and animation exportation of any tour. Facilitates the transformation of numeric variables in the data. Identify various bases finding various features of the data. Creation of manual tours allows analyst steering of the basis to explore the variable sensitivity to the structure. Layered composition of tour displays that mirrors the approach in ggplot2 (Hadley Wickham 2016), interoperable with tours made from tourr (Hadley Wickham et al. 2011). Exporting rendered animation either to interactive html widgets with plotly (Sievert 2020) or to gif, mp4, and other video formats with gganimate (Pedersen and Robinson 2020). Interactive shiny (Chang et al. 2021) application to preprocess data and explore. Users can choose from six supplied datasets or upload their own. Vignettes and code examples help users get up to speed. Introduces an interactive application to preprocess data and explore. Users can choose from six supplied datasets or upload their own. cheem, an R package that facilitates the exploration of local explanations of nonlinear models through the use of the radial tour. Preprocessing: given a tree-based model, calculate the tree SHAP local explanation (via treeshap, Kominsarczyk et al. 2021) of all observations, and find statistics to accent the separability of this space. Visualization of approximations of the data space, attribution space, and model residual information side-by-side with linked brushing, hover tooltips, and tabular display facilitates the selection of observations to explore. Use of the radial tour changes variable contribution to test the support of the variable contribution in agreement with the explanation. Interactive application facilitates this analysis for several prepared datasets or user preprocessed data. A vignette and code examples help users get up to speed. 1.4 Thesis structure The remainder of the thesis is organized as follows: Chapter 2 covers various visualizing techniques before introducing related studies and nonlinear models and their interpretability issues. Chapter 3 discusses the theory and implementation of the radial tours in the package spinifex. Chapter 4 discusses a user study evaluating the radial tours efficacy compared with PCA and the grand tour. Chapter 5 discusses the cheem package which extends the use of radial tours to improve the interpretability of nonlinear models. Lastly, Chapter 6 concludes with some takeaways and a discussion of limitations and possible extensions. "],["2-ch-background.html", "Chapter 2 Background 2.1 Motivation 2.2 Multivariate visualization 2.3 Linear projections 2.4 Evaluating multivariate data visualization 2.5 Nonlinear models 2.6 Local explanations 2.7 Conclusion", " Chapter 2 Background In the last chapter, we discussed the importance of data visualization despite the complexity of viewing high-dimensional data and outlined the research questions we wish to address with the user-control of the radial tour. This chapter first motivates data visualization in general and the importance of interaction. Then we cover common visualizations for quantitative multivariate data before turning to dimension reduction. We cover linear dimension reduction, including further discussion of tours. Then we discuss empirical evaluations of multivariate visuals. Lastly, this chapter concludes with nonlinear models and extends their interpretation with local explanations. 2.1 Motivation Visualization is much more robust than numerical summarization alone (Anscombe 1973; Matejka and Fitzmaurice 2017). Figure 2.1 illustrates this. The data sets have a quite different structure revealed in the visualization but not in the summary statistics, as all data sets have the same means, standard deviations, and correlation. (ref:ch2fig1-cap) The datasaurus dozen is a modern data set illustrating Anscombes point that summary statistics cannot always adequately summarize the content of data. The data patterns shown in the scatterplots have the same summary statistics. Unless the data is plotted, one would never know that there were such radical differences. Figure 2.1: (ref:ch2fig1-cap) Interaction is known to be an essential aspect of modern data visualization (Batch et al. 2019; Card, Moran, and Newell 1983; Marriott et al. 2018). Interaction facilitates accessing increasing amounts of data and amplifies cognition through control and input (Dimara and Perin 2019). Munzner (2014) posits that responsive and fast computer graphics allow us to move beyond paper and static resources. Interaction is key to navigating within views of sizable data and also to link observations and features across these views. Here we focus on multivariate data interactions with coordinated view, linked brushing, and tooltip display. Coordinated and multiple views (Roberts 2007) (also known as ensemble graphics, Unwin and Valero-Mora 2018) use several types of visuals that give a more comprehensive understanding than any one visual portrays in isolation. Linking observations between different views and animation frames is facilitated by linked brushing (Becker and Cleveland 1987). Linked brushing colors selected observations in one view allowing these selections to be tracked and correlated across other views and frames. Linked brushing has proved to be helpful in animated tours (Arms, Cook, and Cruz-Neira 1999; Laa, Cook, and Valencia 2020; Lee, Laa, and Cook 2020). Tooltips display observation ID upon the cursor hovering over observations can also aid identification and display associated values. Interactive selection of parameters extends the breadth of an analysis, and animation interactions such as play, pause, and frame selection are regularly used. 2.2 Multivariate visualization In this thesis, we are concerned with the visualization of multivariate data. Specifically, we are interested in quantitative multivariate data. We assume that our data consists of \\(n\\) observations of \\(p\\) variables. Generally \\(n&gt;p\\) with many more observations than variables. While written as though operating on the original variables, the visualizations discussed below could also be applied to reduced component spaces (such as PCA approximation in a few components) or feature decomposition of data not fitting this format. Kang, Hyndman, and Smith-Miles (2017) provide a good example of decomposing time series data in a quantitative feature matrix. Grinstein, Trutschl, and Cvek (2002) illustrate many multivariate visualization methods. In particular, it shows examples of the actual visualizations. Liu et al. (2017) give a good classification and taxonomy. Here we focus on the most common and the most relevant visuals. We illustrate these with the Palmer penguins data that was used in the Introduction. This data contains 333 observations of three penguin species across four physical measurements: bill length, bill depth, flipper length, and body mass. Observations were collected between 2007 and 2009 near Palmer Station, Antarctica. This is a good substitute for the over-used iris data. 2.2.1 Scatterplot matrices An analyst could look at \\(p\\)-univariate histograms or density curves. Extending this idea, pairs of variables can be exhaustively viewed. Combining these brings us to scatterplot matrices, also known as SPLOM (Chambers et al. 1983). In a scatterplot matrix, variables are arranged across the columns and rows. The diagonal elements show univariate densities, while off-diagonal positions show scatterplot pairs, as in Figure 2.2. This is useful for getting a handle on the range of the variables but is not going to scale well when the number of variables \\(p\\) is large. Such visualization will only partially resolve features that could be better show information from more dimensions. (ref:penguinsplom-cap) A scatterplot matrix shows univariate densities and all pairs of bivariate scatterplots. The panels show partial cluster separation indicating these variables contain some cluster discerning information. This approach is suitable for quickly exploring the range of the data but will not reveal features in more than two dimensions. It is a good exploratory visual but does not scale well with an increasing number of variables. Figure 2.2: (ref:penguinsplom-cap) As \\(n\\) increases, scatterplot displays also suffer from occlusion as the points overlay each other. This is typically addressed in a few ways. One method is to decrease points opacity, allowing more layers to be seen. Another approach is to change the geometric display to 2D density contours or an aggregated heatmap (illustrated in Figure 2.5). These aggregations typically render faster and scale better with increasing observations. Or, if needed, visualization can be performed on a representative subset of the data. 2.2.2 Parallel coordinate plots In scatterplot matrices, each observation is spread across all panels. In contrast, observation-linked visuals have a single line or glyph for each observation. In parallel coordinate plots (Ocagne 1885), variables are arranged horizontally, and lines connect observations after being transformed to a common scale such as quantiles or z-value (standard deviations away from the mean). Figure 2.3 illustrates this method. Parallel coordinate plots scale much better with dimensions than scatterplot matrices but more poorly with observations. They also suffer from an asymmetry with the variable order. That is, changing the order of the variables may lead to very different conclusions. The x-axis is also used to display variables rather than the values of the observations. This restricts the amount of information that can be interpreted between variables. Munzner (2014) asserts that position is the more human-perceptible channel for encoding information; we should prefer to reserve it for the values of the observations rather than distinguishing variables. (ref:penguinpcp-cap) Parallel coordinate plots put variables on a common scale and position them side-by-side with lines connecting observations. Some variation between the clusters can be seen corroborating their importance to explaining cluster separation. This approach scales relatively well with the number of variables but poorly with the number of observations. Figure 2.3: (ref:penguinpcp-cap) The same issues persist across other displays that map observations into \\(n\\) glyph or heatmaps. Examples of these include star plots (Chambers et al. 1983), pixel-based visuals (Keim 2000), and Chernoff faces (Chernoff 1973). Like parallel coordinate plots, these other visuals scale quite poorly with increasing observations. However, because these visuals scale well with the number of variables they maybe candidate visualizations for low \\(n\\), high \\(p\\) data. 2.2.3 Dimension reduction The other main approach for visualizing quantitative multivariate data is to use dimension reduction. This involves a function mapping \\(p\\)-spaces onto a lower \\(d\\)-dimensional space. Dimension reduction is separated into two categories, linear and nonlinear. The linear case spans all affine mathematical transformations, essentially any function where parallel lines stay parallel. Nonlinear transformations complement the linear case, think transformations containing exponents or interacting terms. Examples in low dimensions are relatable. For instance, shadows are linear projections of a 3-dimensional object down to the 2D shadow. Linear perspective drawings are another instance. An example of a nonlinear transformation is that of 2D maps of the globe. A common example is the Mercator projection, a rectangular display where the area is proportionally distorted with the distance away from the equator (Snyder 1987). Other distortions are created when the surface is unwrapped into an elongated ellipse. Yet others create non-continuous gaps on land or oceans to minimize the distortion of targeted areas. Snyder lists over 200 different projections that distort the surface to display as a map, each with unique properties distorting the 3D surface. However, despite familiarity with map projections, users find it difficult to understand the distortions they introduce (Hennerdal 2015). As illustrated by map projections, nonlinear projections can be difficult to understand. Various computational quality metrics, such as Trustworthiness, Continuity, Normalized stress, and Average local error, have been introduced to describe the distortion of the space (Espadoto et al. 2021; Gracia et al. 2016; Maaten, Postma, and Van den Herik 2009; Venna and Kaski 2006). To quote Panagiotelis (2020), All nonlinear projections are wrong, but some are useful, a play on George Boxs quote about models (All models are wrong, but some are useful, Box 1976). The distortions are hard to interpret and, thus, hard to communicate. Furthermore, nonlinear projections have hyperparameters (these are absent from linear methods) that control how the spaces are distorted to fit into fewer dimensions. These introduce a degree of subjectivity into the resulting projection. Opinions differ on how to best deal with hyperparameters. Probst, Wright, and Boulesteix (2019) discusses tuning strategies. Others compare implementation defaults (Gijsbers et al. 2021; Pfisterer et al. 2021). Probst, Boulesteix, and Bischl (2019) look at the sensitivity of hyperparameters to the performance of a model. Automated machine learning takes a programmatic approach to hyperparameter tuning (Feurer et al. 2015; Hutter, Kotthoff, and Vanschoren 2019; Yao et al. 2019). Due to the difficulty of interpreting nonlinear mappings and the added subjectivity of hyperparameter selection, this thesis focuses on linear visualization techniques. 2.2.4 Intrinsic data dimensionality One way dimension reduction is used is to project multivariate data onto 1-, 2-, or 3D space and visualize the results. However, it can also be used as a preprocessing step for any sort of analysis. The intrinsic dimensionality of data is the number of variables needed to minimally represent the data (Grinstein, Trutschl, and Cvek 2002). Intrinsic data dimensionality is an essential consideration of dimension reduction. Consider a Psychology survey consisting of 100 questions about the Big Five personality traits. The data consists of 100 response variables, while the theory would suggest the intrinsic dimensionality is five. Reducing the disparity of these volumes would be necessary to gate the exponentially increasing space to view. Nonlinear techniques regularly perform an implicit PCA initialization step that may default to keeping several dozen components to mitigate run time of data with hundreds or thousands of variables. 2.3 Linear projections Linear projections map a higher \\(p\\)-dimensional space onto a smaller \\(d\\)-space with an affine mapping (where parallel lines stay parallel). A projection is the resulting space of the data multiplied by a basis \\(Y_{n \\times d} = X_{n \\times p} \\cdot A_{p \\times d}\\). This basis is an orthonormal matrix that explains the orientation and magnitudes that variables contribute to the resulting space. This basis is often illustrated as a biplot (Gabriel 1971), where variable contributions are inscribed in a unit circle showing the direction and the magnitude of contribution as illustrated in the previous chapter. A common linear projection is principal component analysis (PCA, Pearson 1901), which creates a component space ordered by descending variation. It uses eigenvalue decomposition to identify the basis. These components are typically viewed as discrete orthogonal pairs, commonly approximated as several components. The exact number of components to keep is subjective but typically guided by a screeplot (Cattell 1966). Scree plots illustrate the decreasing variation contained in subsequent components. The analyst then identifies an elbow in this plot. PCA is also commonly used in preprocessing and model initialization when there are many more variables than the intrinsic data dimensionality, such as the Big Five personality example. These reduced component spaces can be used in visualization, albeit with the added abstraction of another linear mapping to get back to the original variables. 2.3.1 Tours, animated linear projections In one static linear projection, one basis uniquely maps the projection. In contrast to a single projection, a data visualization tour animates many such projections over small changes in the basis. In the shadow analogy, structural information of an object is gained by watching its shadow change due to its rotation. An analyst similarly gains structural information by watching continuous changes to the basis (the orientation of the data). There are various types of tours that are classified by the generation of their basis paths. We enumerate a few related to this work. A more comprehensive discussion and review of tours can be found in the works of Cook et al. (2008) and Lee et al. (2021). Regardless of the type of tour target basis identified, tours must interpolate frames between distant generated target bases. This interpolation is performed along a geodesic path between the bases. Geodesic refers to the shortest path (on a \\(p\\)-sphere of possible bases). This ends up being slightly curved in 2D representation in the same way that flight paths appear curved on 2D representations of the globe. The interpolation of frames at small enough angles is foundational for the trackability of observations between frames. Originally in a grand tour (Asimov 1985), several target frames are randomly selected. Figure 2.4 illustrates six frames from a grand tour. The grand tour is good for EDA in that it will show frames with widely varying contributions but lacks a destination, objective function, or means of steering. (ref:ch2fig4-cap) Frames from a grand tour. Biplots (grey circles) illustrate the direction and magnitude that variables contribute. In the grand tour, target bases are selected randomly. Tours animate linear projections over small changes in the basis. The observation permanence between frames is an essential distinction in tours. An animation can be viewed at vimeo.com/676723441. Figure 2.4: (ref:ch2fig4-cap) The grand tour has no input over the bases selected. In contrast, the manual tour (Cook and Buja 1997) allows the analyst to change the contribution of a selected variable. It does so by initializing a manipulation dimension on a 1- or 2D projection which can then be rotated to alter the contribution of a selected variable. This work focuses on the radial tour sub-variant, where the contribution angle is fixed, and the magnitude of contribution along the radius is controlled. Figure 2.5 illustrates the same radial tour shown in the previous chapter across three geometric displays. The use of density contours and aggregated heatmap displays help to mitigate the occlusion of dense observations and is compatible with any scatterplot display. (ref:ch2fig5-cap) Radial tour across three geometric displays. The contribution of bl is removed from the frame and with it the separation between the orange and green clusters is also removed. Changing to density contours or hexagonal heatmap displays are common ways to mitigate occlusion caused by dense observations. Heatmap display is not the best choice to show supervised cluster separation but can be helpful to see structure in dense data. Figure 2.5: (ref:ch2fig5-cap) 2.4 Evaluating multivariate data visualization Grinstein, Trutschl, and Cvek (2002) provide collected illustrations from many visualization methods. While Liu et al. (2017) provide a good classification of visualization techniques. Definitions and surveys of quality metrics are given in Bertini, Tatu, and Keim (2011). The latest, most comprehensive empirical evaluations are discussed in Espadoto et al. (2021) and Nonato and Aupetit (2018). While the former papers include a discussion of tours, they are absent from empirical evaluations. Gracia et al. (2016) conducted an \\(n=40\\) user study comparing between 2D and 3D scatterplots on traditional 2D monitors. Participants perform point classification, distance perception, and outlier identification tasks. The results are mixed and primarily have small differences. There is some evidence to suggest a lower error in distance perception from a 3D scatterplot. Wagner Filho et al. (2018) performed an \\(n=30\\) within participants using scatterplot display between 2D, 3D displays on monitors and 3D display with a head-mounted display on PCA reduced spaces. None of the tasks on any dataset lead to a significant difference in accuracy. However, the immersive display reduced effort and navigation, resulting in higher perceived accuracy and engagement. Sedlmair, Munzner, and Tory (2013) instead use two expert coders to evaluate 75 datasets and four dimension reduction techniques for 2D scatterplots, interactive 3D scatterplots, and 2D scatterplot matrices. They suggest a tiered guidance approach finding that 2D scatterplots are often good enough to resolve a feature. If not, try with an alternative dimension reduction technique before going to scatterplot matrix display or concluding a true negative. They find that interactive 3D scatterplots help in relatively rare cases. Tours are absent from empirical studies. However, Nelson, Cook, and Cruz-Neira (1998) compare scatterplots of grand tours on a 2D monitor with 3D (stereoscopic, not head-mounted) over \\(n=15\\) participants. Participants perform clusters detection, dimensionality, and radial sparseness tasks on six-dimensional data. They find that stereoscopic 3D leads to more accuracy for cluster identification, though interaction time much increased in the 3D case. 2.5 Nonlinear models Nonlinear models have many or complex interactive terms, which cause an opacity to the interpretation of the variables. This loss of the interpretability of variables in nonlinear models sometimes leads to them being referred to as black-box models. There are different reasons and emphases when considering to fit a model. Breiman (2001), reiterated by Shmueli (2010), taxonomize models based on their purpose; explanatory modeling is done for some inferential purpose, while predictive modeling focuses more narrowly on the performance of some objective function. The intended use has important implications for model selection and development. In explanatory modeling, interpretability is vital for drawing inferential conclusions. While black-box models are preferred in predictive modeling. However, the use and prevalence of nonlinear models is not without controversy (ONeil 2016; Kodiyan 2019). And the loss of interpretation presents a challenge. Interpretability is vital for exploring and protecting against potential biases (e.g., sex  Dastin (2018); Duffy (2019), race  Larson et al. (2016), and age  Díaz et al. (2018)) in any model. For instance, models regularly pick up on biases in the training data where protected classes correlate with the response feature. This bias is then built into the model. Variable-level (feature-level) interpretability of models is essential in evaluating such biases. Another concern is data drift, where a shift in the range of the explanatory variables (features or predictors). Some nonlinear models are sensitive to this and do not extrapolate well outside the support of the training data. Maintaining variable interpretability is also essential to address issues arising from data drift. 2.6 Local explanations Explainable Artificial Intelligence (XAI) is an emerging field of research that tries to increase the interpretability of black-box models. A common approach is local explanations, which attempt to approximate linear variable importance in the vicinity of one observation (instance). This is a linear measure indicating which variables are important for distinguishing between the mean of the data and the prediction near one observation. Because these are point-specific, the challenge is to comprehensively visualize them to understand a model. Consider a highly nonlinear model. It can be hard to determine which variables in the data will lead to a different classification or changes in its residual. Local explanations shed light on these situations by approximating linear variable importance in the vicinity of a single observation. Figure 2.6 motivates local explanations where the analyst wants to know the variable attribution for a particular observation close to the classification boundary in a nonlinear model. (ref:ch2fig6-cap) Illustration of a nonlinear classification model. An analyst may want to know the variable importance at the vicinity of the highlighted red cross. Understanding this attribution elucidates how the variable influence this point that is precariously close to the classification boundary. Local explanations approximate this linear attribution in the vicinity of one observation. Figure from Ribeiro, Singh, and Guestrin (2016). Figure 2.6: (ref:ch2fig6-cap) A comprehensive summary of the taxonomy and literature of explanation techniques is provided in Figure 6 of Arrieta et al. (2020). It includes a large number of model-specific explanations such as deepLIFT (Shrikumar et al. 2016; Shrikumar, Greenside, and Kundaje 2017), a popular recursive method for estimating importance in neural networks. There are fewer model-agnostic explanations, of which LIME, (Ribeiro, Singh, and Guestrin 2016) SHAP, (Lundberg and Lee 2017), and their variants are popular. These observation-level explanations are used in various ways depending on the context. In image classification, a saliency map indicate important pixels for the resulting classification (Simonyan, Vedaldi, and Zisserman 2014). For example, snow is regularly highlighted when distinguishing if a picture contains a wolf or husky (Besse et al. 2019). In text analysis, word-level contextual sentiment analysis can be used to highlight the sentiment and magnitude of influential words (Vanni et al. 2018). In the case of numeric regression, they are used to explain variable additive contributions from the observed mean to the observations prediction (Ribeiro, Singh, and Guestrin 2016). 2.7 Conclusion We have discussed the motivation for data visualization and the importance of user interaction. We discussed several visuals before turning to linear dimension reduction. Empirical evaluations, black-box models, and their local explanations were discussed. There is an absence of studies comparing animated tours with alternative visualization. XAI and extending the interpretability of black-box models are sought-after. The following chapters respectively address the three research questions covered in the Introduction. Chapter 3 discusses the implementation of a package that facilitates the creation of radial tours and extends the display and exporting of tours in general. Chapter 4 covers the first user study evaluating the radial tour compared with two common alternatives. Chapter 5, introduces a novel analysis that explores local explanations of nonlinear models with the radial tour. "],["3-ch-spinifex.html", "Chapter 3 A User-Controlled Radial Tour for Animated Linear Projections 3.1 Algorithm 3.2 Oblique cursor movement 3.3 Package structure 3.4 Use cases 3.5 Discussion", " Chapter 3 A User-Controlled Radial Tour for Animated Linear Projections This chapter introduces manual tours that allows analysts to influence the contributions to a projection. This feature is unique from previous linear embeddings and not facilitated by compiling software. Dynamic low-dimensional linear projections of multivariate data known as tour provide an essential tool for exploring multivariate data and models. The R package tourr provides functions for several types of tours: grand, guided, little, local, and frozen. Each of these can be viewed in a development environment, or their basis array can be saved for later consumption. This chapter describes a new package, spinifex, which provides a manual tour of multivariate data. In a manual tour an analyst controls the contribution of a variable to the projection. Controlled manipulation is important to explore a variables sensitivity to structure of an identified feature. The use of the manual tour is applied to particle physics data to illustrate the sensitivity of structure in a projection to specific variable contributions. Additionally, we create a ggproto API for composing any tour that mirrors the layered additive approach of ggplot2. Tours can then be animated and exported to various formats with plotly or gganimate. In the Chapter 2 we introduce linear projections and tours, dynamic linear projections animated over small changes to the basis. The manual tour (Cook et al. 1995) novelly allows an analyst control the contribution of a variable to the basis. On the theoretical side of the contribution we fill in previously absent details to solve at the 3D rotation matrix used in 2D manual tours. This proves a scaffolding for the extension for solving for a 4D rotation matrix that could be used for a 3D manual tour. After that we turn our attention to the package and implementation before illustrating use of the manual tour with meta analysis on high energy particle physics data. The chapter is organized as follows. Section 3.1 describes the algorithm used to perform a radial manual tour implemented in the package spinifex. Section 3.3 discussed the functions. Package functionality and code usage following the order applied in the algorithm follows in section 3.3.1. Section 3.4 illustrates how this can be used for sensitivity analysis applied to multivariate data collected on high-energy physics experiments (Wang et al. 2018). Section 3.5 summarizes this chapter. 3.1 Algorithm The types of manipulations of the manual tour can be thought of in several ways: radial: fix the direction of contribution, and allow the magnitude to change. angular: fix the magnitude, and allow the angle or direction of the contribution to vary. horizontal, vertical: allow rotation only around the horizontal or vertical axis of the current 2D projection. oblique: paths deviating from these movements such as being captured from the movement of a cursor. Angular manipulations are homomorphic, in that they show the same information while rotating the frame. More interesting a change in the magnitude of the contribution, changing the radius along the original angle of contribution. For this reason we implement the radial tour as the default values for the manual tour. Below we describe the manual tour illustrated in detail. After that we also include summaries of the algorithms oblique cursor movements for in the 1D and 2D instances. 3.1.1 Notation The notation used to describe the algorithm for a 2D radial manual tour is as follows: \\(\\textbf{X}\\), the data, an \\(n \\times p\\) numeric matrix to be projected. \\(\\textbf{A}\\), any orthonormal projection basis, \\(p \\times d\\) matrix, describing the projection from \\(\\mathbb{R}^p \\Rightarrow \\mathbb{R}^d\\). \\(k\\), is the index of the manipulation variable or manip var for short. \\(\\textbf{e}\\), a 1D basis vector of length \\(p\\), with 1 in the \\(k\\)-th position and 0 elsewhere. \\(\\textbf{R}\\), the \\(d+1\\)-D rotation matrix, for performing unconstrained 3D rotations within the manip space, \\(\\textbf{M}\\). \\(\\theta\\), the angle of in-projection rotation, for example, on the reference axes; \\(c_\\theta, s_\\theta\\) are its cosine and sine. \\(\\phi\\), the angle of out-of-projection rotation, into the manip space; \\(c_\\phi, s_\\phi\\) are its cosine and sine. The initial value for animation purposes is \\(\\phi_1\\). \\(\\textbf{U}\\), the axis of rotation for out-of-projection rotation orthogonal to \\(\\textbf{e}\\). \\(\\textbf{Y} = \\textbf{X} \\times \\textbf{A}\\), the resulting projection of the data through the manip space, \\(\\textbf{M}\\), and rotation matrix, \\(\\textbf{R}\\). The algorithm operates entirely on projection bases and incorporates the data only when making the projected data plots in light of efficiency. 3.1.2 Steps 3.1.2.1 Step 0) Setup The flea data (Lubischew (1962)), available in the tourr package (Hadley Wickham et al. 2011), is used to illustrate the algorithm. The data contains 74 observations of six variables, physical measurements of flea beetles. Each observation belongs to one of three species. An initial 2D projection basis must be provided. A suggested way to start is to identify an interesting projection using a projection pursuit guided tour. Here the holes index is used to find a 2D projection of the flea data, which shows three separated species groups. Figure 3.1 shows the initial projection of the data. The left panel displays the projection basis (\\(\\textbf{A}\\)) and can be used as a visual guide of the magnitude and direction that each variable contributes to the projection. The right panel shows the projected data, \\(\\textbf{Y}_{[n,~2]} ~=~ \\textbf{X}_{[n,~p]} \\textbf{A}_{[p,~2]}\\). The color and shape of points are mapped to the flea species. Figure 3.1: Biplot of the initial 2D projection: representation of the basis (left) and resulting data projection (right) of standardized flea data. The color and shape of data points are mapped to the species of flea beetle. The basis was produced by a projection pursuit guided tour with the holes index. The contribution of the variables aede2 and tars1 approximately contrasts the other variables. The visible structure in the projection are the three clusters corresponding to the three species. 3.1.2.2 Step 1) Choose manip variable In figure 3.1 the contribution of the variables tars1 and aede2 mostly contrast the contribution of the other four variables. These two variables combined contribute in the direction of the projection where the purple cluster is separated from the other two clusters. The variable aede2 is selected as the manip var, the variable to be controlled in the tour. The question that will be explored is: how important is this variable to the separation of the clusters in this projection? 3.1.2.3 Step 2) Create the 3D manip space Initialize the coordinate basis vector as a zero vector, \\(\\textbf{e}\\), of length \\(p\\), and set the \\(k\\)-th element to 1. In the example data, aede2 is the fifth variable in the data, so \\(k=5\\), set \\(e_5=1\\). Use a Gram-Schmidt process to orthonormalize the coordinate basis vector on the original 2D projection to describe a 3D manip space, \\(\\textbf{M}\\). \\[\\begin{align*} e_k &amp;\\leftarrow 1 \\\\ \\textbf{e}^*_{[p,~1]} &amp;= \\textbf{e} - \\langle \\textbf{e}, \\textbf{A}_1 \\rangle \\textbf{A}_1 - \\langle \\textbf{e}, \\textbf{A}_2 \\rangle \\textbf{A}_2 \\\\ \\textbf{M}_{[p,~3]} &amp;= (\\textbf{A}_1,\\textbf{A}_2,\\textbf{e}^*) \\end{align*}\\] The manip space provides a 3D projection from \\(p\\)-dimensional space, where the coefficient of the manip var can range completely between [0, 1]. This 3D space serves as the medium to rotate the projection basis relative to the selected manipulation variable. Figure 3.2 illustrates this 3D manip space with the manip var highlighted. This representation is produced by calling the view_manip_space() function. This diagram is purely used to help explain the algorithm. Figure 3.2: Illustration of a 3D manip space, the projection plane is shown as a blue circle extending into and out of the display. A manipulation direction is initialized, the red circle, orthogonal to the projection plane. This allows the selected variable, aede2, to change its contribution back to the projection plane. The other variables contributions rotate into this space as well, preserving the orthogonal structure, but are omitted in the manipulation dimension for simplicity. 3.1.2.4 Step 3) Defining a 3D rotation The basis vector corresponding to the manip var (red line in Figure 3.2), can be operated like a lever anchored to the origin. This is the process of the manual control, that rotates the manip variable into and out of the 2D projection (Figure 3.3). As the variable contribution is controlled, the manip space turns, and the projection onto the horizontal projection plane correspondingly changes. This is a manual tour. Generating a sequence of values for the rotation angles produces a path for the rotation of the manip space. For a radial tour, fix \\(\\theta\\), the angle describing rotation within the projection plane, and compute a sequence for \\(\\phi\\), defining movement out of the plane. This will change \\(\\phi\\) from the initial value, \\(\\phi_1\\), the angle between \\(\\textbf{e}\\) and its shadow in \\(\\textbf{A}\\), to a maximum of \\(0\\) (manip var fully in projection), then to a minimum of \\(\\pi/2\\) (manip var out of projection), before returning to \\(\\phi_1\\). Rotations in 3D can be defined by the axes they pivot on. Rotation within the projection, \\(\\theta\\), is rotation around the \\(Z\\)-axis. Out-of-projection rotation, \\(\\phi\\), is the rotation around an axis on the \\(XY\\) plane, \\(\\textbf{U}\\), orthogonal to \\(\\textbf{e}\\). Given these axes, the rotation matrix, \\(\\textbf{R}\\), can be written as follows, using Rodrigues rotation formula (originally published in Rodrigues (1840)): \\[\\begin{align*} \\textbf{R}_{[3,~3]} &amp;= \\textbf{I}_3 + s_\\phi\\*\\textbf{U} + (1-c_\\phi)\\*\\textbf{U}^2 \\\\ &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} + \\begin{bmatrix} 0 &amp; 0 &amp; c_\\theta s_\\phi \\\\ 0 &amp; 0 &amp; s_\\theta s_\\phi \\\\ -c_\\theta s_\\phi &amp; -s_\\theta s_\\phi &amp; 0 \\\\ \\end{bmatrix} + \\begin{bmatrix} -c_\\theta (1-c_\\phi) &amp; s^2_\\theta (1-c_\\phi) &amp; 0 \\\\ -c_\\theta s_\\theta (1-c_\\phi) &amp; -s^2_\\theta (1-c_\\phi) &amp; 0 \\\\ 0 &amp; 0 &amp; c_\\phi-1 \\\\ \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} c_\\theta^2 c_\\phi + s_\\theta^2 &amp; -c_\\theta s_\\theta (1 - c_\\phi) &amp; -c_\\theta s_\\phi \\\\ -c_\\theta s_\\theta (1 - c_\\phi) &amp; s_\\theta^2 c_\\phi + c_\\theta^2 &amp; -s_\\theta s_\\phi \\\\ c_\\theta s_\\phi &amp; s_\\theta s_\\phi &amp; c_\\phi \\end{bmatrix} \\\\ \\end{align*}\\] where \\[\\begin{align*} \\textbf{U} &amp;= (u_x, u_y, u_z) = (s_\\theta, -c_\\theta, 0) \\\\ &amp;= \\begin{bmatrix} 0 &amp; -u_z &amp; u_y \\\\ u_z &amp; 0 &amp; -u_x \\\\ -u_y &amp; u_x &amp; 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; -c_\\theta \\\\ 0 &amp; 0 &amp; -s_\\theta \\\\ c_\\theta &amp; s_\\theta &amp; 0 \\\\ \\end{bmatrix} \\\\ \\end{align*}\\] 3.1.2.5 Step 4) Creating an animation of the radial rotation The steps outlined above can be used to create any arbitrary rotation in the manip space. To use these for sensitivity analysis, the radial rotation is built into an animation where the manip var is rotated fully into the projection, completely out, and then back to the initial value. This involves allowing \\(\\phi\\) to vary between \\(0\\) and \\(\\pi/2\\), call the steps \\(\\phi_i\\). Figure 3.3: Select frames highlight the animation of a radial manual tour manipulating aede2: (1) original projection, (2) full contribution, (3) zero contribution, before returning to the original contribution. Set initial value of \\(\\phi_1\\) and \\(\\theta\\): \\(\\phi_1 = \\cos^{-1}{\\sqrt{A_{k1}^2+A_{k2}^2}}\\), \\(\\theta = \\tan^{-1}\\frac{A_{k2}}{A_{k1}}\\). Where \\(\\phi_1\\) is the angle between \\(\\textbf{e}\\) and its shadow in \\(\\textbf{A}\\). Set an angle increment (\\(\\Delta_\\phi\\)) that sets the step size for the animation, to rotate the manip var into and out of the projection. Uses of angle increment, rather than a number of steps to control the movement is consistent with the tour algorithm as implemented in the tourr. Step towards \\(0\\), where the manip var is entirely in the projection plane. Step towards \\(\\pi/2\\), where the manip variable has no contribution to the projection. Step back to \\(\\phi_1\\). In each of the steps 3-5, a small step may be added to ensure that the endpoints of \\(\\phi\\) (\\(0\\), \\(\\pi/2\\), \\(\\phi_1\\)) is reached. 3.1.2.6 Step 5) Projecting the data The operation of a manual tour is defined on the projection bases. Only when the data plot needs to be made the data projected into the relevant basis. \\[\\begin{align*} \\textbf{Y}^{(i)}_{[n,~3]} &amp;= \\textbf{X}_{[n,~p]} \\textbf{M}_{[p,~3]} \\textbf{R}^{(i)}_{[3,3]} \\end{align*}\\] where \\(\\textbf{R}^{(i)}_{[3,3]}\\) is the incremental rotation matrix, using \\(\\phi_i\\). To make the data plot, use the first two columns of . Show the projected data for each frame in sequence to form an animation. Tours are typically viewed as an animation. The animation of this tour can be viewed online on GitHub. The page may take a moment to load. 3.2 Oblique cursor movement In a move abbreviated way we can think about the algorithm for 1D and 2D oblique manual tours as: 3.3 Package structure In addition to facilitating the manual tour the other primary function is to facilitate the layered composition of tours, interoperabily with tours from tourr. This package tries to abstract away the complexity of dealing with a varying number of frames and replicating the length of arguments. We use a layered composition approach to tours steming from ggplot2 (Hadley Wickham 2016), which can then be animated animation by plotly (Sievert 2020) or gganimate (Pedersen and Robinson 2020). This section describes the functions available in the package, their usage, and how to install and get up and running. 3.3.1 Usage Using the penguins data , available in the package, to illustrate a manual tour, we will illustrate generating a manual tour to explore the sensitivity of a variable separating two clusters. The composition of the tour display echos the additive layered approach of ggplot2, while abstracting away the complexity of dealing with changing number of frames and their animation. ## Process penguins data dat &lt;- scale_sd(penguins[1:4]) clas &lt;- penguins$species bas &lt;- basis_olda(data = dat, class = clas) ## A manual tour tour path mt_path &lt;- manual_tour(basis = bas, manip_var = 1, data = dat) ## Composing the display of the tour ggt &lt;- ggtour(mt_path, angle = .15) + proto_point(aes_args = list(color = clas, shape = clas), identity_args = list(alpa = .8, size = 1.5)) + proto_basis() + proto_origin() ## Animating animate_plotly(ggt, fps = 5) ## A 1D grand tour from tourr gt_path &lt;- save_history( data = dat, tour_path = grand_tour(d = 1), max_bases = 10) ## Composing the display of the tour ggt2 &lt;- ggtour(gt_path, angle = .15) + proto_default(aes_args = list(color = clas, fill = clas)) + proto_basis1d() + proto_origin1d() ## Animating animate_plotly(ggt2, fps = 5) 3.3.2 Functions Table 3.1 lists the primary functions and their purpose. These are grouped into four types: processing the data, production of tour path, the composition of the tour display, and its animation. Table 3.1: Summary of primary functions. Family Function Related to Description processing scale_01/sd scale each column to [0,1]/std dev away from the mean processing basis_pca/olda/ Rdimtools::do.* basis of orthogonal component spaces processing basis_half_circle basis with uniform contribution across half of a circle processing basis_guided tourr::guided_tour silently return the basis from a guided tour tour path manual_tour basis and interpolation information for a manual tour tour path save_history tourr::save_history silent, extended wrapper returning other tour arrays display ggtour ggplot2::ggplot canvas and initialization for a tour animation display proto_point/text geom_point/text adds observation points/text display proto_density/2d geom_density/2d adds density curve/2d contours display proto_hex geom_hex adds hexagonal heatmap of observations display proto_basis/1d adds adding basis visual in a unit-circle/-rectangle display proto_origin/1d adds reference mark in the center of the data display proto_default/1d wrapper for proto_* point + basis + origin display facet_wrap_tour ggplot2::facet_wrap facets on the levels of variable display append_fixed_y add/overwrite a fixed vertical position animation animate_plotly plotly::ggplotly render as an interactive hmtl widget animation animate_gganimate gganimate::animate render as a gif, mp4, or other video format animation filmstrip static gpplot faceting on the frames of the animation 3.3.3 Installation The spinifex is available from CRAN, the following code will help to get up and running: # Installation: install.package(&quot;spinifex&quot;) ## Install from CRAN library(&quot;spinifex&quot;) ## Load into session # Getting started: ## Shiny app for visualizing basic application run_app(&quot;intro&quot;) ## View the code vignette vignette(&quot;getting_started_with_spinifex&quot;) ## More about proto_* functions vignette(&quot;ggproto_api&quot;) 3.4 Use cases Wang et al. (2018) introduce a new tool, PDFSense, to visualize the sensitivity of hadronic experiments to nucleon structure. The parameter-space of these experiments lies in 56 dimensions, and are approximated as the ten first principal components. Cook, Laa, and Valencia (2018) illustrates how to learn more about the structures using a grand tour. Tours can better resolve the shape of clusters, intra-cluster detail, and better outlier detection than PDFSense &amp; TFEP (TensorFlow embedded projections) or traditional static embeddings. This example builds from here, illustrating how the manual tour can be used to examine the sensitivity of structure in a projection to different parameters. The specific 2D projections passed to the manual tour were provided in their work. The data has a hierarchical structure with top-level clusters; DIS, VBP, and jet. Each cluster is a particular class of experiments, each with many experimental datasets which each have many observations of their own. In consideration of data density, we conduct manual tours on subsets of the DIS and jet clusters. This explores the sensitivity of the structure to each of the variables in turn and we present the subjectively best and worst variable to manipulate for identifying dimensionality of the clusters and describing the span of the clusters. 3.4.1 Jet cluster The jet cluster resides in a smaller dimensionality than the full set of experiments, with four principal components explaining 95% of the variation in the cluster (Cook, Laa, and Valencia 2018). The data within this 4D embedding is further subset to ATLAS7old and ATLAS7new, to focus on two groups that occupy different parts of the subspace. Radial manual tours controlling contributions from PC4 and PC3 are shown in Figures 3.4 and 3.5, respectively. The difference in shape can be interpreted as the experiments probing different phase spaces. Back-transforming the principal components to the original variables can be done for a more detailed interpretation. When PC4 is removed from the projection (Figure 3.4), the difference between the two groups is removed, indicating that PC4 is essential for the separation of experiments. However, eliminating PC3 from the projection (Figure 3.5) does not affect the structure, meaning PC3 is not important for distinguishing experiments. Animations for the remaining PCs can be viewed at the following links: PC1, PC2, PC3, and PC4. It can be seen that only PC4 is important for viewing the difference in these two experiments. Figure 3.4: Select frames from a radial tour of PC4 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When PC4 is removed from the projection (frame 10), there is little difference between the clusters, suggesting that PC4 is important for distinguishing the experiments. Figure 3.5: Frames from the radial tour manipulating PC3 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When the contribution from PC3 is changed, there is little change in the separation of the clusters, suggesting that PC3 is not important for distinguishing the experiments. 3.4.2 DIS cluster Following Cook, Laa, and Valencia (2018), to explore the DIS cluster, PCA is recomputed and the first six principal components, explaining 48% of the full sample variation, are used. The contributions of PC6 and PC2 are explored in Figures 3.6 and 3.7, respectively. Three experiments are examined: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). Both PC2 and PC6 contribute to the projection similarly. When PC6 is rotated into the projection, variation in the DIS HERA1+2 is greatly reduced. When PC2 is removed from the projection, dimuon SIDIS becomes more distinct. Even though both variables contribute similarly to the original projection their contributions have quite different effects on the structure of each cluster, and the distinction between clusters. Animations of all of the principal components can be viewed from the links: PC1, PC2, PC3, PC4, PC5, and PC6. Figure 3.6: Select frames from a radial tour exploring the sensitivity that PC6 has on the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). DIS HERA1+2 is distributed in a cross-shaped plane, and charm SIDIS occupies the center of this cross, and dimuon SIDIS is a linear cluster crossing DIS HERA1+2. As the contribution of PC6 is increased, DIS HERA1+2 becomes almost singular in one direction (frame 5), indicating that this cluster has very little variability in the direction of PC6. Figure 3.7: Frames from the radial tour exploring the sensitivity PC2 to the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). As the contribution of PC2 is decreased, dimuon SIDIS becomes more distinguishable from the other two clusters, indicating that in the absence of PC2 is important for separating this cluster from the others. 3.5 Discussion Dynamic linear projections of numeric multivariate data, tours, play an important role in data visualization; they extend the dimensionality of visuals to peek into high-dimensional data and parameter spaces. This research has taken the manual tour algorithm, specifically the radial rotation, used in GGobi (Swayne et al. 2003) to interactively rotate a variable into or out of a 2D projection, and modified it to create an animation that performs the same task. It is most useful for examining the importance of variables and how the structure in the projection is sensitive or not to specific variables. This functionality is made available in the package spinifex. Which also extends the geometric display and export formats interoperable with the tourr package. This work was motivated by problems in physics, and thus the usage was illustrated on data comparing experiments of hadronic collisions to explore the sensitivity of cluster structure to different principal components. These tools can be applied quite broadly to many multivariate data analysis problems. The manual tour is constrained in the sense that the effect of one variable is dependent on the contributions of other variables in the manip space. However, this can be useful to simplify a projection by removing variables without affecting the visible structure. Defining a manual rotation in high dimensions is possible using Givens rotations and Householder reflections as outlined in Buja et al. (2005). This would provide more flexible manual rotation but more difficult for a user because they have the choice (too much choice) of which directions to move. "],["4-ch-userstudy.html", "Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data 4.1 User study 4.2 Results 4.3 Conclusion", " Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data The previous chapter introduced the package spinifex which gave us the means to perform radial tours. There is no evidence to support that the user-controlled steering of the radial tour leads to better perception than traditional methods. Therefore, this chapter discusses the user study to elucidate the efficacy of the radial tour. In Chapters 1 and 2 have introduced PCA, the grand tour, and radial tour. This chapter describes a within-participants user study evaluating efficacy of these techniques. A supervised classification task is devised where participants evaluate variable attribution of the separation between two classes. An accuracy measure is defined to use as the response variable. Data were collected from 108 crowdsourced participants, who performed two trials of each visual for 648 trials in total. The user influence over a basis, uniquely available in the radial tour, is crucial to testing variable sensitivity to the structure visible in projection. If the contribution of a variable is reduced and the feature disappears, then it is said that the variable is sensitive to that structure. For example, Figure 4.1 shows two frames of simulated data. Panel (a) has identified separation between the two clusters. The contributions in panel (b) show no such cluster separation. The former has a large contribution to V2 in the direction of separation, while it is negligible in the right frame. Because of this it is said that V2 is sensitive to the separation of the clusters. Figure 4.1: Illustration of cluster separation. Panel (a) shows clear separation in V2 and no separation in the direction of V3. While V1 and v4 have relatively small contributions to the frame. Panel (b) has a random basis with a minimal contribution from V2, and no separation between the cluster means is resolved. Knowing which variables to use is also important for statistical modeling and their interpretations. Models are becoming increasingly complex, and the nonlinear interactions of the terms cause an opaqueness to model interpretability. Exploratory Artificial Intelligence (XAI, Adadi and Berrada 2018; Arrieta et al. 2020) is an emerging field that extends the interpretability of such black-box models. Multivariate data visualization is essential for exploring features spaces and communicating interpretations of models (Biecek 2018; Biecek and Burzykowski 2021; Hadley Wickham, Cook, and Hofmann 2015). The chapter is structured as follows. Section 4.1 describes the experimental factors, task, and accuracy measure used. The results of the study are discussed in Section 4.2. Conclusions and potential future directions are discussed in Section 4.3. The software used for the study is described in Section A.1. 4.1 User study An experiment was constructed to assess the performance of the radial tour relative to the grand tour and PCA for interpreting the variable attribution contributing to separation between two clusters. Data were simulated across three experimental factors: cluster shape, location of the cluster separation, and data dimensionality. Participant responses were collected using a web application and crowdsourced through prolific.co, (Palan and Schitter 2018) an alternative to MTurk. 4.1.1 Objective PCA will be used as a baseline for comparison as it is the most commonly used linear embedding. The grand tour will act as a secondary control that will help evaluate the benefit of animation without influencing its path. Lastly, the radial tour should perform best as it benefits from animation and user control. Then for some subset of tasks, we expect to find that the radial tour performs most accurately. In the appendix, section A.2, regresses on the log response time. Due to the absence of inputs, the grand tour may lead to faster response time than the alternatives since users can focus all of their attention on interpreting the fixed path. Conversely, we are less sure about the accuracy of such limited grand tours as there is no objective function in selecting the bases; it is possible that the random selection of the target bases altogether avoids bases showing cluster separation. However, given that the data dimensionality was modest, it seems plausible that the grand tour coincidentally regularly crossed frames with the correct information for the task. An experimental factors and definition of an accuracy measure are given below. The null hypothesis can be stated as: \\(~~~~H_0: \\text{accuracy does not change across visual method} \\\\\\) \\(~~~~~H_\\alpha: \\text{accuracy does change across visual method} \\\\\\) 4.1.2 Experimental factors In addition to the visual, data are simulated across three experimental factors. First, the location of the separation between clusters by mixing a signal and a noise variable at different ratios. Secondly, the shape of the clusters reflects varying distributions of the data. And third, the dimension-ality of the data. The levels within each of factors are described below and Figure 4.2 gives a visual representation. Figure 4.2: Illustration of the experimental factors, the parameter space of the independent variables, the support of our study. The location of the separation of the clusters is at the heart of the measure. It would be good to test a few varying levels. To test the sensitivity, noise and signal-containing variables are mixed. The separation between clusters are mixed at the following percentages: 0/100% (not mixed), 33/66%, 50/50% (evenly mixed). In selecting the shape of the clusters, the convention given by Scrucca et al. (2016) is followed. They describe 14 variants of model families containing three clusters. The name of the model family is the abbreviation of its respective volume, shape, and orientation of the clusters, the levels of which are either _E_qual or _V_ary. The models EEE, EEV, and EVV are used. For Instance, in the EEV model, the volume and shape of clusters are constant, while the shapes orientation varies. The EVV model is further modified by moving four-fifths of the data out in a V or banana-like shape. Dimension-ality is tested at two modest levels, namely, in four dimensions containing three clusters and six dimensions with four clusters. Such modest dimensionality is required to bound the difficulty and search space to keep the task realistic for crowdsourcing. 4.1.3 Task and evaluation With our hypothesis formulated and data at hand, let us turn our attention to the task and how to evaluate it. Regardless of the visual method, the elements of the display are held constant, shown as a 2D scatterplot with an axis biplot to its left. Observations were supervised with the cluster level mapped to color and shape. Participants were asked to check any/all variables that contribute more than average to the cluster separation green circles and orange triangles, which was further explained in the explanatory video as mark any and all variable that carries more than their fair share of the weight, or one quarter in the case of four variables. The instructions iterated several times in the video was: 1) use the input controls to find a frame that contains separation between the clusters of green circles and orange triangles, 2) look at the orientation of the variable contributions in the gray circle (biplot axes orientation), and 3) select all variables that contribute more than uniformed distributed cluster separation in the scatterplot. Independent with experimental level, participants were limited to 60 seconds for each evaluation of this task. This restriction did not impact many participants as the 25th, 50th, 75th quantiles of the response time were about 7, 21, and 30 seconds respectively. The evaluation measure of this task was designed with a few features in mind: 1) the sum of squares of the individual variable weights should be one, 2) symmetric about zero, that is, without preference to under- or over-guessing 3) heavier than linear weight with increasing distance from a uniform height. The following measure is defined for evaluating the task with these in mind. Let a data \\(\\textbf{X}_{n,~p,~k}\\) be a simulation containing clusters of observations of different distributions. Where \\(n\\) is the number of observations, \\(p\\) is the number of variables, and \\(k\\) indicates the cluster an observation belongs. Cluster membership is exclusive; an observation cannot belong to more than one cluster. The weights, \\(w\\) as a vector explaining the variable-wise difference between two clusters. Namely, the difference of each variable between clusters, as a proportion of the total difference, less \\(1/p\\), the expected cluster separation if it were uniformly distributed. Participant responses are a logical value for each variable - whether or not the participant thinks each variable separates the two clusters more than uniformly distributed separation. \\[\\begin{align*} w_{j} &amp;=\\frac{(\\overline{X}_{\\cdot, j=1, k=1} - \\overline{X}_{\\cdot, 1, 2}, ~...~ (\\overline{X}_{\\cdot, p, 1} - \\overline{X}_{\\cdot, p, 2})} {\\sum_{j=1}^{p}(|\\overline{X}_{\\cdot, j, k=1} - \\overline{X}_{\\cdot, j, 2}|)} - \\frac{1}{p} \\shortintertext{Where accuracy, A, is defined as:} A &amp;= \\sum_{j=1}^{p}I(j) \\cdot sign(w_j) \\cdot w^2 \\end{align*}\\] Where \\(I(j)\\) is the indicator function, the binary response for variable \\(j\\). Figure 4.3 shows one frame of a simulation with its observed variable separation (wide bars), expected uniform separation (dashed line), and accuracy if selected (thin lines). Figure 4.3: Illustration of how accuracy is measured. (L), Scatterplot and biplot of PC1 by PC4 of a simulated data set (R) illustration of cluster separation between the means of the green circles and orange triangles. Bars indicate observed cluster separation and (red/green) lines show the accuracy weight of the variable if selected. The horizontal dashed line is \\(1 / p\\), the expected value. The weights equal the signed square of the difference between each variable value and the dashed line. 4.1.4 Visual design standardization The visuals are tested within-participant, with each visual being evaluated twice by each participant. The order that experimental factors are experienced is controlled with the assignment, as illustrated in Figure 4.4. Below discusses the design standardization and input uniqueness within each visual. The visualization methods were standardized wherever possible. Data were displayed as 2D scatterplots with biplots (Gabriel 1971), a visual with variable contributions inscribed on a unit circle. All aesthetic values (colors, shapes, sizes, absence of legend, and axis titles) were constant. Variable contributions were always shown left of the scatterplot embeddings with their aesthetic values consistent. What did vary between visuals were their inputs. PCA inputs allowed users to select between the top four principal components for both axes regardless of the data dimensionality (four or six). Data were simulated to have cluster separation within the 2nd to 4th components. Cluster separation was sampled to not bury signal in 5th and 6th components (not selectable in PCA input) in the interest of simplicity and time. There was no user input for the grand tour; users were instead shown a 15-second animation of the same randomly selected path. Participants could view the same clip up to four times within the time limit. Radial tours were also displayed at five frames per second with a step size of 0.1 radians between interpolated frames. Users were able to swap between variables. Selecting a new variable resets the animation where the new variable is manipulated to a full, zero, and then back to its initial contribution. The complete animation of any variable takes about 20 seconds and is almost entirely in the projection frame at around six seconds. The starting basis was initialized to a half-clock design, where the variables were evenly distributed in half of the circle. This design was created to be variable agnostic while maximizing the independence of the variables. 4.1.5 Data simulation Each dimension is originally distributed as \\(\\mathcal{N}(0, 1)\\), given the covariance set by the shape factor. Clusters were originally separated by a distance of two before location mixing. Signal variables had a correlation of 0.9 when they had equal orientation and -0.9 when their orientations varies. Noise variables were restricted to zero correlation. Each cluster is simulated with 140 observations and is offset in a variable that did not distinguish previous variables. Clusters of the EVV shape are transformed to the banana-chevron shape (illustrated in figure 4.2, shape row). Then location mixing is applied by post-multiplying a (2x2) rotation matrix to the signal variable and a noise variable for the clusters in question. All variables are then standardized by standard deviation. The rows and columns are then shuffled randomly. The observations cluster and order of shuffling are attached to the data and saved. Each of these replications is then iterated with each level of the visual. For PCA, projections were saved for each of the 12 pairs of the top four principal components. A basis path is saved for a 4- and 6D grand tour. The data from each simulation is then projected through its corresponding bases path. Each simulations variable order was previously shuffled, effectually randomizing cluster separation shown. The resulting animations were saved as gif files. The radial tour starts at either the four or six variable half-clock basis, where each variable has a uniform contribution in the right half with no variable contributing in the opposite direction. This acts to minimize the dependence between variable contributions. A radial tour is then produced for each variable and saved as a gif. 4.1.6 Randomized assignment Now, with simulation and their artifacts in hand, we explain how the experimental factors are assigned and illustrate how this is experienced from a participants perspective. The study is sectioned into three periods. Each period is linked to a randomized level of visual and location. The order of dimension and shape are of secondary interest and are held constant in increasing order of difficulty; four then six dimensions and EEE, EEV, then EVV-banana, respectively. Each period starts with an untimed training task at the simplest remaining experimental levels; location = 0/100%, shape = EEE, and four dimensions with three clusters. This serves to introduce and familiarize participants with input and visual differences. After the training, the participant performs on two trials with the same visual and location level across the increasing difficulty of dimension and shape. The plot was removed after 60 seconds, though participants rarely reached this limit. The order of the visual and location levels is randomized with a nested Latin square where all levels of the visuals are exhausted before advancing to the next level of location. That requires \\(3!^2 = 36\\) participants to evaluate all permutations of the experimental factors once. This randomization controls for potential learning effects the participant may receive. Figure 4.4 illustrates how an arbitrary participant experiences the experimental factors. Figure 4.4: Illustration of how a hypothetical participant 63 is assigned experimental factors. Each of the six visual order permutations is exhausted before iterating to the next permutation of location order. Through pilot studies sampled by convenience (information technology and statistics Ph.D. students attending Monash University), it is estimated that three full evaluations are needed to properly power the study, for a total of \\(N = 3 \\cdot 3!^2 = 108\\) participants. 4.1.7 Participants \\(N = 108\\) participants were recruited via prolific.co (Palan and Schitter 2018). Participants are restricted based on their claimed education requiring that they have completed at least an undergraduate degree (some 58,700 of the 150,400 users at the time). This restriction is used on the premise that linear projections and biplot displays will not be regularly used for consumption by general audiences. There is also the implicit filter that Prolific participants must be at least 18 years of age and implicit biases of timezone, location, and language. Participants were compensated for their time at 7.50 per hour, whereas the mean duration of the survey was about 16 minutes. Previous knowledge or familiarity was minimal as validated in the follow-up survey. The appendix contains a heatmap distribution of age and education paneled across preferred pronouns of the participants that completed the survey, who are relatively young, well educated, and slightly more likely to identify as males. 4.1.8 Data collection Data were recorded in shiny application and written to a Google Sheet after each third of the study. Especially at the start of the study, participants experienced adverse network conditions due to the volume of participants hitting the application with modest allocated resources. In addition to this, API read/write limitations further hindered data collection. To mitigate this, the number of participants were throttled and over-collect survey trials until three evaluations are collected for all permutation levels. The processing steps were minimal. The data were formatted and then filtered to only the latest three complete studies of each experimental factor, which should have experienced the least adverse network conditions. The bulk of the studies removed were partial data and a few over-sampled permutations. This brings us to the 108 studies described in the paper, from which models and aggregation tables were built. The post-study surveys were similarly decoded to human-readable format and then filtered to include only those 84 associated with the final 108 studies. The code, response files, their analyses, and the study application are publicly available at; . 4.2 Results To recap, the primary response variable is task accuracy, as defined in section 4.1.3. The parallel analysis of the log response time is provided in the appendix. Two primary data sets were collected; the user study evaluations and the post-study survey. The former is the 108 participants with the experimental factors: visual, location of the cluster separation signal, the shape of variance-covariance matrix, and the dimensionality of the data. Experimental factors and randomization were discussed in section 4.1.2. The survey was completed by 84 of these 108 people. It collected demographic information (preferred pronoun, age, and education), and subjective measures for each visual (preference, familiarity, ease of use, and confidence). Below a battery of mixed regression models is built to examine the degree of the evidence and the size of the effects from the experimental factors. Then, Likert plots and rank-sum tests to compare the subjective measures between the visuals. 4.2.1 Accuracy To quantify the contribution of the experimental factors to the accuracy a linear mixed-effects model is fitted. All models have a random effect term on the participant and the simulation. These terms explain the error attributed to the individual participants effect and variation due to the random sampling data. In building a set of models to test, a base model with only the visual term is compared with the full linear model term and progressively crossing an additional experimental factor. The models with three and four interacting variables are rank deficient; there is not enough varying information in the data to explain all interacting terms. \\[ \\begin{array}{ll} \\textbf{Fixed effects} &amp;\\textbf{Full model} \\\\ \\alpha &amp;\\widehat{Y} = \\mu + \\alpha_i + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha + \\beta + \\gamma + \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha \\cdot \\beta + \\gamma + \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i \\cdot \\beta_j + \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha \\cdot \\beta \\cdot \\gamma + \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i \\cdot \\beta_j \\cdot \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha \\cdot \\beta \\cdot \\gamma \\cdot \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i \\cdot \\beta_j \\cdot \\gamma_k \\cdot \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\end{array} \\] \\[ \\begin{array}{ll} \\text{where } &amp;\\alpha_i \\text{, fixed term for visual}~|~i\\in (\\text{pca, grand, radial}) \\\\ &amp;\\beta_j \\text{, fixed term for location}~|~j\\in (\\text{0/100\\%, 33/66\\%, 50/50\\%}) \\text{ \\% noise/signal mixing} \\\\ &amp;\\gamma_k \\text{, fixed term for shape}~|~k\\in (\\text{EEE, EEV, EVV banana}) \\text{ model shapes} \\\\ &amp;\\delta_l \\text{, fixed term for dimension}~|~l\\in (\\text{4 variables \\&amp; 3 cluster, 6 variables \\&amp; 4 clusters}) \\\\ &amp;\\mu \\text{ is the intercept of the model including the mean of random effect} \\\\ &amp;\\textbf{Z} \\sim \\mathcal{N}(0,~\\tau), \\text{ the error of the random effect of participant} \\\\ &amp;\\textbf{W} \\sim \\mathcal{N}(0,~\\upsilon), \\text{ the error of the random effect of simulation} \\\\ &amp;\\epsilon \\sim \\mathcal{N}(0,~\\sigma), \\text{ the remaining error in the model} \\\\ \\end{array} \\] Table 4.1: Model performance of random effect models regressing accuracy. Each model includes a random effect term of the participant explaining the individuals influence on accuracy. Complex models perform better in terms of \\(R^2\\) and RMSE, yet AIC and BIC penalize their large number of fixed effects in favor of the much simpler model containing only the visuals. Conditional \\(R^2\\) includes the random effects, while marginal does not. Fixed effects No. levels No. terms AIC BIC R2 cond. R2 marg. RMSE a 1 3 -71 -44 0.303 0.018 0.194 a+b+c+d 4 8 -45 4 0.334 0.056 0.194 a*b+c+d 5 12 -26 41 0.338 0.064 0.193 a*b*c+d 8 28 28 167 0.383 0.108 0.19 a*b*c*d 15 54 105 360 0.37 0.222 0.185 Table 4.2: The task accuracy model coefficients for \\(\\widehat{Y} = \\alpha \\cdot \\beta + \\gamma + \\delta\\), with visual = pca, location = 0/100%, shape = EEE, and dim = 4 held as baselines. Visual being radial is the fixed term with the strongest evidence supporting the hypothesis. Interacting with the location term there is evidence suggesting radial performs worse with 33/66% mixing. Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 0.10 0.06 16.1 1.54 0.143 visual Factorgrand 0.06 0.04 622.1 1.63 0.104 Factorradial 0.14 0.04 617.0 3.77 0.000 *** fixed effects Location33/66% -0.02 0.07 19.9 -0.29 0.777 Location50/50% -0.04 0.07 20.0 -0.66 0.514 ShapeEEV -0.05 0.06 11.8 -0.82 0.427 Shapebanana -0.09 0.06 11.8 -1.54 0.150 Dim6 -0.01 0.05 11.8 -0.23 0.824 interactions Factorgrand:Location33/66% -0.02 0.06 588.9 -0.29 0.774 Factorradial:Location33/66% -0.12 0.06 586.5 -2.13 0.033 Factorgrand:Location50/50% -0.03 0.06 591.6 -0.47 0.641 Factorradial:Location50/50% -0.06 0.06 576.3 -1.16 0.248 Table 4.1 compares the model summaries across increasing complexity. The \\(\\alpha \\cdot \\beta + \\gamma + \\delta\\) model to is selected to examine in more detail. Table 4.2 looks at the coefficients for this model. We also want to visually examine the conditional variables in the model. Figure 4.5 examines violin plots of accuracy by visual with panels distinguishing location (vertical) and shape (horizontal). Use of the radial tour, on average, increases the accuracy, and especially so when the location of signal mixing is not 33/66%. Figure 4.5: Violin plots of terms of the model \\(\\widehat{Y} = \\alpha \\cdot \\beta + \\gamma + \\delta\\). Overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked-sum tests suitable for handling discrete data. Participants are more confident and find the radial tour easier to use than the grand tour. Participants claim low familiarity, as expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task. 4.2.2 Subjective measures The 84 evaluations of the post-study survey also collect four subjective measures for each visual. Figure 4.6 shows the Likert plots, or stacked percentage bar plots, alongside violin plots with the same non-parametric, ranked sum tests previously used. Participants preferred to use radial for this task. Participants were also more confident of their answers and found radial tours easier than grand tours. All visuals have reportedly low familiarity, as expected from crowdsourced participants. Figure 4.6: The subjective measures of the 84 responses of the post-study survey, five discrete Likert scale levels of agreement (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests. 4.3 Conclusion Data visualization is an integral part understanding relationships in data, and how models are fitted. However, thorough exploration of data in high dimensions becomes difficult. Previous methods offer no means for an analyst to impact the projection basis. The manual tour provides a mechanism for changing the contribution of a selected variable to the basis. Giving analysts such control should facilitate the exploration of variable-level sensitivity to the identified structure. This paper discussed a with-in participant user study (\\(n=108\\)) comparing the efficacy of three linear projection techniques. The participants performed a supervised cluster task, explicitly identifying which variables contribute to separating two target clusters. This was evaluated evenly over four experimental factors. In summary, mixed model regression finds strong evidence that using the radial tour leads to a sizable accuracy increase. In the extended analysis, there is significant evidence for a change in response time, with PCA being fastest, then the grand tour, followed by the radial tour. The effect sizes on accuracy are large relative to the change from the other experimental factors, though smaller than the random effect of the participant. The radial tour was subjectively preferred, leading to more confidence in answers, and increased ease of use than the alternatives. There are several ways that this study could be extended. In addition to expanding the support of the experimental factors, more exciting directions include: changing the task, visualizations used, and experience level of the target population. It is difficult to achieve good coverage given the number of possible permutations. Keep in mind the traffic volume and low effort of responses from participants when crowdsourcing. "],["5-ch-cheem.html", "Chapter 5 Exploring Local Explanations of Nonlinear Models Using the Radial tour 5.1 SHAP and tree SHAP local explanations 5.2 The cheem viewer 5.3 Case studies 5.4 Discussion", " Chapter 5 Exploring Local Explanations of Nonlinear Models Using the Radial tour In the previous chapter discussed the within-participants user study comparing PCA, the grand tour, and the radial tour in a supervised variable attribution task. There was strong evidence that the radial tour leads to large increase in accuracy. Now the analyst can be more confident that the radial tour leads to better analysis of variable-level attribution to features identified in a projection. Given the interpretability crisis of nonlinear models, it would be interesting to see if the radial tour can help. Specifically, we will investigate using the radial tour to explore variable sensitivity to the structure identified in linear local explanations of nonlinear models. That is under what range of variable importance does an explanation make sense, and when does it fail to be supported by the data. This can provide insight into why an observation is misclassified or otherwise has an extreme residual. The radial tour can also test how susceptible a variables contribution is to discerning the predictions of two observations. The increased predictive power comes at the cost of interpretability, which has led to the emergence of eXplainable AI (XAI). XAI attempts to shed light on how models use predictors to arrive at a prediction with a point estimate of the linear feature importance in the vicinity of each instance. These can be considered linear projections and can be further explored interactively to understand better the interaction between features used to make predictions across the predictive model surface. Here we describe interactive linear interpolation used for exploration at any instance and illustrate with examples with categorical (penguin species, chocolate types) and quantitative (football salaries, house prices) output. The methods are implemented in the R package cheem, available on CRAN. Chapter 2 introduced predictive modeling, the interpretability crisis of nonlinear models, and local explanations  approximations of linear variable importance in the vicinity of one observation. The remainder of this chapter is organized as follows. The following Section, 5.1, induces the SHAP and tree SHAP local explanation. Section 2.3.1 explains the animations of continuous linear projections. Section 5.2 discusses the visual layout in the interactive interface, how they facilitate analysis, data preprocessing, and package infrastructure. Then Section 5.3 illustrates the application to supervised learning with categorical and quantitative output. Section 5.4 concludes with the insights gained and directions that might be explored in the future. 5.1 SHAP and tree SHAP local explanations SHaply Additive exPlanations (SHAP) quantifies the feature contributions of one instance by examining the effect of other features on the predictions. The explanations of SHAP almost all refer to Shapley (1953)s method to evaluate an individuals contribution to cooperative games by assessing the performance of this player in the presence or absence of other players. Strumbelj and Kononenko (2010) introduced the use of SHAP for local explanations in ML models. The attribution of feature importance depends on the sequence of the included features. The SHAP values are the mean contributions over different feature sequences. The approach is related to partial dependence plots (Molnar 2020), used to explain the effect of a feature by predicting the response for a range of values on this feature after fixing the value of all other features to their mean. Partial dependence plots are a global approximation of the feature importance, while SHAP is specific to one instance. It could also be considered similar to examining the coefficients from all subsets regression, as described in Hadley Wickham, Cook, and Hofmann (2015), which helps to understand the relative importance of each feature in the context of all other candidate features. Figure 5.1: Illustration SHAP values for a random forest model FIFA 2020 player wages from nine skill predictors. A star offensive and defensive player are compared, L. Messi and V. van Dijk, respectively. Panel (a) shows breakdown plots of three sequences of the features, order, and magnitude change. Panel (b) shows the distribution of attribution for each feature across 25 sequences of predictors, with the mean displayed as a dot for each player. Offense and movement are important for Messi but not van Dijk, and conversely, defense and power are important for van Dijk but not Messi. For the application, we use tree SHAP, a variant of SHAP that enjoys a lower computational complexity (Lundberg, Erion, and Lee 2018). Instead of aggregating over sequences of the features, tree SHAP calculates instance-level feature importance by exploring the structure of the decision trees. Tree SHAP is only compatible with tree-based models; random forests are used for illustration. The following section will use normalized SHAP values as a projection basis (call this the attribution projection) will have coefficients varied to further scrutinize the feature contributions. Following the use case Explanatory Model Analysis (Biecek and Burzykowski 2021), FIFA data is used to illustrate SHAP use. Consider soccer data from the FIFA 2020 season (Leone 2020). There are 5000 instances of 9 skill measures (after aggregating highly correlated features). A random forest model is fit, regressing players wages [2020 Euros] from their skill measurements. The SHAP values are compared for a star offensive player (L. Messi) and defensive player (V. van Dijk). The results are displayed in Figure 5.1. A difference in the attribution of the feature importance across the two positions of the players can be expected. This would be interpreted as how the players salary depends on this combination of skill sets. Plot (b) is a modified breakdown plot (Gosiewska and Biecek 2019) where the order of features is fixed, so the two instances can be more easily compared. In summary, these plots highlight how local explanations bring interpretability to a model, at least in the vicinity of their instances. In this instance, two players with different positions receive different profiles of feature importance to explain the prediction of their wages. 5.2 The cheem viewer To explore the local explanations, an ensemble of plots (Unwin and Valero-Mora 2018) is provided, called the cheem viewer. There are two primary plots: the global view to give the context of all of the SHAP values, and the radial tour view to explore the local explanations with user-controlled rotation. In addition, there are numerous user inputs, including feature selection for the radial tour and instance selection for making comparisons. There are different plots used for the categorical and quantitative responses. Figures 5.2 and 5.3 are screenshots showing the cheem viewer for the two primary tasks: classification (categorical response) and regression (quantitative response). 5.2.1 Global view The global view provides the context of all instances and facilitates the exploration of the separability of the data- and attribution-spaces. Both of these spaces are of dimension \\(n\\times p\\), where \\(n\\) is the number of instances and \\(p\\) is the number of predictors. The attribution space corresponds to the local explanations for each instance, each a vector of \\(p\\) values. A visualization is provided by the first two principal components of the data (left) and the attribution (middle) spaces. These single 2D projections will not reveal all of the structure of higher-dimensional space, but they are useful visual summaries. In addition, a plot of the observed against predicted response values is also provided (Figures 5.2b, 5.3a), to help identify instances poorly predicted by the model. For classification tasks, misclassified instances are circled in red if applicable. Linked brushing between the plots is provided, and a tabular display of selected points helps to facilitate exploration of the spaces and the model (shown in Figures 5.2a,c). While the comparison of these spaces is interesting, a main purpose of the global view is to enable the selection of instances to explore the local explanations. The projection attribution of the primary instance (PI) is examined and typically viewed with an optional comparison instance (CI). These instances are highlighted as asterisk and \\(\\times\\), respectively. 5.2.2 Radial tour The local explanations for all observations are normalized (squared sum of values adds to 1), and thus, the relative importance of features can be compared across all instances. These are depicted as a vertical parallel coordinate plot, where each line connects one instances feature attribution (Figures 5.2e and 5.3e). The attribution projections of the PI and CI are shown as dashed and dotted lines, respectively. From this plot,the range of importances across all instances can be interpreted. For classification, one would look at differences between groups on any feature. For example, Figure 5.2e suggests that bl is important for distinguishing the green class from the other two. For regression, one might generally observe which features have low values for all instances (not important), for example, BMI and pwr in Figure 5.3e, and which have a range of high and low values (e.g. off, def) suggesting important for some instances and not important for other instances. The overlaid bars on the parallel coordinate plot represent the attribution projection of the PI. (Remember that the PI is interactively selected from the global view). The attribution projection is an approximation of the feature importance for the prediction of this instance. This combination of features best explains the difference between the mean response and an instances predicted value. It is not an indication of the local shape of the model surface. That is, it is not some indication of the tangent to the curve at this point. The attribution projection of the PI is the initial 1D basis in a radial tour, displayed as a density plot for a categorical response (Figure 5.2f), and as scatterplots for a quantitative response (Figure 5.3f). The PI and CI are indicated by vertical dashed and dotted lines, respectively. The user uses the radial tour to vary the contribution of the selected feature between 0-1. Doing so tests the sensitivity of structure (class separation or strength of relationship) to the features contribution. For classification, if the separation between classes diminishes when the feature contribution is reduced then this suggests that the feature is important for the class separation. For regression, if the relationship scatterplot weakens when the feature contribution is reduced then this suggests that the feature is important for accurately predicting the response. 5.2.3 Classification task Selecting a misclassified instance as PI and a correctly classified point nearby in data space as CI makes it easier to examine the features most responsible for the error. The global view (Figure 5.2c) displays the model confusion matrix. The radial tour is 1D, plotted as a density where color indicates class. A scroll bar here enables the user to vary the contribution of each feature to explore the sensitivity of the separation to that feature. Figure 5.2: Overview of the cheem viewer for classification tasks. Global view inputs, (a), set the PI, CI, and color statistic. Global view, (b) PC1 by PC2 approximations of the data space and attribution space. (c) prediction by observed y (visual of the confusion matrix for classification tasks). Points are colored by predicted class, and red circles indicate misclassified instances. Radial tour inputs (d) select features to include and which feature is changed in the tour. (e) shows a parallel coordinate display of the distribution of the feature attributions while bars depict contribution for the current basis. The black bar is the variable being changed in the radial tour. Panel (f) is the resulting projection of the data indicated as density in the classification case. 5.2.4 Regression task Selecting an inaccurately predicted instance as PI and an accurately predicted instance, with similar feature values, as CI is a useful way to understand how the model is failing or not. The global view (Figure 5.3a) shows a scatterplot of the observed vs predicted values, which should exhibit a strong relationship if the model is a good fit. The points can be colored by a statistic, residual, a measure of outlyingness (log Mahalanobis distance), or correlation, to help with understand where the model fits better or worse. In the radial tour view, the observed response and the residuals (vertical) are plotted against the attribution projection of the PI (horizontal). The attribution projection can be interpreted similarly to the predicted value from the global view plot. It represents a linear combination of the features, and a good fit would be indicated when there is a strong relationship seen with the observed values. This can be viewed as a local linear approximation if the fitted model is nonlinear. As the contribution of a feature is varied, if the value of the PI does not change much, it would indicate that the prediction for this instance is NOT sensitive to that feature. Conversely, if the predicted value varies substantially, the prediction is very sensitive to that feature, suggesting that the feature is very important for the PIs prediction. Figure 5.3: Overview of the cheem viewer for regression task highlighting the differences from the classification task and interactive features. Panel (a) PCA of the data and attributions spaces, (b), residual plot, predictions by observed values. Four points are selected points and highlighted in the PC spaces and tabularly displayed. Coloring on a statistic (c) highlights structure organized in the attribution space. Interactive tabular display (d) populates when instances are selected. Contribution of the 1D basis affecting the horizontal position (e) parallel coordinate display of the feature attribution from all observations, and horizontal bars show the contribution to the current basis. Regression projection (f) uses the same horizontal projection and fixes the vertical positions to the observed y and residuals (left and right). 5.2.5 Interactive features The application has several reactive inputs that affect the data used, aesthetic display, and tour manipulation. These reactive inputs make the software flexible and extensible. The application also has more exploratory interactions to help link points across displays and reveal structure found in different spaces. A tooltip displays instance number/name and classification information while the cursor hovers over a point. Linked brushing allows the selection of points (left click and drag) where those points will be highlighted across plots. The information corresponding to the selected points is populated on a dynamic table. These interactions aid exploration of the spaces and, finally, identification of a primary and comparison instance. 5.2.6 Preprocessing It is vital to mitigate the render time of visuals, especially when users may want to iterate many times. All computational operations should be prepared before runtime. The work remaining when an application is run solely reacts to inputs and rendering visuals and tables. Below discusses the steps and details of the reprocessing. (ref:citeRf) (Liaw and Wiener 2002) (ref:citeTs) (Kominsarczyk et al. 2021) The time to preprocess the data will vary significantly with the model and local explanation. For reference, the FIFA data, 5000 instances of nine explanatory features, took 2.5 seconds to fit a random forest model of modest hyperparameters. Extracting the tree SHAP values of each instance took 270 seconds combined. PCA and statistics of the features and attributions took 2.8 seconds. These runtimes were from a non-parallelized R session on a modern laptop, but suffice to say that most of the time will be spent on the local attribution. An increase in model complexity or data dimensionality will quickly become an obstacle. Its reduced computational complexity makes tree SHAP a good candidate to start. (Alternatively, the package fastshap (Greenwell 2020) claims extremely low runtimes, attributed to fewer calls to the prediction function, partial implementation in C++, and efficient use of logical subsetting.) 5.2.7 Package infrastructure The above-described method and application are implemented as an open-source R package, cheem available on CRAN. Preprocessing was facilitated with models created via randomForest (Liaw and Wiener 2002) and explanations calculated with treeshap (Kominsarczyk et al. 2021). The application was made with shiny (Chang et al. 2021). The tour visual is built with spinifex (Spyrison and Cook 2020). Both views are created first with first with ggplot2 (Hadley Wickham 2016) and then rendered as interactive html widgets with plotly (Sievert 2020). DALEX (Biecek 2018) and the free ebook, Explanatory Model Analysis (Biecek and Burzykowski 2021) were a huge boon to understanding local explanations and how to apply them. 5.2.8 Installation and getting started The package can be installed from GitHub using the following R code: # Install remotes if absent if(require(&quot;remotes&quot;) == FALSE) install.packages(&quot;remotes&quot;) remotes::install.packages(&quot;cheem&quot;, dependencies = TRUE) library(&quot;cheem&quot;) run_app() To process your own data, you will need to use the treeshap package, which can be installed from GitHub: remotes::install_github(&#39;ModelOriented/treeshap&#39;) Follow the examples provided with the package to compute the local explainers, (see ?cheem_ls). The application expects the return of call from cheem_ls() which is then saved to an .rds file with saveRDS(). Alternatively, the cheem viewer shiny app can be directly accessed at ebsmonash.shinyapps.io/cheem_initial/. 5.3 Case studies To illustrate the use of the cheem method, it is applied to modern datasets, two classification examples and then two of regression. 5.3.1 Palmer penguin, species classification The Palmer penguins data (Gorman, Williams, and Fraser 2014; Horst, Hill, and Gorman 2020) was collected on three species of penguins foraging near Palmer Station, Antarctica. The data was publicly available to substitute for the overly-used iris data and is quite similar in form. After removing incomplete instances, there are 333 instances of four physical measurements, bill length (bl), bill depth (bd), flipper length (fl), body mass (bm), for this illustration. A random forest model was fit with species as the response feature. (ref:casepenguins) Examining the SHAP values for a random forest model classifying Palmer penguin species. The PI is a Gentoo (purple) Chinstrap (orange) penguin that is misclassified as a Chinstrap (orange), marked as an asterisk in (a), and the dashed vertical line in (b). The radial view shows varying the contribution of fl from the initial attribution projection (b, left), which produces a linear combination where the PI is more probably (higher density value) a Chinstrap than a Gentoo (b, right). (The animation of the radial tour is at vimeo.com/666431172.) Figure 5.4: (ref:casepenguins) Figure 5.4 shows plots from the cheem viewer for exploring the random forest model on the penguins data. Panel (a) shows the global view, and panel (b) shows several 1D projections generated with the radial tour. Penguin 243, a Gentoo (purple), is the PI because it has been misclassified as a Chinstrap (orange). (ref:casepenguinsblfl) Checking what is learned from the cheem viewer. This is a plot of flipper length (fl) and bill length (bl), where an asterisk highlights the PI. A Gentoo (purple) misclassified as a Chinstrap (orange). The PI has an unusually small f_l length which is why it is confused with a Chinstrap. Figure 5.5: (ref:casepenguinsblfl) There is more separation visible in the attribution space than the data space, as would be expected. The predicted vs observed plot reveals a handful of misclassified instances. A Gentoo has been wrongly labeled as a Chinstrap is selected for illustration. The PI is a misclassified point (represented by the asterisk in the global view and a dashed vertical line in the tour view). The CI is a correctly classified point (represented by an \\(\\times\\) and a vertical dotted line). The radial tour starts from the attribution projection of the misclassified instance (b, left). The important features identified by SHAP in the (wrong) prediction for this instance are mostly bl and bd with small contributions of fl and bm. This projection is a view where the Gentoo (purple) looks much more likely for this instance than Chinstrap. That is, this combination of features is not particularly useful because the PI looks very much like other Gentoo penguins. To explore this, the radial tour is used to vary the contribution of flipper length (fl). (In our exploration, this was the third feature explored. It is typically useful to explore the features with larger contributions, here bl and bd, but when doing this, nothing was revealed about how the PI differed from other Gentoos). On varying fl as it contributes more to the projection (b, right), more, and more, this penguin looks like a Chinstrap. This suggests that fl should be considered an important feature for explaining the (wrong) prediction. Figure 5.5 confirms that flipper length (fl) is important for the confusion of the PI as a Chinstrap. Here, flipper length and body length are plotted, and the PI can be seen to be closer to the Chinstrap group in these two features, mostly because it has an unusually low value of flipper length relative to other Gentoos. From this view, it makes sense that its a hard instance to account for as decision trees can only partition only vertical and horizontal lines. 5.3.2 Chocolates, milk/dark chocolate classification The chocolates dataset consists of 88 instances of ten nutritional measurements determined from their labels and labeled as either milk or dark. Dark chocolate is considered healthier than milk. The data was collected by students during the Iowa State University class STAT503 from nutritional information from the manufacturers website and normalized to 100g equivalents. The data is available in the cheem package. A random forest model is used for the classification of chocolate type. It could be interesting to examine the nutritional properties of any dark chocolates that have been misclassified as milk. A reason to do this is that a dark chocolate nutritionally more like milk should not be considered a healthy alternative. It is interesting to explore which of the nutritional features contribute most to misclassification. (ref:casechocolates) Examining the local interpretation for a PI which is dark (orange) chocolate incorrectly predicted to be milk (green). From the attribution projection, this chocolate correctly looks more like dark more than milk, which suggests that the local explanation does not help understand the prediction for this instance. So, the contribution of Sugar is varied  reducing it corresponds primarily with increasing Fiber. When Sugar is zero, Fiber is contributing strongly towards the left. In this particular view, the PI is closer to the bulk of the milk chocolates, suggesting that the prediction put a lot of importance on Fiber. This chocolate is a rare dark chocolate without any Fiber leading to it being mistaken for a milk chocolate. (A video of the tour animation can be found at vimeo.com/666431143.) Figure 5.6: (ref:casechocolates) This type of exploration is shown in Figure 5.6, where a chocolate labeled dark but predicted to be milk is chosen as the PI (instance 22). It is compared with a CI that is a correctly classified dark chocolate (instance 7). The PCA plot, and the tree SHAP PCA plots (a) show a big difference between the two chocolate types but with confusion for a handful of instances. The misclassifications are more apparent in the observed vs predicted plot, and can be seen to be mistaken in both ways: milk to dark and dark to milk. The attribution projection for chocolate 22 suggests that Fiber, Sugars, and Calories are most responsible for its incorrect prediction. The way to read this plot is to see that Fiber has a large negative value while Sugars and Calories have reasonably large positive values. In the density plot, instances on the very left of the display would have high values of Fiber (matching the negative projection coefficient) and low values of Sugars and Calories. The opposite would be interpreting a point with high values in this plot. The dark chocolates (orange) are mostly on the left, and this is a reason why they are considered to be healthier: high fiber and low sugar. The density of milk chocolates is further to the right, indicating that they generally have low fiber and high sugar. The instance of interest (dashed line) can be viewed against the comparison instance (dotted line). Now one needs to pay different attention to the parallel plot of the SHAP values, which are local to a particular instance, and the density plot, which is the same projection of all instances as specified by the SHAP values of the instance of interest. The feature contributions to the two different predictions can be quickly compared in the parallel coordinate plot. The instance of interest differs with the comparison primarily on the Fiber feature, which suggests that this is the reason for the incorrect prediction. From the density plot, which is the attribution projection corresponding to the instance of interest, both instances are more like dark chocolates. Varying the contribution of Sugars and altogether removing it from the projection, is where the difference becomes apparent. When primarily Fiber is examined, instance 22 looks more like a milk chocolate. (ref:casechocolatesinverse) Examining the local interpretation for a PI which is milk (green) chocolate incorrectly predicted to be dark (orange). In the attribution projection, the PI could be either milk or dark. Sodium and Fiber have the largest differences in attributed feature importance, both with low values relative to other milk chocolates. The lack of use of these variables is suspected to contribute to the mistake, so the contribution of Sodium is varied. If Sodium had a larger contribution to the prediction (like in this view). the PI would look more like other milk chocolates. (A video of the tour animation can be found at vimeo.com/666431148.) Figure 5.7: (ref:casechocolatesinverse) It would also be interesting to explore the inverse case. This would describe which features lead to a milk chocolate being misclassified as dark and how those attributions differ from the previous misclassification. Chocolate 84 is just this case, and is compared with a correctly predicted milk chocolate (instance 71). This exploration is shown in Figure 5.7. The difference of position in the tree SHAP PCA with the previous case is quite large; this gives an approximate feel that the attribution should be quite different. Looking at the initial contribution, this is found to be the case. Previously Fiber was very important while it is absent from the attribution in this case. Conversely, Calories from Fat and Total Fat are highly attributed here, while unimportant in the preceding case. Comparing the attribution with the CI (dotted line), discrepancies in Sodium and Fiber are identified. The contribution of Sodium is selected to be varied. The instance looks slightly more like its observed milk than predicted dark chocolate even in the initial projection. The misclassification appears least supported when the basis reaches sodium attribution of typical dark chocolate. 5.3.3 FIFA, wage regression The 2020 season FIFA data (Leone 2020; Biecek 2018) contains many skill measurements of soccer/football players and wage information. From a correlation matrix plot, nine higher-level skill groupings were identified and aggregated. A random forest model if fit from these aggregations and regress player wages [2020 euros]. The model was fit from 5000 instances before being thinned to 500 players to mitigate occlusion and render time. Continuing from the exploration in section 2.6, we are interested to see the difference in attribution based on the exogenous player position. That is, the model should be able to use multiple linear profiles to better predict the wages from different field positions of players. A leading offensive fielder (L. Messi) is compared with that of a top defensive fielder (V. van Dijk). The same instances were used in figure 5.1. (ref:casefifa) FIFA 2020 data, a random forest model, regresses wages [2020 Euros] from nine aggregated skill measurements. The PI is a star offensive player (L. Messi) compared with a top defensive player (V. van Dijk). Three features with low attribution from both players are removed. The attribution projection starts with the selected instance on the right. The contribution to defense (def) is varied. The star offensive player is not distinguished in the horizontal direction. At this point, defensive players have been rotated to the highest horizontal value. (A video of the animated radial tour can be found at vimeo.com/666431163.) Figure 5.8: (ref:casefifa) With figure 5.8, tests the support of the local explanation. Offensive and reaction skills (off and rct) are both crucial to explaining a star offensive player. If either of them were rotated out, the other will be rotated into frame, maintaining a far-right position. However, when varying the defensive skills, the other skills are rotated out of the frame. As the contribution of defensive skills increases, Messis is no longer separated from the group. Players with high values in defensive skills are now the rightmost points. In terms of what-if analysis, the difference between the data mean and his predicted wages would be halved if Messis tree SHAP attributions at these levels. 5.3.4 Ames housing 2018, sales price regression Ames 2018, housing data was subset to North Ames (the neighborhood with the most house sales). The remaining are 338 house sales. A random forest model has regressed this price with the features Lot Area (LtA), Overall Quality (Qlt), Year the house was Built (YrB), Living Area (LvA), number of Bathrooms (Bth), number of Bedrooms (Bdr), total number of Rooms (Rms), Year the Garage was Built (GYB), and Garage Area (GrA). Using interaction from the global view, a house with an extreme negative residual and an accurate instance with similar prediction are selected. (ref:caseames) Exploring an instance with a large residual as the PI from fitting sales price [USD] to other variables in the Ames housing 2018. The sale price of the PI was under-predicted. The local explanation indicates a sizable attribution to Lot Area (LtA). The CI has a similar predicted sales price and smaller residual and has minimal attribution to Lot Area. In the attribution projection, the PI has a higher sales price than the CI. Reducing the contribution of lot area brings these two prices in line. This suggests if the model did not consider Lot Area, then the two houses would be quite similar. That is, the large residual is due to a lack of factoring in the lot area for the prediction of PIs sales price. (A video showing the animation is at vimeo.com/666431134.) Figure 5.9: (ref:caseames) Figure 5.9 selects the house sale 74, a sizable under prediction with a large Lot Area contribution. The CI has a similar predicted price though the prediction was accurate and gives almost no attribution to lot size. The attribution projection is places instances with high Living Areas to the right. The contribution of Living Area control the contribution of this feature. As the contribution of lot area decreases, the predictive power decreases for the PI, while the CI remains stationary. This large of importance in the Living Area is relatively uncommon. Boosting tree models may be more resilient to such an under-prediction as up-weighting this residual would force its inclusion in the final model. 5.4 Discussion New tools to assist with the interpretability of black-box models is increasingly important. This chapter provides a technique that builds on local interpretations to explore the feature importance local to an instance. The local interpretations form an attribution projection from which feature contributions are varied using a radial tour. Several diagnostic plots are provided to assist with understanding the sensitivity of the prediction to particular features. A global view shows the data space, explanation space, model fit. The user can interactively select instances to compare, contrast, and study further. The approach has been illustrated on four data examples using random forest models and using the tree SHAP local explanation. In the penguins example, we showed how the misclassification of a penguin arose due to it having an unusually small flipper size compared to others of its species. This was verified by making a follow-up plot of the data, including this variable. The chocolates example shows how a dark chocolate was misclassified primarily due to it value on Fiber, and a milk chocolate was misclassified as dark due to its lowish Sodium value. For the FIFA example, we show how low Messis salary would be if it depended on defensive skills. In the Ames housing data, an inaccurate prediction for a house was likely due to the Lot Area not being effectively used. The approach is manually intensive and thus only feasible for investigating a few instances. The approach is to select instances that the model has not done well and compare it with an instance where it did fit well. The radial tour launches from the attribution projection to enable exploration of the sensitivity of the prediction to any feature. It can be helpful to make additional plots of the features and responses in order to cross-check interpretations made from the cheem viewer. This methodology provides an additional tool in the box for studying model fitting. An implementation is provided in the open-source R package cheem, available on CRAN. Example data sets are provided, and you can upload your data after model fitting and computing the local explanations. In theory, this approach would work with any black-box model but the implementation currently only calculates tree SHAP for tree-based models supported by treeshap (tree based models from randomForest, ranger, gbm, xgboost, lightgbm, or catboost). Tree SHAP was selected because of its computational efficiency. The SHAP and oscillation explanations could be added with the use of the DALEX::explain() and would be an excellent direction to extend the work (Biecek 2018; Biecek and Burzykowski 2021). "],["6-ch-conclusion.html", "Chapter 6 Conclusion 6.1 Contributions 6.2 Limitations 6.3 Future work", " Chapter 6 Conclusion Most data are multivariate. This thesis makes important contributions to interactive visualization of data where all variables are quantitative. The methods are built on dynamic animation of linear projections, called tours. The thesis developed the radial tour, illustrating that it improved understanding variable importance in higher dimensional data and can be used to better understand black-box models for XAI. 6.1 Contributions The contributions of this thesis can be split into scientific knowledge and software. 6.1.1 Scientific knowledge Chapter 3 clarifies the radial tour methodology, specifically the use of Rodrigues rotation formula (Rodrigues 1840) to solve the rotation matrix with the definition for 1 and 2D tours. This sets up a scaffolding to extend the manual tour to three dimensions with another rotation angle to span the manipulation space. This work also supports manual tours by illustrating use cases on several high-energy physics data sets. Chapter 4, defines a task and accuracy measure for a variable attribution of the separation of two clusters. The \\(n=108\\) crowdsourced user study compares the performance from PCA, the grand tour, and the radial tour. This is measured across three experimental factors of the data simulation. Mixed model regression finds considerable evidence for a sizable improvement in accuracy from the radial tour, which participants also subjectively prefer. Chapter 5 covers cheem analysis. This extends the interpretability of nonlinear models by exploring local explanation with the radial tour. The global view gives a full observation summary of data space, attribution space, and residual plot side-by-side as an coordinated view. From this, an analyst identifies a primary observation to explore the explanation in detail. The normalized attribution this point becomes the starting basis for a radial tour. By vary the contributions of variables, an analyst tests the contributions sensitivity to the predictive power identified in the explanation. We provide usage and discussion from four contemporary datasets. 6.1.2 Software The R package spinifex facilitates the creation of manual tours, which allow an analyst control over the contributions of a variable. It handles data transformations and the identification of various starting bases. It creates a framework for the layered display of tours interoperable with the tourr package. Building the geometric display will feel at home to ggplot2 users. After composition, tours can be animated and exported as interactive html widgets or fixed animations as gif, or mp4 files. Vignettes and an interactive application help users rapidly understand the concepts of facilitated work. The impact of spinifex can be seen in two ways. My contributions to spinifex and tourr won the ACEMS Impact and Engagement Award, 2018. Furthermore, the package is available on CRAN with vignettes and version notes on its pkgdown site. It has been downloaded over 14,400 times from CRAN between 09 April 2019 and 28 November 2021. The cheem package facilitates the tree SHAP local explanations from tree-based models. Given a compatible model, functions perform the preprocessing to calculate the local explain of all observations with several statics that help describe the separability of data and attribution space. This processed object then feeds two novel visuals. The global view helps analysts interactively identify an observation to look at in more detail. A custom display of the radial tour then helps to evaluate the sensitivity of the variable contributions to the structure identified in the explanation. An interactive graphical user interface uses these visuals to facilitate the outlined cheem analysis. Several preprocess datasets are included and also allows analysts to upload their data after processing. This package was recently uploaded to CRAN and has a corresponding pkgdown site. 6.2 Limitations Below, we discuss a number of limitations with this work in chapter order. The following section echos this order and discusses possible directions to address these limitations. Manual tours (and radial tours) are limited in several ways. For instance, the work currently lists rotation matrices for 1- and 2D manual tours. Another limitation is that they only change one variable at a time. This can be cumbersome and timely if many variables need to be zeroed or otherwise changed. The radial tour moves in three segments (full contribution-no contribution-initial contribution). It may be more approachable to directly relate the fraction of the slider to the magnitude of the variables contribution. Setting aside the manual tour, there are several extensions to the layered composition of tours in spinifex, such as extending the type of geometric display. Because the manual tour is currently defined for \\(d \\in [1,2]\\) projections, the geometric display for \\(d&gt;2\\) tourr-made tours are under-supported. Most tour implementations are made with 2D monitors in mind. It would be nice to have implementations for extended reality with a stereoscopic head-mounted display. The user study evaluating the radial tour has several intrinsic limitations. It only considered discrete 2d PCA, grand tour, and the manual tour for supervised cluster separation for various levels of experimental factors affecting the data. The cheem analysis was illustrated on random forest models using the tree SHAP explanations. The cheem package handles several other tree-based models, though the analysis should be generalized to a wider base of models and compatible explanations. We also focus on quantitative matrices. This could be generalized to accommodate text, image, or time-series data. There is also no comparison evaluating the value of cheem analysis. It would be interesting to measure the benefit of cheem over local explanations or other observation-level evaluations of a model. 6.3 Future work This section purposes possible directions to address or extend from the limitations outlined above. Chapter 3 included the scaffolding to extend manual tours beyond 2D. Namely, this would require the use Rodrigues rotation formula (Rodrigues 1840) to defining another angle of rotation. The 3D projection would initialize a 4D manipulation space and use three input angles to control the contribution in the first three components. Another display dimension may benefit the detection and understanding of the higher dimensional structure, while we would also expect longer interaction time and less intuitive input. In addition to the manual tour controlling the contribution of a single variable, it may be insightful to change the contributions of several variables at once (effectively manipulating a linear combination of variables). This may increase manipulation speed or prove to be unintuitive to input. Alternatively, an automated approach may help clean up variables with small contributions. A sort of dimension reduction tour, could append several manual tours that sequentially zero the contributions of variables contributing less than some threshold, which may prove to expedite analysis, especially for approaching a features intrinsic dimensionality. This approach may be better as an initialization step before render time. This would abstract away some of the business and monotony of dealing with many variables allowing an analyst to focus on variables tangibly impacting projection. Currently, the radial tour creates three segments (increase-decrease-increase of magnitude). An ink tank display for a manual tour may be more intuitive than the current approach. For this, the magnitude of variable contribution would match the progress of an animation slider. The first frame would contain zero variable contribution, and the last would have a complete contribution. The starting frame could be the original contribution that would also be exaggerated or annotated to refer against. This last point is adjacent to the pedagogical side of tours. The user-steering of the manual tour provides a way to play with projections and test hypotheses making it a good candidate as a learning tool. An interactive application built for learning and exploring projection techniques would be a great introductory tool. Extending the output dimensions of some tours is relatively easy to do. The display in spinifex has focused on \\(d \\in [1, 2]\\). Additional functions could be added to facilitate the geometric display of parallel coordinate, Chernoff faces, glyph-based, or pixel-based visuals. For the reasons mentioned in Chapter 2, these displays are potentially best used with data with relatively few observations and many variables. There are also several extensions to the display of 1 &amp; 2D tours including: tabular displaying the numeric values of the basis, drawing of lines around convex and alpha hulls, and a high-density region displays with progressive density rugs, or a combination of point and density contour display where the bulk of the data is shown as density contour, while the outermost observations are displayed as points (Hyndman 1996; OHara-Wild et al. 2022). It may be interesting to experience tours as 3D scatterplots in extended reality with stereoscopically true head tracking may be fruitful. Nelson, Cook, and Cruz-Neira (1998) explore 2D tours in virtual reality. Other works view 3D scatterplot tours on 2D displays (Yang 1999, 2000). It would be interesting to see modern implementations using WebGL, Mozilla A-frame, or Unity. One concern would be keeping hardware and software as generalized as possible. There are some ways that the user-study evaluating the radial tour could be extended. Besides changing the support of the experimental factors to the user study, it would be more interesting to compare different tasks or other visualization techniques. The performed user study crowdsourced participants with little exposure to linear projections. It would be interesting to compare the results from more experienced participants. The outlined cheem analysis can be generally applied models and local explanations. While the package cheem currently calculates tree SHAP for tree-based models supported by treeshap (Kominsarczyk et al. 2021). This could be generalized more broadly to other models and local explanations. Those facilitated by DALEX::explain() seems to be an excellent direction to extend (Biecek 2018; Biecek and Burzykowski 2021). However, processing runtime is a looming obstacle that is exasperated when moving away from computationally efficient explanations. Alternatively, other statistics may better show the structure identified in the attribution space from the explanations. In the cheem analysis, we had focused primarily on continuous numeric predictors. Perhaps this analysis could be extended to image, text, or time series analysis. The global view may remain helpful in summary and identification while observation-level exploration would likely need to change to fit the context of the data, be it saliency map, word-level contextual sentiment analysis, or other. A user study would help elucidate the benefit of cheem analysis over local explanations or observation-specific analysis of a model. Our analysis can highlight the unique attribution of a selected observation against peers and to test the sensitivity of that attribution. Perhaps a task identifying variable sensitivity to a prediction may be appropriate. "],["A-supplementary-material-for-radial-tour-user-study.html", "A Supplementary material for radial tour user study A.1 Accompanying radial tour application A.2 Extended analysis", " A Supplementary material for radial tour user study A.1 Accompanying radial tour application An accompanying application illustrates the radial tour. The R package, spinifex, (Spyrison and Cook 2020) is an open-source and now contains a shiny (Chang et al. 2021) application allowing users to apply various preprocessing tasks and interactively explore their data via interactive radial tour. Example datasets are provided with the ability to upload data. The html widget produced is a more interactive variant relative to the one used in the user study. Screen captures and more details are provided in the appendix. Run the following R code will run the application locally. ## Download: install.packages(&quot;spinifex&quot;, dependencies = TRUE) ## Run interactive app demonstrating the radial tour: spinifex::run_app() ## Set format and fonts for pdf vs html: if(knitr::is_html_output()){ fmt &lt;- &quot;html&quot; fnt &lt;- 12L mod_comp &lt;- readRDS(&quot;./figures/ch4_tab1_model_comp_ls_html.rds&quot;) ## Escape HTML formatting of * multiplication mod_comp$modelComp_MarksByEval$`Fixed effects` &lt;- gsub(&quot;[*]&quot;, &quot;\\\\\\\\*&quot;, mod_comp$modelComp_MarksByEval$`Fixed effects`) mod_comp$modelComp_TimeByEval$`Fixed effects` &lt;- gsub(&quot;[*]&quot;, &quot;\\\\\\\\*&quot;, mod_comp$modelComp_TimeByEval$`Fixed effects`) }else{ fmt &lt;- &quot;latex&quot; fnt &lt;- 10L mod_comp &lt;- readRDS(&quot;./figures/ch4_tab1_model_comp_ls_latex.rds&quot;) } esc_comp &lt;- FALSE ## Comparisons, with bolding esc_coef &lt;- TRUE ## Coefficients, with % and * Figure A.1: Process data tab, interactively loads or select data, check which variables to project, and optionally scale columns by standard deviation. In the initial tab, Figure A.1, users upload their own (.csv, .rds, or .rda) data or select from predefined data sets. The numeric columns appear as a list of variables to include in the projection. Below that, a line displays whether or not missing rows were removed. Scaling by standard deviation is included by default, as this is a common transformation used to explore linear projections of spaces. Summaries of the raw data and processed numeric data are displayed to illustrate how the data was read and its transformation. Figure A.2: Radial tour tab, interactively create radial tours, changing the manipulation variable, color, or shape of the resulting manual tour. Here, the palmer penguins data is being explored, bill length was selected to manipulate as it is the only variable separating the green cluster from the orange. By mapping shape to island of observation, the green species can be noted to live on all three islands, while the other species live on only one island. The second tab, Figure A.2 contains interaction for selecting the manipulation variable, and non-numeric columns can be used to change the color and shape of the data points in the projection. The radial tour is created in real-time, animated as an interactive plotly html widget. The application offers users a fast, intuitive introduction elucidating what the radial tour does and some of the features offered. A.2 Extended analysis This section covers peripheral and extended analysis. First, the demographics of the participants is covered. Then a parallel modeling analysis on log response time is conducted. Lastly, the effect ranges and marginal effects of the random effect of the participants and data simulation are examined. Survey participant demographics The target population is relatively well-educated people, as linear projections may prove difficult for generalized consumption. Hence Prolific.co participants are restricted to those with an undergraduate degree (58,700 of the 150,400 users at the study time). From this cohort, 108 performed a complete study. Of these participants, 84 submitted the post-study survey, represented in the following heatmap. All participants were compensated for their time at 7.50 per hour, with a mean time of about 16 minutes. Figure A.3 shows a heat map of the demographics for these 84 participants. Figure A.3: Heatmaps of survey participant demographics; counts of age group by completed education as faceted across preferred pronoun. Our sample tended to be between 18 and 35 years of age with an undergraduate or graduate degree. A.2.1 Response time regression As a secondary explanatory variable response time is considered. Response time is first log transformed to remove its right skew. The same modeling procedure is repeated for this response. 1) Compare the performance of a battery of all additive and multiplicative models. Table A.1 shows the higher level performance of these models over increasing model complexity. 2) Select the model with the same effect terms, \\(\\alpha \\cdot \\beta + \\gamma + \\delta\\), and examine its coefficients, displayed in Table A.2. Table A.1: Model performance regressing on log response time [seconds], \\(\\widehat{Y_2}\\) random effect models, where each includes random effect terms for participants and simulations. There is a simplar trade-off where AIC/BIC prefer the simplest factor model, while \\(R^2\\) and RMSE are the largest in the full multiplicative model. The model \\(\\alpha \\cdot \\beta + \\gamma + \\delta\\) model is selected to examine further as it has relatively high marginal \\(R^2\\) while having much less complexity than the complete interaction model. Conditional \\(R^2\\) includes the random effects, while marginal does not. Fixed effects No. levels No. terms AIC BIC R2 cond. R2 marg. RMSE a 1 3 &lt;span style=\" font-weight: bold; \" &gt;1448&lt;/span&gt; &lt;span style=\" font-weight: bold; \" &gt;1475&lt;/span&gt; 0.645 0.007 0.553 a+b+c+d 4 8 1467 1516 0.647 0.017 0.552 a*b+c+d 5 12 1474 1541 0.656 0.024 0.548 a*b*c+d 8 28 1488 1627 0.673 0.054 0.536 a*b*c*d 15 54 1537 1792 &lt;span style=\" font-weight: bold; \" &gt;0.7&lt;/span&gt; &lt;span style=\" font-weight: bold; \" &gt;0.062&lt;/span&gt; &lt;span style=\" font-weight: bold; \" &gt;0.523&lt;/span&gt; Table A.2: Model coefficients for log response time [seconds] \\(\\widehat{Y_2} = \\alpha \\cdot \\beta + \\gamma + \\delta\\), with factor = pca, location = 0/100%, shape = EEE, and dim = 4 held as baselines. Location = 50/50% is the fixed term with the strongest evidence and takes less time. In contrast, the interaction term location = 50/50%:shape = EEV has the most evidence and takes much longer on average. Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 2.71 0.14 42.6 19.06 0.000 *** Factor Factorgrand -0.23 0.12 567.6 -1.97 0.049 Factorradial 0.16 0.12 573.5 1.34 0.181 Fixed effects Location33/66% 0.05 0.14 40.9 0.34 0.737 Location50/50% -0.05 0.14 42.1 -0.35 0.729 ShapeEEV -0.15 0.09 8.3 -1.61 0.145 Shapebanana -0.13 0.09 8.3 -1.42 0.192 Dim6 0.14 0.08 8.3 1.90 0.093 Interactions Factorgrand:Location33/66% 0.24 0.18 580.9 1.34 0.181 Factorradial:Location33/66% -0.24 0.18 582.4 -1.32 0.188 Factorgrand:Location50/50% 0.12 0.18 578.6 0.69 0.491 Factorradial:Location50/50% 0.05 0.18 584.4 0.25 0.800 Random effect ranges The random effect terms further clarify the source of the error. Below is a comparison the effect ranges attributed to the participant and to the simulations next to their marginal effect on the response, a sort of upper bound of the error they could explain. This was performed for the models regressing accuracy and then log response time. The residual plots have no noticeable nonlinear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure A.4 illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at \\(\\alpha = .95\\), while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95% confidence intervals participation and simulation mean accuracy, respectively. Residual plots have no noticeable nonlinear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure A.4 illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at \\(\\alpha = .95\\), while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95% confidence intervals participation and simulation mean accuracy, respectively. Figure A.4: Accuracy model: (T) Estimated effect ranges of the random effect terms participant and data simulation of the accuracy model, \\(\\widehat{Y_1} = \\alpha \\cdot \\beta + \\gamma + \\delta\\). Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about two-thirds of the range of the data without the model. All intervals for \\(\\alpha = .95\\) confidence. Similarly, figure A.5 shows the Gelman simulations and marginal effects of the simulation and participants for the model with the same terms regressing on log response time. Figure A.5: Log response time model: (T) The effect ranges of Gelman resimulation on posterior distributions for the time model, \\(\\widehat{Y_2} = \\alpha \\cdot \\beta + \\gamma + \\delta\\). These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log time by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: \\(e^{1} = 2.7\\), \\(e^{2.75} = 15.6\\), \\(e^{3.75} = 42.5\\) seconds. Of the simulations on the right, the bottom has a large variation in response time, relative to the effect ranges which means that the variation is explained in the terms of the model and not by the simulation itself. "],["B-overall-appendix.html", "B Overall appendix B.1 Glossary B.2 Animated tour links B.3 Supplementary material", " B Overall appendix B.1 Glossary Table B.1: Glossary of terms Term Notation Alias Description observation \\(n\\) instance, item, row (of data) A unit being measured across the variables. variable \\(p\\) feature, column (of data) A measure taken across all observations. data \\(X_{n \\times p}\\) \\(n\\) observations of \\(p\\) variables, a complete quantitative matrix. basis \\(A_{p \\times d}\\) Of linear projections, an othorgonal component mapping of \\(p\\) down to \\(d\\) dimensions. biplot Visual representation of the basis, showing the direction and magnitude the variable contribute inscribed in a unit circle. projection \\(Y_{n \\times d} = X_{n \\times p} \\cdot A_{p \\times d}\\) embedding The resulting space the data multiplied by the basis. tour A dynamic linear projection animated over small changes to the projection basis. Geodesic interpolation Creating intermediate basis frames along the shortest path of possible bases. Intrinsic data dimensionality \\(iid\\) The minimal dimensionality data can be represented with. Nonlinear model black-box model A model with numerous or interactive terms that makes the term difficult to interpret. Local explanation Approximation of the linear variable importance of a model in the vicinity of one observation. B.2 Animated tour links Table B.2: Animated tour links Reference Description Link Figure 1.2 radial tour, penguins vimeo.com/676723431 Figure 2.4 grand tour, penguins vimeo.com/676723441 Figure 5.4 cheem, penguins vimeo.com/666431172 Figure 5.6 cheem, chocolates vimeo.com/666431143 Figure 5.7 cheem, chocolates (inverse) vimeo.com/666431148 Figure 5.8 cheem, fifa vimeo.com/666431163 Figure 5.9 cheem, ames housing 2018 vimeo.com/666431134 B.3 Supplementary material Table B.3: Supplementary material Context Description Link spinifex vignette, Getting started with spinifex nspyrison.github.io/spinifex/articles/getting-started-with-spinifex.html spinifex vignette, Ggproto api nspyrison.github.io/spinifex/articles/ggproto-api.html cheem vignette, Getting started with cheem nspyrison.github.io/cheem/articles/getting-started-with-cheem.html thesis repository github.com/nspyrison/thesis_ns thesis thesis, pdf format github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf thesis thesis, html format https://nspyrison.github.io/thesis_ns/ "],["bibliography.html", "Bibliography", " Bibliography "]]
