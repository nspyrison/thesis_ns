[["index.html", "Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models Welcome", " Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models Nicholas S Spyrison Welcome This book covers is the PhD thesis during my studies at Monash University, Australia. A pdf version can be found here and the code repository can be found on github. 2022-02-04 "],["abstract.html", "Abstract Publications and papers during candidature not part of this thesis", " Abstract Visualizing data space is a crucial aspect of exploratory data analysis, checking assumptions, and validating model performance. However, visualization quickly becomes complex as the dimensionality of the data or features increases. Traditionally, linear projections have viewed discrete pairs of components to mitigate this complexity. Data visualization tours are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis. The permanence of observations between nearby frames potentially conveys more information than discrete orthogonal frames alone. Tours are categorized by the path of their bases. Manual tours uniquely allow for user-controlled steering of a path of bases, where the contributions of individual variables can be changed. The radial tour is a specific case of the manual tour, that freezes the angle of movement but allows the magnitude to be varied. This is used in the work reported here. Chapter 3 defines and clarifies the theoretical basis of the radial tour. The details of implementation and illustration of its use are provided. It introduces an open-source R package, that facilitates creating these tours with a variety of display choices and user controls. Allowing the analyst to steer a path in the radial tour should enable a better understanding of the variable importance to any structure revealed in a projection. Chapter 4 discusses a within-participant user study comparing the radial tour with current practices: principal component analysis (PCA) and the original type of tour that has no steering. The \\(n=108\\) crowdsourced participants performed a variable attribution task describing the separation between clusters. The results find that the radial tour lead to more accurate variable attribution. Participants also reported that the radial tour was their preferred visualization method. Non-linear modeling techniques are sometimes referred to as black-box models due to the uninterpretable nature of model terms. Recent research in Explainable Artificial Intelligence (XAI) tries to bring these models interpretability through local explanations. Local explanations are a class of techniques that approximate the linear-variable importance for prediction at one point in the data. Chapter 5 provides a new approach for exploring the variable sensitivity of local explanations using radial tour. Local explanations can be considered projection bases. The radial tour is used to vary the contribution of an feature to assess the importance that feature for any particular prediction. This is illustrated using four contemporary data examples covering classification and regression. An accompanying R package provides a graphical user interface (GUI) for conducting this analysis. I have renumbered and updated sections of the published paper to generate a consistent presentation within the thesis. The code illustrated has been adjusted to highlight the new ggproto API. Introductory, background, and conclusion content has been moved to their respective thesis chapters. Publications and papers during candidature not part of this thesis In addition to the research discussed in the thesis, other notable contributions during my candidature include: The state-of-the-art on tours for dynamic visualization of high-dimensional data (Lee et al. 2021). A WIREs Computational Statistics Review of current tour methods. I contributed writing and visuals discussing manual tours. Is IEEE VIS that good? On key factors in the initial assessment of manuscript and venue quality (Spyrison, Lee, and Besan√ßon 2021). A survey IEEE VIS authors, how they source articles, decide which to read, and evaluate venue quality. We find low evidence that sentiment changes across academic positions for these topics and provide commentary and discussion on the effects of publish or perish environment, standard author and journal metrics, and the need to publish null findings and replication studies. Intraday effect of COVID-19 restrictions on Melbourne electricity consumption (Barrow, Chong, and Spyrison 2020). We corroborate that the Victorian interday effect on energy consumption did not change and novelly find that the intraday distribution of energy consumption does change. Namely, we find a statistically significant change in the height of the morning and evening peak, energy consumption that we posit is due to less strict schedules associated with working from home, absence of commute time, and other employment changes. We were awarded 1st place of hundreds of entries in the insights category of the Melbourne 2020 Datathon. Nicholas Spyrison 2021-12-12 &gt; "],["acknowledgments.html", "Acknowledgments", " Acknowledgments I would like to express my sincere gratitude to my supervisors, Professor Dianne Cook and Professor Kimbal Marriott, for their support of my Ph.D studies and research, their subject expertise, and their careers of supervising and teaching in addition to performing research. Thank you for continuously pushing me and my research to new levels. I have enjoyed teaching data visualization, which has been strongly shaped by Dis practical, data-first, visualization-often pragmatic approach. I will continue to hear Kims persistent question, what do we learn from this? as a reminder not to get lost in the details of implementation and regularly step back and analyze if this is the correct object to change. A special thanks to Professor Przemyslaw Biecek for giving his input in the formulation stages of my project and his easy-to-understand explanations of complex modeling aspects. Thank you for responding to cold emails and being available for collaboration. Thank you to Jieyang Chong and Julie Holden for their help proofreading and tightening up my writing. I thank my fellow Ph.D students, lab members, and Pomodoro partners, primarily on the occasional stimulating discussions and the positive peer pressure of knowing others are around and working. Thanks immensely to those who empathized with me and others, especially through the hardships of studies and COVID-19. Gratitude to Ying Zhou for her enduring support through the thick of my studies and wavering mental health. Last but not least, I would like to thank my parents, Doug and Terry, for their support and concerns at odd hours of the day. Thanks to Alan and Claire for their companionship and support now and in our more formative years. I am looking forward to seeing you all in person shortly. "],["preface.html", "Preface", " Preface This thesis has been written using R Markdown with the bookdown package (Xie 2016). All materials required to compile the thesis are available at github.com/nspyrison/thesis_monash_phd. Versions are made available as .html and .pdf at nspyrison.github.io/thesis_ns/ and github.com/nspyrison/thesis_ns/blob/master/docs/thesis_ns.pdf, respectively. I recognize that terminology is often overburdened by ambiguous use, with several changing meanings coming from different fields. My educational background comes from Statistics, and I will default to terms from statistics and geometry. "],["1-ch-introduction.html", "Chapter 1 Introduction 1.1 Research questions 1.2 Methodology 1.3 Contributions 1.4 Thesis structure", " Chapter 1 Introduction Exploratory Data Analysis (EDA) is the process of the initial summarization and visualization of a dataset. This is a critical first step of checking for realistic values, finding improper data formats, and revealing insights (Tukey 1977). Early and frequent data visualization is key to the data analysts workflow (Hadlet Wickham and Grolemund 2017) illustrated in Figure 1.1. The analyst cleans and tidies the data then intertwines visualization with model fitting, repeating this until the analyst is happy with the result. (ref:ch1fig1-cap) Data analysis workflow (Hadlet Wickham and Grolemund 2017). This work focuses primarily on visualization of multivariate data. Figure 1.1: (ref:ch1fig1-cap) As modern datasets have grown in complexity, multivariate data has become ubiquitous. Multivariate data is found in physics, biology, social sciences, and manufacturing (Wang et al. 2018; Huber et al. 2015; Brown 2015; Evans and Boreland 2017). As the number of variables in the data increases, however, it becomes increasingly difficult to visualize the relationships between the variables and discern the structure of the data set. This thesis addresses the visualization of multivariate data and the analysis of multivariate data using the above iterated workflow. One of the most common and successful approaches to visualize multivariate data is to project multiple dimensions of the data onto two dimensions and then display the projected data. In the same way that 3D object casts a 2D shadow, these projections cast a profile orientation of the data onto a 2D plane. Our starting point are linear projections. These use a linear combination of variables, called a basis, to define each dimension of the projected space. Each dimension combines multiple variables. This is in contrast to looking at say, each pair of variables in isolation. The basis of linear projections is frequently illustrated with a biplot (Gabriel 1971). The biplot shows the magnitude and angle each variable contributes to the resulting display dimensions inscribed in a unit circle such as in Figure 1.2. (ref:ch1fig2-cap) Palmer Penguin data (Gorman, Williams, and Fraser 2014; Horst, Hill, and Gorman 2020), three species of penguins were measured across four physical variables: bill length (b_l), bill depth (b_d), flipper length (f_l), and body mass (b_m). These are two projections of the 4D variable space with biplot display of the basis orientation. The separation of the species clusters is the feature of interest. Some orientations of the data do not identify cluster separation (left) while others do (right). Figure 1.2: (ref:ch1fig2-cap) There are many features that an analyst may be interested in when analyzing multivariate data. Shape and spread, identifying clusters, outliers, and irregularity are some of the most common. While linear projections can show these features, not all projections will reveal the feature. Thus the choice of projection is important. Furthermore, the analyst is interested in understanding how the variables contribute to revealing the feature. For instance, Figure 1.2 shows two linear projections of penguin data. The color and shape of the data points distinguish the three penguin species. The linear projection used in the left frame does not distinguish the three species while that used in the right frame shows a significant separation. It therefore makes sense for an analyst to explore different linear projections. However, it can be difficult to understand the affect of the projection and to keep track of data points if the analyst is shown several projections with no relationship to one another. The tour is a dynamic visualization that overcomes this difficulty (Cook et al. 2008; Lee et al. 2021). It is a class of linear projections that animate small changes to the projection basis. A key feature of the tour is the visual permanence and trackability of the points through the frames. In the shadow analogy, an object such as a barstool will cast a circular shadow if the light is directly above the seat. However, such a shadow does not give the observer sufficient information as it could arise from any number of shapes that contain profiles of spheres, cylinders, or circles. However, if the stool was rotated, its legs would show in the shadow quickly giving an intuitive interpretation of the object. Similarly, the rotation of a data object yields information about its structure. A crucial component for human-in-the-loop analysis (Karwowski 2006) is the ability for the analyst to manually steer the tour. This allows, for example, the analyst to explore what happens to the structure when one variable is removed or the contribution of another is increased. Cook and Buja (1997) introduced the manual tour, offering user control over the basis. By selecting a variable and initializing an additional manipulation dimension to an embedding, the contribution of the variable can be controlled. The manual tour allowed the analyst to control both the angle and magnitude that a variable contributes to the projection. However, controlling the magnitude is generally more meaningful as angular manipulations effectively rotate the projection, changing the relative position, but not the contribution of a variable. Because of this, this work focuses on a specific manual tour, the radial tour, where the angle of the manipulated variable is fixed, but the analyst can vary its magnitude, changing its radius. Figure 1.3 shows a radial tour on the penguins data varying the contribution of bill length. In frames 1 and 2 there is a large contribution from bill length, and all species are distinguished. In frame 3, however, bill length is removed, and the separation between orange and green clusters has collapsed; we say this variable is sensitive to the separation of these two clusters. (ref:ch1fig3-cap) Frames of a radial, manual tour of Palmer Penguin data manipulating the contribution of bill length (b_l). When bill length has a considerable contribution to the frame, the clusters of orange and green species are separated (frames 1 and 2). When its contribution is removed, the clusters overlap (frame 3). Because of this, bill length is sensitive to the separation of these two species. An animated version can viewed at vimeo.com/670936513. Figure 1.3: (ref:ch1fig3-cap) 1.1 Research questions Discerning variable sensitivity to the structure is a crucial step in understanding a variables contribution to features or differences of interest to the analyst. We conjecture that the user interaction afforded by the radial tour should allow for a more precise exploration of this structure by testing the variable sensitivity to that structure. The over-arching question of interest can, therefore, be stated as: Can the radial tour, with user control of the basis, help analysts understand the variable sensitivity of structure in the projection? While Cook and Buja (1997) sketched the theoretical basis for the manual (and hence radial) tour, some details are missing. Furthermore, we lack a publicly available implementation, fully featured interface design, implementation notes, and have no evaluation of its performance over alternatives. RQ 1. How do we define and implement a user interface and interactions for the radial tours to add and remove variables smoothly from a 2D linear projection of data? At present the radial tour is not used by analysts. Instead they would use a single projection to understand the structure, almost always the principal components analysis (PCA) which chooses the basis that shows the most variation. Another approach is to use a grand tour. This randomly selects target bases and then generates an animation that interpolates between these target bases. Neither PCA nor the grand tour provide a means for manually manipulating a desired variables contribution to the basis. We wish to investigate if the ability for the analyst to steer the basis in the radial tour facilitates better understand variable sensitivity to the structure. RQ 2. Does the use of the interactive radial tour improve analysts understanding of the relationship between variables and structure in 2D linear projections compared to existing approaches? Complex non-linear models are also being applied more frequently to predict or classify from many predictors. While these models lead to increased accuracy over linear models, they suffer from a loss of the interpretability of their variables. One aspect of eXplainable Artificial Intelligence (XAI, Adadi and Berrada 2018; Arrieta et al. 2020) tries to preserve the interpretability of such models through local explanations. These explanations are essentially linear variable importance in the vicinity of one observation of a model. That is, the extent that variables help the model explain the difference between the observed means and this observations prediction. The user control from the radial tour potentially allows an analyst to understand better the model and the support of these local explanations. RQ 3. Can the radial tours be used in conjunction with local explanations to improve the interpretability of black-box models? 1.2 Methodology The research corresponding with RQ 1 entails algorithm &amp; software design (Kleinberg and Tardos 2006) adapting the algorithm from Cook and Buja (1997). To address RQ 2, we use experimental design (Winer 1962). We must define a task and measure suitable to evaluate the radial tour against alternatives. The experimental factors and their levels must be selected and randomly assigned to explore the efficacy of user-controlled radial tours compared with two benchmark methods. The research responding to RQ 3 involves design science (Hevner et al. 2004). It is not obvious how to combine a radial tour with a non-linear model. A local explanation approximates the linear variable importance in the vicinity of one observation. We must develop a novel interactive visualization that accommodate two aspects. First, it should visually facilitate the selection of observations to explore. Secondly, extend the biplot to show the distribution of the local explanations and examine the variable sensitivity to the structure identified in local explanation with the radial tour. 1.3 Contributions The contributions resulting from the research to address these research questions can be split into scientific knowledge and software contributions: 1.3.1 Scientific knowledge Manual tour theory Use of the Rodrigues rotation formula to derive the rotation matrix; this was absent from the original paper and points to the means to extend the manual tour in a 3D embedding Use cases for the manual tour giving support to its application A user study comparing the radial tours efficacy against two alternativesPCA and the grand tour, the first empirical evaluation of the radial tour Creation of supervised classification task to assess the variable attribution to the separation of two cluster As tested over experimental factors: location, shape, and dimensionality Definition of an accuracy measure to evaluate this task Results: strong evidence that the radial tour increases the accuracy of this task by a sizable amount and minor evidence to suggest a moderate increase in accuracy of the grand tour over Principal Component Analysis (PCA) Mixed model regression helps to attribution the source of the error accounting for the variability of participants skill and the difficulty from random simulation Cheem analysis, a novel method exploring the variable sensitivity of local explanations from non-linear models A global view approximates the variable space, attribution space, and model information side-by-side serves to identify a primary observation of interest This observations normalized variable attribution is used as a projection basis Explore the support of the local explanation; using the radial tour, the variable sensitivity to the structure identified test the support of the explanation 1.3.2 Software spinifex, an R package for transforming data, performing radial tours, and the layered composition of any tours Transform of numeric variable in the data Extract various bases exposing features of the data Manual tours allow analyst steering of the basis to explore the variable sensitivity to structure Layered composition of tour displays that mirrors the approach in ggplot2 (Hadley Wickham 2016), Interoperable with tours made from tourr (Hadley Wickham et al. 2011) Interactive application to preprocess data and explore. Users can choose from six supplied datasets or upload their own Vignettes and code examples help users get up to speed Introduces an interactive application to preprocess data and explore. Users can choose from six supplied datasets or upload their own cheem, an R package that facilitates the exploration of local explanations of non-linear models: Preprocessing; given a tree-based model, calculate the tree SHAP local explanation of all observations, and find statistics to accent the separability of this space Visualization of approximations of the data space, attribution space, and model residual information side-by-side with linked brushing, hover tooltips, and tabular display facilitates the selection of observations to explore Use of the radial tour varies the contribution of variable test the support of the variable contribution in agreement with the explanation Interactive application facilitates this analysis for several prepared datasets or user preprocessed data A vignette and code examples help users get up to speed 1.4 Thesis structure The remainder of the thesis is organized as follows: Chapter 2 covers various visualizing techniques before introducing related studies and then non-linear models and their interpretability issues. Chapter 3 discusses the theory and implementation of the manual tour in the package spinifex. Chapter 4 discusses a user study evaluating the radial, manual tours efficacy compared with PCA and the grand tour. Chapter 5 extends the use of radial tours to improve the interpretability of non-linear models. Lastly, Chapter 6 concludes with some takeaways and a discussion of possible extensions. "],["2-ch-background.html", "Chapter 2 Background 2.1 Scatterplot matrices 2.2 Parallel coordinate plots 2.3 Dimension reduction 2.4 Tours, animated linear projections 2.5 Evaluating multivariate data visualization 2.6 Non-linear models 2.7 Local explanations", " Chapter 2 Background This chapter first motivates data visualization in general and the importance of interaction. Then we cover orthogonal and observation-based visuals before turning to dimension reduction, including a further discussion of tours. Then we turn to empirical evaluations of multivariate visuals. Lastly, it concludes with non-linear models and extending their interpretation with local explanations. Visualization is much more robust than numerical summarization alone (Anscombe 1973; Matejka and Fitzmaurice 2017). Several datasets have the same summary statistics in these studies yet contain obvious visual shapes that could go utterly unheeded if plotting is foregone. Figure 2.1 illustrates this, where data is allowed to drift toward different patterns provided that the mean and standard deviations stay within some tolerance of the original data. (ref:ch2fig1-cap) Starting from the profile of a dinosaur, observations are allowed to drift (by iterated simulated annealing) toward 12 patterns provided that they stay close to the original statistics (Matejka and Fitzmaurice 2017). Visualization of data yields stark designs that are easy to miss in numerical summarization. Figure 2.1: (ref:ch2fig1-cap) Interaction is known to be an essential aspect of modern data visualization (Batch et al. 2019; Card, Moran, and Newell 2018; Marriott et al. 2018). Specific interactions are closely linked to the visual method, display dimensionality, the hardware used. Linked brushing (Becker and Cleveland 1987) has proved to be helpful in tours (Arms, Cook, and Cruz-Neira 1999; Laa, Cook, and Valencia 2020; Lee, Laa, and Cook 2020) and ensemble graphics. Tooltip display of observation identification and displaying associated values. The novel user-steering of the projection basis in the radial tour is the primary feature of interest to discern in the user study conducted in Chapter 4. Before jumping into visualization, we cover the context of the data in mind. Consider the case where data is a complete numeric matrix \\(X_{nxp}\\) containing \\(n\\) observations of \\(p\\) variables. Ideally, values are continuous numeric (not ordinal levels) and \\(n&gt;p\\) with many more observations than variables. While written as though always operating on the original variables, the visualization discussed could similarly be applied to component spaces or feature decomposition of data not fitting this format. The work in Grinstein, Trutschl, and Cvek (2002) gives a good taxonomy of high-dimensional visualization. Below covers a guided discussion while we generally consider the question, How can an analyst visualize arbitrary \\(p-\\)dimensions? We continue to use the Palmer penguins data in illustrations. This data contains 333 observations of 3 penguin species across four physical measurements: bill length, bill depth, flipper length, and body mass. Observations were collected between 2007 and 2009 near Palmer Station, Antarctica. 2.1 Scatterplot matrices Viewing as many univariate histograms or density curves is one method. Similarly, one could look at all variable pairing as scatter plots. This forms the crux of the scatterplot matrices, also known as SPLOM (Chambers et al. 1983). In a scatterplot matrix, variables are displayed across the columns and rows. The diagonal elements show univariate densities, while off-diagonal positions show scatterplot pairs, as Figure 2.2. This is useful for getting a handle on the support of the variables but is not going to scale well with dimension and is not a suitable audience-ready display. It is hectic and doesnt draw attention to any one spot. Munzner (2014) reminds us to abstract the cognitive work out of the visual, allowing the audience to focus on the evidence supporting the claim. (ref:penguinsplom-cap) Scatterplot matrix of penguins data. This is a good exploratory step but does not direct the audiences attention and will not scale well as \\(p\\) increases. Figure 2.2: (ref:penguinsplom-cap) 2.2 Parallel coordinate plots Alternatively, we could consider a class of observation-based visuals. In parallel coordinate plots (Ocagne 1885), variables are arranged horizontally, and lines connect observations after being transformed to a common scale quantile or z-value (standard deviations away from the mean). Figure 2.3 illustrates this method. This scales much better with dimensions but poorly with observations. It also suffers from an asymmetry with the variable order. That is, changing the order of the variable will lead people to very different conclusions. The x-axis is also used to display variables rather than the values of the observations. This restricts the amount of information that can be interpreted between variables. Munzner asserts that position is the more human-perceptible channel for encoding information; we should prefer to reserve it for the values of the observations. The same issues persist across other observation-based displays such as radial variants, pixel-based visuals, and Chernoff faces (Keim 2000; Chernoff 1973). These visuals are better suited for the \\(n&lt;p\\) case with more variables than observations. (ref:penguinpcp-cap) Parallel coordinate plots of penguins data. This does not scale well with observations, suffers from asymmetry with the variable ordering, and horizontal position is used for distinguishing between variables rather than values within the variable. Figure 2.3: (ref:penguinpcp-cap) However, in the \\(n&lt;p\\) case, these visuals will perform better with fewer observations than variables. Alternatively, as \\(n\\) increases, scatterplots displays suffer from dense points occluding each other. This is typically addressed in a few ways. One method would decrease points opacity, allowing more layers to be seen. Less interestingly, visualizing a representative subset of the data is another option. Another would change the geometric display to an aggregated heatmap or 2D density contours. These aggregations typically render faster and scale better with increasing observations. 2.3 Dimension reduction Ultimately, we will need to turn to dimension reduction to create a compelling visual allowing audiences to focus on features with contributions from multiple variables. Dimension reduction is separated into two categories, linear and non-linear. The linear case spans all affine mathematical transformations, essentially mappings where parallel lines stay parallel. Non-linear transformations complement the linear case, think transformations containing exponents or interacting terms. Examples in low dimensions are relatable. For instance, shadows are an example of linear projections where a 3-dimensional object casts a 2D projection, the shadow. Our vision (at any one instance) and pictures are similarly 2D projections. An example of a non-linear transformation is that of 2D maps of the globe. There are many different methods to distort the surface to display as a map. The most common may be rectangular displays where the area is proportionally distorted with the distance away from the equator. Other distortions are created when the surface is unwrapped into a long ellipse. Yet others create non-continuous gaps in oceans to minimize the distortion of countries. Non-linear techniques often have hyperparameters that affect how the spaces are distorted to fit into fewer dimensions. Various computational quality metrics, such as Trustworthiness, Continuity, Normalized stress, and Average local error, describe the distortion of the space (Espadoto et al. 2021; Gracia et al. 2016; Maaten, Postma, and Van den Herik 2009; Venna and Kaski 2006) To quote Anastasios Panagiotelis, All non-linear projections are wrong, but some are useful, a play on George Boxs quote about models. The distortions are hard to interpret and, thus hard to communicate. Moreover, they can introduce features not in the data depending on the selection of hyperparameters. Then plausibly, the presence of structure in a non-linear model is necessary but not sufficient to conclude the existence of a structure in the data. Unfortunately, there is no free lunch here. An increase in the original data dimensions will lead to a \\(p-d\\)-dimensional viewing space in the linear case or an increasingly perturbed and distorted space in non-linear techniques. Neither is a panacea for visualizing multivariate spaces. However, we will continue with only linear projections due to the opaque distortions of non-linear methods. The intrinsic dimensionality of data is the number of variables needed to minimally represent the data (Grinstein, Trutschl, and Cvek 2002). Intrinsic data dimensionality is an essential aspect of dimension reduction that does not have to end in visual but is also a standard part of factor analysis and preprocessing data. Consider a Psychology survey consisting of 100 questions about the Big Five personality traits. The data consists of 100 response variables, while the theory would suggest the intrinsic dimensionality is five. However, Its likely that these personalities do not fully span the five dimensions. Regardless, reducing the disparity of these volumes would be necessary to gate the exponentially increasing space to view. One example of linear projections is that of principal component analysis (PCA, Pearson 1901), which creates a component space ordered by descending variation. It uses eigenvalue decomposition to identify the basis reorientation. These components are typically viewed as discrete orthogonal pairs, commonly approximated in fewer components than the original dimensionality. This is commonly used in preprocessing and model initialization step when there are many more variables than the intrinsic data dimensionality, such as the Big Five personality example. These reduced spaces can be interpreted as the original variables, albeit with the added abstraction of another linear mapping. 2.4 Tours, animated linear projections In one static linear projection let, \\(Y_{nxd} = X_{nxp} \\cdot A_{pxd}\\) be the embedding of the data mapped by the basis \\(A\\), where \\(d&lt;p\\). In contrast to one such projection, a data visualization tour animates many such projections through small changes in the basis. In the shadow analogy, structural features of an object are gained by watching its shadow change due to its rotation. An analyst similarly gains information about the data object by watching continuous changes to the basis (the orientation of the data). There are various types of tours that are classified by the generation of their basis paths. We enumerate a few related to this work. A more comprehensive discussion and review of tours can be found in the works of Cook et al. (2008) and Lee et al. (2021). Originally in a grand tour (Asimov 1985), several target frames are randomly selected. Figure 2.4 illustrates six frames from a grand tour. The grand tour is good for EDA in that it will show frames with widely varying contributions but lacks a destination, objective function, or means of steering. (ref:ch2fig4-cap) Frames from a grand tour of Palmer Penguin data. Tours animate linear projections over small changes in the basis. The observation permanence between frames is an essential distinction in tours. Target frames are selected randomly in the grand tour. An animation can be viewed at vimeo.com/670936494. Figure 2.4: (ref:ch2fig4-cap) (ref:ch2fig5-cap) Illustration of geodesic interpolation between a randomly generated manual tour target frames (grey) and the resulting intermediate frames (white). Figure from Buja et al. (2005). Figure 2.5: (ref:ch2fig5-cap) Regardless of the type of tour target basis identified, tours must interpolate frames between distant randomly generated target bases. Figure 2.5 illustrates the geodesic interpolation between distant target frames. Animating through small distances between these interpolated frames is important for the trackability of observations. 2.5 Evaluating multivariate data visualization We have discussed several different multivariate visualizations. Yet, the analyst must determine which method to use. Chapter 4, conducts a user study comparing competing visualizations to inform this selection. Gracia et al. (2016) conducted an \\(n=40\\) user study comparing between 2D and 3D scatterplots on traditional 2D monitors. Participants perform point classification, distance perception, and outlier identification tasks. The results are mixed and mostly small differences. There is some evidence to suggest a lower error in distance perception from 3D scatterplot. Wagner Filho et al. (2018) performed an \\(n=30\\) within participants using scatterplot display between 2D, 3D displays on monitors and 3D display with a head-mounted display on PCA reduced spaces. None of the tasks on any dataset lead to a significant difference im accuracy. However, the immersive display reduced effort and navigation while resulting in higher perceived accuracy and engagement. Sedlmair, Munzner, and Tory (2013) instead uses two expert coders to evaluate 75 datasets and four dimension reduction techniques for 2D scatterplots, interactive 3D scatterplots, and 2D scatterplot matrices. They suggest a tiered guidance approach finding that 2D scatterplots are often good enough. If not, try 2D scatterplots on a different dimension reduction technique before going to scatterplot matrix display or concluding a true negative. They find that interactive 3D scatterplots help in very few cases. Empirical studies scarcely compare tours. However, Nelson, Cook, and Cruz-Neira (1998) compare scatterplots of grand tours on 2D monitor with 3D (stereoscopic, not head-mounted) over \\(n=15\\) participants. Participants perform clusters detection, dimensionality and radial sparseness tasks on six dimensional data. They find that stereoscopic 3D leads to more accuracy in the cluster identification, though interaction time was much increased in the in 3D case. In chapter Chapter 4, we extend the evaluation of tours which novelly compares the radial tour as benchmarked against the grand tour and discrete pairs of principal components. 2.6 Non-linear models In Chapter 5, we turn our attention to predictive modeling, the loss of variable-level interpretability of the non-linear models, and a method to maintain model transparency, local explanations. There are different reasons and emphases to fit a model. Breiman (2001), reiterated by Shmueli (2010), taxonomize modeling based on its purpose; explanatory modeling is done for some inferential purpose, while predictive modeling focuses more narrowly on the performance of some objective function. The intended use has important implications for model selection and development. In explanatory modeling, interpretability is vital for drawing inferential conclusions. While the use of black-box models is almost exclusively used in predictive modeling. However, the prevalence of non-linear models is not without controversy (ONeil 2016; Kodiyan 2019), and the loss of interpretation presents a challenge. Interpretability is vital for exploring and protecting against potential biases (e.g., sex  Dastin (2018); Duffy (2019), race  Larson et al. (2016), and age  D√≠az et al. (2018)) in any model. For instance, models regularly pick up on biases in the training data that have observed influence on the response (output) feature, which is then built into the model. Variable-level (feature-level) interpretability of models is essential in evaluating such biases. Another concern is data drift, where a shift in support or domain of the explanatory variables (features or predictors). Non-linear models are typically more sensitive and do not extrapolate well outside the support of the training data. Maintaining variable interpretability is similarly essential to address issues arising from data drift. 2.7 Local explanations Explainable Artificial Intelligence (XAI) is an emerging field of research that tries to increase the interpretability of black-box models. A common approach is to use local explanations, which attempt to approximate linear variable importance at the location of each observation (instance). That is a prediction at a specific point in the data domain. Because these are point-specific, the challenge is to visualize them to understand a model comprehensively. Consider a highly non-linear model. It can be hard to determine whether small changes in a variables value will make a class prediction change group or identify which variables contribute to an extreme residual. Local explanations shed light on these situations by approximating linear variables importance in the vicinity of a single observation. Figure 2.6 motivates local explanations where the analyst wants to know the variable attribution for a particular observation close to the classification boundary in a non-linear model. (ref:ch2fig6-cap) Illustration of a non-linear classification model. An analyst may want to know the variable importance at the vicinity of the highlighted red cross. Knowing this attribution elucidates how the variable influence this point that is precariously close to the classification boundary. Local explanations approximate this linear attribution in the vicinity of one observation. Figure from Ribeiro, Singh, and Guestrin (2016). Figure 2.6: (ref:ch2fig6-cap) A comprehensive summary of the taxonomy and literature of explanation techniques is provided in Figure 6 of Arrieta et al. (2020). It includes a large number of model-specific explanations such as deepLIFT (Shrikumar et al. 2016; Shrikumar, Greenside, and Kundaje 2017), a popular recursive method for estimating importance in neural networks. There are fewer model-agnostic explanations, of which LIME, (Ribeiro, Singh, and Guestrin 2016) SHAP, (Lundberg and Lee 2017), and their variants are popular. These observation-level explanations are used in various ways depending on the context. In image classification, a saliency map indicate important pixels for the resulting classification (Simonyan, Vedaldi, and Zisserman 2014). For example, snow is regularly highlighted when distinguishing if a picture contains a wolf or husky (Besse et al. 2019). In text analysis, word-level contextual sentiment analysis can be used to highlight the sentiment and magnitude of influential words (Vanni et al. 2018). In the case of numeric regression, they are used to explain variable additive contributions from the observed mean to the observations prediction (Ribeiro, Singh, and Guestrin 2016). "],["3-ch-spinifex.html", "Chapter 3 spinifex: an R package for creating user-controlled animated linear projections 3.1 Algorithm 3.2 Oblique cursor movement 3.3 Package structure 3.4 Use cases 3.5 Discussion", " Chapter 3 spinifex: an R package for creating user-controlled animated linear projections This chapter introduces manual tours that allows analysts to influence the contributions to a projection. This feature is unique from previous linear embeddings and not facilitated by compiling software. Dynamic low-dimensional linear projections of multivariate data known as tour provide an essential tool for exploring multivariate data and models. The R package tourr provides functions for several types of tours: grand, guided, little, local, and frozen. Each of these can be viewed in a development environment, or their basis array can be saved for later consumption. This chapter describes a new package, spinifex, which provides a manual tour of multivariate data. In a manual tour an analyst controls the contribution of a variable to the projection. Controlled manipulation is important to explore a variables sensitivity to structure of an identified feature. The use of the manual tour is applied to particle physics data to illustrate the sensitivity of structure in a projection to specific variable contributions. Additionally, we create a ggproto API for composing any tour that mirrors the layered additive approach of ggplot2. Tours can then be animated and exported to various formats with plotly or gganimate. In the Chapter 2 we introduce linear projections and tours, dynamic linear projections animated over small changes to the basis. The manual tour (Cook et al. 1995) novelly allows an analyst control the contribution of a variable to the basis. On the theoretical side of the contribution we fill in previously absent details to solve at the 3D rotation matrix used in 2D manual tours. This proves a scaffolding for the extension for solving for a 4D rotation matrix that could be used for a 3D manual tour. After that we turn our attention to the package and implementation before illustrating use of the manual tour with meta analysis on high energy particle physics data. The chapter is organized as follows. Section 3.1 describes the algorithm used to perform a radial manual tour implemented in the package spinifex. Section 3.3 discussed the functions. Package functionality and code usage following the order applied in the algorithm follows in section 3.3.1. Section 3.4 illustrates how this can be used for sensitivity analysis applied to multivariate data collected on high-energy physics experiments (Wang et al. 2018). Section 3.5 summarizes this chapter. 3.1 Algorithm The types of manipulations of the manual tour can be thought of in several ways: radial: fix the direction of contribution, and allow the magnitude to change. angular: fix the magnitude, and allow the angle or direction of the contribution to vary. horizontal, vertical: allow rotation only around the horizontal or vertical axis of the current 2D projection. oblique: paths deviating from these movements such as being captured from the movement of a cursor. Angular manipulations are homomorphic, in that they show the same information while rotating the frame. More interesting a change in the magnitude of the contribution, changing the radius along the original angle of contribution. For this reason we implement the radial tour as the default values for the manual tour. Below we describe the manual tour illustrated in detail. After that we also include summaries of the algorithms oblique cursor movements for in the 1D and 2D instances. 3.1.1 Notation The notation used to describe the algorithm for a 2D radial manual tour is as follows: \\(\\textbf{X}\\), the data, an \\(n \\times p\\) numeric matrix to be projected. \\(\\textbf{A}\\), any orthonormal projection basis, \\(p \\times d\\) matrix, describing the projection from \\(\\mathbb{R}^p \\Rightarrow \\mathbb{R}^d\\). \\(k\\), is the index of the manipulation variable or manip var for short. \\(\\textbf{e}\\), a 1D basis vector of length \\(p\\), with 1 in the \\(k\\)-th position and 0 elsewhere. \\(\\textbf{R}\\), the \\(d+1\\)-D rotation matrix, for performing unconstrained 3D rotations within the manip space, \\(\\textbf{M}\\). \\(\\theta\\), the angle of in-projection rotation, for example, on the reference axes; \\(c_\\theta, s_\\theta\\) are its cosine and sine. \\(\\phi\\), the angle of out-of-projection rotation, into the manip space; \\(c_\\phi, s_\\phi\\) are its cosine and sine. The initial value for animation purposes is \\(\\phi_1\\). \\(\\textbf{U}\\), the axis of rotation for out-of-projection rotation orthogonal to \\(\\textbf{e}\\). \\(\\textbf{Y} = \\textbf{X} \\times \\textbf{A}\\), the resulting projection of the data through the manip space, \\(\\textbf{M}\\), and rotation matrix, \\(\\textbf{R}\\). The algorithm operates entirely on projection bases and incorporates the data only when making the projected data plots in light of efficiency. 3.1.2 Steps 3.1.2.1 Step 0) Setup The flea data (Lubischew (1962)), available in the tourr package (Hadley Wickham et al. 2011), is used to illustrate the algorithm. The data contains 74 observations of six variables, physical measurements of flea beetles. Each observation belongs to one of three species. An initial 2D projection basis must be provided. A suggested way to start is to identify an interesting projection using a projection pursuit guided tour. Here the holes index is used to find a 2D projection of the flea data, which shows three separated species groups. Figure 3.1 shows the initial projection of the data. The left panel displays the projection basis (\\(\\textbf{A}\\)) and can be used as a visual guide of the magnitude and direction that each variable contributes to the projection. The right panel shows the projected data, \\(\\textbf{Y}_{[n,~2]} ~=~ \\textbf{X}_{[n,~p]} \\textbf{A}_{[p,~2]}\\). The color and shape of points are mapped to the flea species. Figure 3.1: Biplot of the initial 2D projection: representation of the basis (left) and resulting data projection (right) of standardized flea data. The color and shape of data points are mapped to the species of flea beetle. The basis was produced by a projection pursuit guided tour with the holes index. The contribution of the variables aede2 and tars1 approximately contrasts the other variables. The visible structure in the projection are the three clusters corresponding to the three species. 3.1.2.2 Step 1) Choose manip variable In figure 3.1 the contribution of the variables tars1 and aede2 mostly contrast the contribution of the other four variables. These two variables combined contribute in the direction of the projection where the purple cluster is separated from the other two clusters. The variable aede2 is selected as the manip var, the variable to be controlled in the tour. The question that will be explored is: how important is this variable to the separation of the clusters in this projection? 3.1.2.3 Step 2) Create the 3D manip space Initialize the coordinate basis vector as a zero vector, \\(\\textbf{e}\\), of length \\(p\\), and set the \\(k\\)-th element to 1. In the example data, aede2 is the fifth variable in the data, so \\(k=5\\), set \\(e_5=1\\). Use a Gram-Schmidt process to orthonormalize the coordinate basis vector on the original 2D projection to describe a 3D manip space, \\(\\textbf{M}\\). \\[\\begin{align*} e_k &amp;\\leftarrow 1 \\\\ \\textbf{e}^*_{[p,~1]} &amp;= \\textbf{e} - \\langle \\textbf{e}, \\textbf{A}_1 \\rangle \\textbf{A}_1 - \\langle \\textbf{e}, \\textbf{A}_2 \\rangle \\textbf{A}_2 \\\\ \\textbf{M}_{[p,~3]} &amp;= (\\textbf{A}_1,\\textbf{A}_2,\\textbf{e}^*) \\end{align*}\\] The manip space provides a 3D projection from \\(p\\)-dimensional space, where the coefficient of the manip var can range completely between [0, 1]. This 3D space serves as the medium to rotate the projection basis relative to the selected manipulation variable. Figure 3.2 illustrates this 3D manip space with the manip var highlighted. This representation is produced by calling the view_manip_space() function. This diagram is purely used to help explain the algorithm. Figure 3.2: Illustration of a 3D manip space, the projection plane is shown as a blue circle extending into and out of the display. A manipulation direction is initialized, the red circle, orthogonal to the projection plane. This allows the selected variable, aede2, to change its contribution back to the projection plane. The other variables contributions rotate into this space as well, preserving the orthogonal structure, but are omitted in the manipulation dimension for simplicity. 3.1.2.4 Step 3) Defining a 3D rotation The basis vector corresponding to the manip var (red line in Figure 3.2), can be operated like a lever anchored to the origin. This is the process of the manual control, that rotates the manip variable into and out of the 2D projection (Figure 3.3). As the variable contribution is controlled, the manip space turns, and the projection onto the horizontal projection plane correspondingly changes. This is a manual tour. Generating a sequence of values for the rotation angles produces a path for the rotation of the manip space. For a radial tour, fix \\(\\theta\\), the angle describing rotation within the projection plane, and compute a sequence for \\(\\phi\\), defining movement out of the plane. This will change \\(\\phi\\) from the initial value, \\(\\phi_1\\), the angle between \\(\\textbf{e}\\) and its shadow in \\(\\textbf{A}\\), to a maximum of \\(0\\) (manip var fully in projection), then to a minimum of \\(\\pi/2\\) (manip var out of projection), before returning to \\(\\phi_1\\). Rotations in 3D can be defined by the axes they pivot on. Rotation within the projection, \\(\\theta\\), is rotation around the \\(Z\\)-axis. Out-of-projection rotation, \\(\\phi\\), is the rotation around an axis on the \\(XY\\) plane, \\(\\textbf{U}\\), orthogonal to \\(\\textbf{e}\\). Given these axes, the rotation matrix, \\(\\textbf{R}\\), can be written as follows, using Rodrigues rotation formula (originally published in Rodrigues (1840)): \\[\\begin{align*} \\textbf{R}_{[3,~3]} &amp;= \\textbf{I}_3 + s_\\phi\\*\\textbf{U} + (1-c_\\phi)\\*\\textbf{U}^2 \\\\ &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} + \\begin{bmatrix} 0 &amp; 0 &amp; c_\\theta s_\\phi \\\\ 0 &amp; 0 &amp; s_\\theta s_\\phi \\\\ -c_\\theta s_\\phi &amp; -s_\\theta s_\\phi &amp; 0 \\\\ \\end{bmatrix} + \\begin{bmatrix} -c_\\theta (1-c_\\phi) &amp; s^2_\\theta (1-c_\\phi) &amp; 0 \\\\ -c_\\theta s_\\theta (1-c_\\phi) &amp; -s^2_\\theta (1-c_\\phi) &amp; 0 \\\\ 0 &amp; 0 &amp; c_\\phi-1 \\\\ \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} c_\\theta^2 c_\\phi + s_\\theta^2 &amp; -c_\\theta s_\\theta (1 - c_\\phi) &amp; -c_\\theta s_\\phi \\\\ -c_\\theta s_\\theta (1 - c_\\phi) &amp; s_\\theta^2 c_\\phi + c_\\theta^2 &amp; -s_\\theta s_\\phi \\\\ c_\\theta s_\\phi &amp; s_\\theta s_\\phi &amp; c_\\phi \\end{bmatrix} \\\\ \\end{align*}\\] where \\[\\begin{align*} \\textbf{U} &amp;= (u_x, u_y, u_z) = (s_\\theta, -c_\\theta, 0) \\\\ &amp;= \\begin{bmatrix} 0 &amp; -u_z &amp; u_y \\\\ u_z &amp; 0 &amp; -u_x \\\\ -u_y &amp; u_x &amp; 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; -c_\\theta \\\\ 0 &amp; 0 &amp; -s_\\theta \\\\ c_\\theta &amp; s_\\theta &amp; 0 \\\\ \\end{bmatrix} \\\\ \\end{align*}\\] 3.1.2.5 Step 4) Creating an animation of the radial rotation The steps outlined above can be used to create any arbitrary rotation in the manip space. To use these for sensitivity analysis, the radial rotation is built into an animation where the manip var is rotated fully into the projection, completely out, and then back to the initial value. This involves allowing \\(\\phi\\) to vary between \\(0\\) and \\(\\pi/2\\), call the steps \\(\\phi_i\\). Figure 3.3: Select frames highlight the animation of a radial manual tour manipulating aede2: (1) original projection, (2) full contribution, (3) zero contribution, before returning to the original contribution. Set initial value of \\(\\phi_1\\) and \\(\\theta\\): \\(\\phi_1 = \\cos^{-1}{\\sqrt{A_{k1}^2+A_{k2}^2}}\\), \\(\\theta = \\tan^{-1}\\frac{A_{k2}}{A_{k1}}\\). Where \\(\\phi_1\\) is the angle between \\(\\textbf{e}\\) and its shadow in \\(\\textbf{A}\\). Set an angle increment (\\(\\Delta_\\phi\\)) that sets the step size for the animation, to rotate the manip var into and out of the projection. Uses of angle increment, rather than a number of steps to control the movement is consistent with the tour algorithm as implemented in the tourr. Step towards \\(0\\), where the manip var is entirely in the projection plane. Step towards \\(\\pi/2\\), where the manip variable has no contribution to the projection. Step back to \\(\\phi_1\\). In each of the steps 3-5, a small step may be added to ensure that the endpoints of \\(\\phi\\) (\\(0\\), \\(\\pi/2\\), \\(\\phi_1\\)) is reached. 3.1.2.6 Step 5) Projecting the data The operation of a manual tour is defined on the projection bases. Only when the data plot needs to be made the data projected into the relevant basis. \\[\\begin{align*} \\textbf{Y}^{(i)}_{[n,~3]} &amp;= \\textbf{X}_{[n,~p]} \\textbf{M}_{[p,~3]} \\textbf{R}^{(i)}_{[3,3]} \\end{align*}\\] where \\(\\textbf{R}^{(i)}_{[3,3]}\\) is the incremental rotation matrix, using \\(\\phi_i\\). To make the data plot, use the first two columns of . Show the projected data for each frame in sequence to form an animation. Tours are typically viewed as an animation. The animation of this tour can be viewed online on GitHub. The page may take a moment to load. 3.2 Oblique cursor movement In a move abbreviated way we can think about the algorithm for 1D and 2D oblique manual tours as: 3.3 Package structure In addition to facilitating the manual tour the other primary function is to facilitate the layered composition of tours, interoperabily with tours from tourr. This package tries to abstract away the complexity of dealing with a varying number of frames and replicating the length of arguments. We use a layered composition approach to tours steming from ggplot2 (Hadley Wickham 2016), which can then be animated animation by plotly (Sievert 2020) or gganimate (Pedersen and Robinson 2020). This section describes the functions available in the package, their usage, and how to install and get up and running. 3.3.1 Usage Using the penguins data , available in the package, to illustrate a manual tour, we will illustrate generating a manual tour to explore the sensitivity of a variable separating two clusters. The composition of the tour display echos the additive layered approach of ggplot2, while abstracting away the complexity of dealing with changing number of frames and their animation. ## Process penguins data dat &lt;- scale_sd(penguins[1:4]) clas &lt;- penguins$species bas &lt;- basis_olda(data = dat, class = clas) ## A manual tour tour path mt_path &lt;- manual_tour(basis = bas, manip_var = 1, data = dat) ## Composing the display of the tour ggt &lt;- ggtour(mt_path, angle = .15) + proto_point(aes_args = list(color = clas, shape = clas), identity_args = list(alpa = .8, size = 1.5)) + proto_basis() + proto_origin() ## Animating animate_plotly(ggt, fps = 5) ## A 1D grand tour from tourr gt_path &lt;- save_history(data = dat, tour_path = grand_tour(d = 1), max_bases = 10) ## Composing the display of the tour ggt2 &lt;- ggtour(gt_path, angle = .15) + proto_default(aes_args = list(color = clas, fill = clas)) + proto_basis1d() + proto_origin1d() ## Animating animate_plotly(ggt2, fps = 5) 3.3.2 Functions Table 3.1 lists the primary functions and their purpose. These are grouped into four types: processing the data, production of tour path, the composition of the tour display, and its animation. Table 3.1: Summary of primary functions. Family Function Related to Description processing scale_01/sd scale each column to [0,1]/std dev away from the mean processing basis_pca/olda/ Rdimtools::do.* basis of orthogonal component spaces processing basis_half_circle basis with uniform contribution across half of a circle processing basis_guided tourr::guided_tour silently return the basis from a guided tour tour path manual_tour basis and interpolation information for a manual tour tour path save_history tourr::save_history silent, extended wrapper returning other tour arrays display ggtour ggplot2::ggplot canvas and initialization for a tour animation display proto_point/text geom_point/text adds observation points/text display proto_density/2d geom_density/2d adds density curve/2d contours display proto_hex geom_hex adds hexagonal heatmap of observations display proto_basis/1d adds adding basis visual in a unit-circle/-rectangle display proto_origin/1d adds reference mark in the center of the data display proto_default/1d wrapper for proto_* point + basis + origin display facet_wrap_tour ggplot2::facet_wrap facets on the levels of variable display append_fixed_y add/overwrite a fixed vertical position animation animate_plotly plotly::ggplotly render as an interactive hmtl widget animation animate_gganimate gganimate::animate render as a .gif, .mp4, or other video format animation filmstrip static gpplot faceting on the frames of the animation 3.3.3 Installation The spinifex is available from CRAN, the following code will help to get up and running: # Installation: install.package(&quot;spinifex&quot;) ## Install from CRAN library(&quot;spinifex&quot;) ## Load into session # Getting started: ## Shiny app for visualizing basic application run_app(&quot;intro&quot;) ## View the code vignette vignette(&quot;getting_started_with_spinifex&quot;) ## More about proto_* functions vignette(&quot;ggproto_api&quot;) 3.4 Use cases Wang et al. (2018) introduce a new tool, PDFSense, to visualize the sensitivity of hadronic experiments to nucleon structure. The parameter-space of these experiments lies in 56 dimensions, and are approximated as the ten first principal components. Cook, Laa, and Valencia (2018) illustrates how to learn more about the structures using a grand tour. Tours can better resolve the shape of clusters, intra-cluster detail, and better outlier detection than PDFSense &amp; TFEP (TensorFlow embedded projections) or traditional static embeddings. This example builds from here, illustrating how the manual tour can be used to examine the sensitivity of structure in a projection to different parameters. The specific 2D projections passed to the manual tour were provided in their work. The data has a hierarchical structure with top-level clusters; DIS, VBP, and jet. Each cluster is a particular class of experiments, each with many experimental datasets which each have many observations of their own. In consideration of data density, we conduct manual tours on subsets of the DIS and jet clusters. This explores the sensitivity of the structure to each of the variables in turn and we present the subjectively best and worst variable to manipulate for identifying dimensionality of the clusters and describing the span of the clusters. 3.4.1 Jet cluster The jet cluster resides in a smaller dimensionality than the full set of experiments, with four principal components explaining 95% of the variation in the cluster (Cook, Laa, and Valencia 2018). The data within this 4D embedding is further subset to ATLAS7old and ATLAS7new, to focus on two groups that occupy different parts of the subspace. Radial manual tours controlling contributions from PC4 and PC3 are shown in Figures 3.4 and 3.5, respectively. The difference in shape can be interpreted as the experiments probing different phase spaces. Back-transforming the principal components to the original variables can be done for a more detailed interpretation. When PC4 is removed from the projection (Figure 3.4), the difference between the two groups is removed, indicating that PC4 is essential for the separation of experiments. However, eliminating PC3 from the projection (Figure 3.5) does not affect the structure, meaning PC3 is not important for distinguishing experiments. Animations for the remaining PCs can be viewed at the following links: PC1, PC2, PC3, and PC4. It can be seen that only PC4 is important for viewing the difference in these two experiments. Figure 3.4: Select frames from a radial tour of PC4 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When PC4 is removed from the projection (frame 10), there is little difference between the clusters, suggesting that PC4 is important for distinguishing the experiments. Figure 3.5: Frames from the radial tour manipulating PC3 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When the contribution from PC3 is changed, there is little change in the separation of the clusters, suggesting that PC3 is not important for distinguishing the experiments. 3.4.2 DIS cluster Following Cook, Laa, and Valencia (2018), to explore the DIS cluster, PCA is recomputed and the first six principal components, explaining 48% of the full sample variation, are used. The contributions of PC6 and PC2 are explored in Figures 3.6 and 3.7, respectively. Three experiments are examined: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). Both PC2 and PC6 contribute to the projection similarly. When PC6 is rotated into the projection, variation in the DIS HERA1+2 is greatly reduced. When PC2 is removed from the projection, dimuon SIDIS becomes more distinct. Even though both variables contribute similarly to the original projection their contributions have quite different effects on the structure of each cluster, and the distinction between clusters. Animations of all of the principal components can be viewed from the links: PC1, PC2, PC3, PC4, PC5, and PC6. Figure 3.6: Select frames from a radial tour exploring the sensitivity that PC6 has on the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). DIS HERA1+2 is distributed in a cross-shaped plane, and charm SIDIS occupies the center of this cross, and dimuon SIDIS is a linear cluster crossing DIS HERA1+2. As the contribution of PC6 is increased, DIS HERA1+2 becomes almost singular in one direction (frame 5), indicating that this cluster has very little variability in the direction of PC6. Figure 3.7: Frames from the radial tour exploring the sensitivity PC2 to the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). As the contribution of PC2 is decreased, dimuon SIDIS becomes more distinguishable from the other two clusters, indicating that in the absence of PC2 is important for separating this cluster from the others. 3.5 Discussion Dynamic linear projections of numeric multivariate data, tours, play an important role in data visualization; they extend the dimensionality of visuals to peek into high-dimensional data and parameter spaces. This research has taken the manual tour algorithm, specifically the radial rotation, used in GGobi (Swayne et al. 2003) to interactively rotate a variable into or out of a 2D projection, and modified it to create an animation that performs the same task. It is most useful for examining the importance of variables and how the structure in the projection is sensitive or not to specific variables. This functionality is made available in the package spinifex. Which also extends the geometric display and export formats interoperable with the tourr package. This work was motivated by problems in physics, and thus the usage was illustrated on data comparing experiments of hadronic collisions to explore the sensitivity of cluster structure to different principal components. These tools can be applied quite broadly to many multivariate data analysis problems. The manual tour is constrained in the sense that the effect of one variable is dependent on the contributions of other variables in the manip space. However, this can be useful to simplify a projection by removing variables without affecting the visible structure. Defining a manual rotation in high dimensions is possible using Givens rotations and Householder reflections as outlined in Buja et al. (2005). This would provide more flexible manual rotation but more difficult for a user because they have the choice (too much choice) of which directions to move. "],["4-ch-userstudy.html", "Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data 4.1 User study 4.2 Results 4.3 Conclusion 4.4 Accompanying tool: radial tour application 4.5 Extended analysis", " Chapter 4 A Study on the Benefit of a User-Controlled Radial Tour for Variable Importance for Structure in High-Dimensional Data The previous chapter introduced the package spinifex which gave us the means to perform radial tours. Now we have the means to perform radial tours, we want now investigate whether we should be confident that this method with user control will lead to better analysis than traditional alternatives. Therefore, this chapter discusses the user study to elucidate the efficacy of the radial tour. In Chapters 1 and 2 have introduced PCA, the grand tour, and radial tour. This chapter describes a within-participants user study evaluating efficacy of these techniques. We devise a supervised classification task where participants evaluate variable attribution of the separation between two classes. We define an accuracy measure as the response variable. Data were collected from 108 crowdsourced participants, who performed two trials of each visual for 648 trials in total. The user influence over a basis, unique available in the radial tour, is crucial to testing variable sensitive to the structure visible in linear frame. If the contribution of a variable is reduced and the feature disappears, then we say that the variable was sensitive to that structure. For example, in Figure 4.1 shows 2 frames of simulated data. Panel (a) has identified separation between the two clusters. The contributions in panel (b) show no such cluster separation. The former has a large contribution to V2 in the direction of separation, while it is negligible in the later frame. Because of this we say that V2 is sensitive to the separation of the clusters. Figure 4.1: Illustrastion of cluster separation. Panel (a) shows clear separation in V2 and no separation in the direction of V3. While V1 and and v4 have relatively small contributions to the frame. Panel (b) has a random basis with a minmal contirbution from V2 and no separation between the cluster means is resolved. Knowing which variables to use is also important for statistical modeling and their interpretations. Models are becoming increasingly complex causing an opaqueness to their interpretability. Exploratory Artificial Intelligence (XAI, Adadi and Berrada 2018; Arrieta et al. 2020) is an emerging field that attempts to bring transparency to such black-box models by offering techniques to increase their interpretability. Multivariate data visualization is essential for exploring features spaces and communicating interpretations of models (Biecek 2018; Biecek and Burzykowski 2021; Hadley Wickham, Cook, and Hofmann 2015). The chapter is structured as follows. Chapter 2 discusses several visualization methods and orthogonal and observation-based visuals before arriving at the three linear dimension reduction techniques compared in the study. Section 4.1 describes the experimental factors, task, and accuracy measure used. The results of the study are discussed in Section 4.2. Conclusions and potential future directions are discussed in Section 4.3. The software used for the study is described in Section 4.4. 4.1 User study An experiment was constructed to assess the performance of the radial tour relative to the grand tour and PCA for interpreting the variable attribution contributing to separation between two clusters. Data were simulated across three experimental factors: cluster shape, location of the cluster separation, and data dimensionality. Participant responses were collected using a web application and crowdsourced through prolific.co, (Palan and Schitter 2018) an alternative to MTurk. 4.1.1 Objective PCA will be used as a baseline for comparison as it is the most common linear embedding. The grand tour will act as a secondary control that will help evaluate the benefit of animation without influencing its path. Lastly, the radial tour should perform best as it benefits both from animation and user-control. Then for some subset of tasks, we expect to find that the radial tour performs most accurately. In the appendix, section 4.5, we also regress on the last response time. Due to the absence of inputs, we expect the grand tour to perform faster than the alternatives since users can focus all of their attention on interpreting the fixed path. Conversely, we are less sure about the accuracy of such limited grand tours as there is no objective function in selecting the bases; it is possible that the random selection of the target bases altogether avoid bases showing cluster separation. However, given that the data dimensionality was modest, it seems plausible that the grand tour coincidentally regularly crossed frames with the correct information for the task. We measure the accuracy and response time over the support of the discussed experimental factors. The null hypothesis can be stated as: \\(~~~~H_0: \\text{task accuracy does not change across visualization method} \\\\\\) \\(~~~~~H_\\alpha: \\text{task accuracy does change across visualization method} \\\\\\) 4.1.2 Experimental factors In addition to visual factor, we simulate the data across three aspects. First the location of the difference between clusters by mixing a signal and a noise variable at different ratios, we vary the number of variables and their magnitude of cluster separation. Secondly the shape of the clusters, to reflect varying distributions of the data. And third, the dimension-ality of the data. Below we describe the levels within each factor, while Figure 4.2 gives a visual representation of the levels. Figure 4.2: Illustration of the experimental factors, the parameter space of the independent variables, the support of our study. The location of the separation of the clusters is at the heart of the measure. It would be good to test a few varying levels. To test the sensitivity to this, we mix a noise variable with the signal-containing variable. The difference in the clusters is mixed at the following percentages: 0/100% (not mixed), 33/66%, 50/50% (evenly mixed). In selecting the shape of the clusters, we follow the convention given by Scrucca et al. (2016), where 14 variants of model families containing three clusters are defined. The name of the model family is the abbreviation of its respective volume, shape, and orientation of the clusters, the levels of which are either _E_qual or _V_ary. We use the models EEE, EEV, and EVV. For Instance, in the EEV model, the volume and shape of clusters are constant, while the shapes orientation varies. The latter model is further modified by moving four-fifths of the data out in a V or banana-like shape. Dimension-ality is tested at two modest levels, namely, in four dimensions containing three clusters and six dimensions with four clusters. Such modest dimensionality is required to bound the difficulty and search space to keep the task realistic for crowdsourcing. 4.1.3 Task and evaluation With our hypothesis formulated and data at hand, let us turn our attention to the task and how to evaluate it. Regardless of the visual method, the elements of the display are held constant, shown as a 2D scatterplot with an axis biplot to its left. Observations were supervised with the cluster level mapped to color and shape. Participants were asked to check any/all variables that contribute more than average to the cluster separation green circles and orange triangles, which was further explained in the explanatory video as mark any and all variable that carries more than their fair share of the weight, or one quarter in the case of four variables. The instructions iterated several times in the video was: 1) use the input controls to find a frame that contains separation between the clusters of green circles and orange triangles, 2) look at the orientation of the variable contributions in the gray circle (biplot axes orientation), and 3) select all variables that contribute more than uniformed distributed cluster separation in the scatterplot. Independent with experimental level, participants were limited to 60 seconds for each evaluation of this task. This restriction did not impact many participants as the 25th, 50th, 75th quantiles of the response time were about 7, 21, and 30 seconds respectively. The evaluation measure of this task was designed with a few of features in mind: 1) the sum of squares of the individual variable weights should be one, 2) symmetric about zero, that is, without preference to under- or over-guessing 3) heavier than linear weight with increasing distance from a uniform height. With these in mind, we define the following measure for evaluating the task. Let a data \\(\\textbf{X}_{n,~p,~k}\\) be a simulation containing clusters of observations of different distributions. Where \\(n\\) is the number of observations, \\(p\\) is the number of variables, and \\(k\\) indicates the number of the cluster an observation belongs. Cluster membership is exclusive; an observation cannot belong to more than one cluster. We define weights, \\(w\\) as a vector explaining the variable-wise difference between two clusters. Namely, the difference of each variable between clusters, as a proportion of the total difference, less \\(1/p\\), the amount of difference each variable would hold if it were uniformly distributed. Participant responses are a logical value for each variable - whether or not the participant thinks each variable separates the two clusters more than uniformly distributed separation. \\[\\begin{align*} w_{j} &amp;=\\frac{(\\overline{X}_{\\cdot, j=1, k=1} - \\overline{X}_{\\cdot, 1, 2}, ~...~ (\\overline{X}_{\\cdot, p, 1} - \\overline{X}_{\\cdot, p, 2})} {\\sum_{j=1}^{p}(|\\overline{X}_{\\cdot, j, k=1} - \\overline{X}_{\\cdot, j, 2}|)} - \\frac{1}{p} \\shortintertext{Where accuracy, A, is defined as:} A &amp;= \\sum_{j=1}^{p}I(j) \\cdot sign(w_j) \\cdot w^2 \\end{align*}\\] Where \\(I(j)\\) is the indicator function, the binary response for variable \\(j\\). Figure 4.3 shows one frame of a simulation with its observed variable separation (wide bars), expected uniform separation (dashed line), and accuracy if selected (thin lines). Figure 4.3: (L), PCA biplot of the components showing the most cluster separation with (R) illustration of the magnitude of cluster separation is for each variable (bars) and the weight of the variable accuracy if selected (red/green lines). The horizontal dashed line is \\(1 / p\\), the amount of separation each variable would have if evenly distributed. The weights equal the signed square of the difference between each variable value and the dashed line. 4.1.4 Visual design standardization The factors are tested within-participant, with each visual being evaluated twice by each participant. The order that experimental factors are experienced is controlled with the assignment, as illustrated in Figure 4.4. Below we cover the visual design standardization and the input and display within each factor. The visualization methods were standardized wherever possible. Data were displayed as 2D scatterplots with biplots (Gabriel 1971), a visual with variable contributions inscribed on a unit circle. All aesthetic values (colors, shapes, sizes, absence of legend, and axis titles) were constant. Variable contributions were always shown left of the scatterplot embeddings with their aesthetic values consistent. What did vary between factors were their inputs. PCA inputs allowed users to select between the top four principal components for both axes regardless of the data dimensionality (four or six). Data was simulated to have cluster separation within the 2nd to 4th components. Cluster separation was sampled to not burying signal in 5th and 6th components (not selectable in PCA input), in the interest of simplicity and time. There was no user input for the grand tour; users were instead shown a 15-second animation of the same randomly selected path. Participants could view the same clip up to four times within the time limit. Radial tours were also displayed at five frames per second with a step size of 0.1 radians between interpolated frames. Users were able to swap between variables. Selecting a new variable resets the animation where the new variable is manipulated to a full, zero, and then back to its initial contribution. The complete animation of any variable takes about 20 seconds and is almost entirely in the projection frame at around six seconds. The starting basis was initialized to a half-clock design, where the variables were evenly distributed in half of the circle. This design was created to be variable agnostic while maximizing the independence of the variables. 4.1.5 Data simulation Each dimension is originally distributed as \\(\\mathcal{N}(0, 1)\\), given the covariance set by the shape factor. Clusters were originally separated by a distance of two before location mixing. Signal variables had a correlation of 0.9 when they had equal orientation and -0.9 when their orientations vary. Noise variables were restricted to zero correlation. Each cluster is simulated with 140 observations and is offset in a variable that did not distinguish previous variables. Clusters of the EVV shape are transformed to the banana-chevron shape (illustrated in figure 4.2, shape row). Then location mixing is applied by post-multiplying a (2x2) rotation matrix to the signal variable and a noise variable for the clusters in question. All variables are then standardized by standard deviation. The rows and columns are then shuffled randomly. The observations cluster and order of shuffling are attached to the data and saved. Each of these replications is then iterated with each level of the factor. For PCA, projections were saved for each of the 12 pairs of the top four principal components. We first save two basis paths of differing dimensions for the grand tour before each replication is projected through the common basis path. Each simulations variable order was previously shuffled effectually randomizing cluster separation shown, while mitigating bias from fringe selection of target bases. The resulting animations were saved as .gif files. The radial tour starts at either the four or six variable half-clock basis, where each variable has a uniform contribution in the right half with no variable contributing in the competing opposite direction. This acts to minimize the dependence between variable contributions. A radial tour is then produced for each variable and saved as a .gif. 4.1.6 Randomized factor assignment Now, with simulation and their artifacts in hand, we explain how the experimental factors are assigned and illustrate how this is experienced from a participants perspective. We section the study into three periods. Each period is linked to a randomized level of factor visualization and the location. The order of dimension and shape are of secondary interest and are held constant in increasing order of difficultly; four then six dimensions and EEE, EEV, then EVV-banana, respectively. Each period starts with an untimed training task at the simplest remaining experimental levels; location = 0/100%, shape = EEE, and four dimensions with three clusters. This serves to introduce and familiarize participants with input and visual differences. After the training, the participant performs on two trials with the same factor and location level across the increasing difficulty of dimension and shape. The plot was removed after 60 seconds, though this limit was rarely reached by participants. The order of the factor and location levels is randomized with a nested Latin square where all levels of the visual factor are exhausted before advancing to the next level of location. That means we need \\(3!^2 = 36\\) participants to evaluate all permutations of the experimental factors once. This randomization controls for potential learning effects the participant may receive. Figure 4.4 illustrates how an arbitrary participant experiences the experimental factors. Figure 4.4: Illustration of how a hypothetical participant 63 is assigned experimental factors. Each of the 6 factor order permutations is exhausted before iterating to the next permutation of location order. Through pilot studies sampled by convenience (information technology and statistics Ph.D.¬†students attending Monash University), we predict that we need three full evaluations to properly power our study; we set out to crowdsource \\(N = 3 \\cdot 3!^2 = 108\\) participants. 4.1.7 Participants We recruited \\(N = 108\\) participants via prolific.co (Palan and Schitter 2018). We filtered participants based on their claimed education requiring that they have completed at least an undergraduate degree (some 58,700 of the 150,400 users at the time); we apply this filter under the premise that linear projections and biplot displays will not be regularly used for consumption by general audiences. There is also the implicit filter that Prolific participants must be at least 18 years of age and implicit biases of timezone, location, and language. Participants were compensated for their time at 7.50 per hour, whereas the mean duration of the survey was about 16 minutes. We cannot preclude previous knowledge or experience with the factors but validate this assumption in the follow-up survey asking about familiarity with the factors. The appendix contains a heatmap distribution of age and education paneled across preferred pronouns of the participants that completed the survey, who are relatively young, well educated, and slightly more likely to identify as males. 4.1.8 Data collection Data were recorded by a shiny application and written to a Google Sheet after each third of the study. Especially at the start of the study, participants experienced adverse network conditions due to the volume of participants hitting the application with modest allocated resources. In addition to this, API read/write limitations further hindered data collection. To mitigate this, we throttled the number of participants and over-collect survey trials until we received our target three evaluations of all permutation levels. The processing steps were minimal. First, we format to an analysis-ready form, decoding values to a more human-readable state, and add a flag indicating whether the survey had complete data. We filter to only the latest three complete studies of each experimental factor, which should have experienced the most minor adverse network conditions. The bulk of the studies removed were partial data and a few over-sampled permutations. This brings us to the 108 studies described in the chapter, from which models and aggregation tables were built. The post-study surveys were similarly decoded to human-readable format and then filtered to include only those 84 associated with the final 108 studies. The code, response files, their analyses, and the study application are publicly available at on GitHub; . 4.2 Results To recap, the primary response variable is task accuracy, as defined in section 4.1.3. The parallel analysis of the log response time is provided in the appendix. We have two primary data sets; the user study evaluations and the post-study survey. The former is the 108 participants with the explanatory variables: visual factor, location of the cluster separation signal, the shape of variance-covariance matrix, and the dimensionality of the data. Experimental factors and randomization were discussed in section 4.1.2. The survey was completed by 84 of these 108 people. It collected demographic information (preferred pronoun, age, and education), and subjective measures for each factor (preference, familiarity, ease of use, and confidence). Below we build a battery of mixed regression models to explore the degree of the evidence and the size of the effects from the experimental factors. The, we use likert plots and rank-sum tests to compare the subjective measures between the visual factors. 4.2.1 Accuracy regression To more thoroughly examine explanatory variables, we regress against accuracy. All models have a random effect term on the participant and the simulation. These terms explain the error that can be attributed to the effect of the individual participant and variation due to the random sampling data. In building a set of models to test, we include all single term models with all independent terms. We also include an interaction term for factor and location, allowing for the slope of each location to change across each level of the factor. For comparison, an overly complex model with all interaction terms is included. The matrices for models with more than a two terms is rank deficient; there is not enough varying information in the data to explain all interacting terms. \\[ \\begin{array}{ll} \\textbf{Fixed effects} &amp;\\textbf{Full model} \\\\ \\alpha &amp;\\widehat{Y} = \\mu + \\alpha_i + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha + \\beta + \\gamma + \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha \\cdot \\beta + \\gamma + \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i \\cdot \\beta_j + \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha \\cdot \\beta \\cdot \\gamma + \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i \\cdot \\beta_j \\cdot \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha \\cdot \\beta \\cdot \\gamma \\cdot \\delta &amp;\\widehat{Y} = \\mu + \\alpha_i \\cdot \\beta_j \\cdot \\gamma_k \\cdot \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\end{array} \\] \\[ \\begin{array}{ll} \\text{where } &amp;\\alpha_i \\text{, fixed term for factor}~|~i\\in (\\text{pca, grand, radial}) \\\\ &amp;\\beta_j \\text{, fixed term for location}~|~j\\in (\\text{0/100\\%, 33/66\\%, 50/50\\%}) \\text{ \\% noise/signal mixing} \\\\ &amp;\\gamma_k \\text{, fixed term for shape}~|~k\\in (\\text{EEE, EEV, EVV banana}) \\text{ model shapes} \\\\ &amp;\\delta_l \\text{, fixed term for dimension}~|~l\\in (\\text{4 variables \\&amp; 3 cluster, 6 variables \\&amp; 4 clusters}) \\\\ &amp;\\mu \\text{ is the intercept of the model including the mean of random effect} \\\\ &amp;\\textbf{Z} \\sim \\mathcal{N}(0,~\\tau), \\text{ the error of the random effect of participant} \\\\ &amp;\\textbf{W} \\sim \\mathcal{N}(0,~\\upsilon), \\text{ the error of the random effect of simulation} \\\\ &amp;\\epsilon \\sim \\mathcal{N}(0,~\\sigma), \\text{ the remaining error in the model} \\\\ \\end{array} \\] Table 4.1: Model performance of random effect models regressing accuracy. Each model includes a random effect term of the participant explaining the individuals influence on accuracy. Complex models perform better in terms of \\(R^2\\) and RMSE, yet AIC and BIC penalizes their large number of fixed effects in favor of the much simpler model containing only the visual factor. Conditional \\(R^2\\) includes the random effects, while marginal does not. Fixed effects No.¬†levels No.¬†terms AIC BIC R2 cond. R2 marg. RMSE a 1 3 1000 1027 0.180 0.022 0.462 a+b+c+d 4 8 1026 1075 0.187 0.030 0.460 a*b+c+d 5 12 1036 1103 0.198 0.043 0.457 a*b*c+d 8 28 1069 1207 0.238 0.080 0.447 a*b*c*d 15 54 1125 1380 0.282 0.111 0.438 Table 4.2: The task accuracy model coefficients for \\(\\widehat{Y} = \\alpha \\cdot \\beta + \\gamma + \\delta\\), with factor = grand, location = 0/100%, and shape = EEE held as baselines. Factor being radial is the fixed term with the strongest evidence supporting the hypothesis. When crossing the visual factor there is some evidence suggesting radial performs worse with 33/66% mixing. The model fit is based on the 648 evaluations by the 108 participants. Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 0.03 0.08 44.2 0.44 0.66 factor Factorpca -0.15 0.09 622.4 -1.74 0.08 Factorradial 0.22 0.09 618.6 2.46 0.01 fixed effects Location33/66% 0.10 0.09 84.9 1.09 0.28 Location50/50% 0.05 0.09 83.0 0.58 0.56 ShapeEEV 0.04 0.06 11.5 0.79 0.44 Shapebanana -0.03 0.06 11.5 -0.48 0.64 Dim6 -0.06 0.05 11.5 -1.39 0.19 interactions Factorpca:Location33/66% 0.06 0.13 587.3 0.49 0.63 Factorradial:Location33/66% -0.28 0.13 577.6 -2.14 0.03 Factorpca:Location50/50% 0.09 0.13 589.6 0.68 0.50 Factorradial:Location50/50% -0.10 0.13 588.0 -0.77 0.44 Table 4.1 compares the model summaries across increasing complexity. We select the \\(\\alpha \\cdot \\beta + \\gamma + \\delta\\) model to explore in more detail. Table 4.2 looks at the coefficients for this model. We also want to visually explore the conditional variables in the model. Figure 4.5 explores violin plots of accuracy by factor while faceting on the location (vertical) and shape (horizontal). Use of the radial visual, on average, increases the accuracy, and especially so when the location of signal mixing is not 33/66%. Figure 4.5: Violin plots of terms of the model \\(\\widehat{Y} = \\alpha \\cdot \\beta + \\gamma + \\delta\\). Overlaid with global significance from the Kruskal-Wallis test and pairwise significance from the Wilcoxon test, both are non-parametric, ranked-sum tests suitable for handling discrete data. Participants are more confident and find the radial tour easier to use than the grand tour. Participants claim low familiarity, as we expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task. 4.2.2 Subjective measures The 84 evaluations of the post-study survey also collect four subjective measures for each factor. Figure 4.6 shows the Likert plots, or stacked percentage bar plots, alongside violin plots with the same non-parametric, ranked sum tests previously used. Participants preferred to use radial for this task. Participants were also more confident of their answers and found radial tours easier than grand tours. All factors have reportedly low familiarity, as expected from crowdsourced participants. Figure 4.6: The subjective measures of the 84 responses of the post-study survey, five discrete Likert scale levels of agreement (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests. 4.3 Conclusion Data visualization is an integral part of EDA. However, thorough exploration of data in high dimensions become difficult. Previous methods offer no means for an analyst to impact the projection basis. The manual tour provides a mechanism for changing the contribution of a selected variable to the basis. Giving analysts such control should facilitate the exploration of variable-level sensitivity to the identified structure. We find strong evidence that using the radial tour improves the accuracy relative to PCA or the grand tour on the supervised cluster task assigning variable attribution to the separation of the two clusters. This chapter discussed a with-in participant user study (\\(n=108\\)) comparing the efficacy of three linear projection techniques. The participants performed a supervised cluster task, explicitly identifying which variables contribute to separating two target clusters. This was evaluated evenly over four experimental factors. In summary, we find strong evidence that using the radial tour leads to a sizable accuracy increase. In the appendix we find evidence for a small change in response time, with PCA being fastest, then the grand tour followed by the radial tour. The effect sizes on accuracy are large relative to the change from the other experimental factors, though smaller than the random effect of the participant. The radial tour was subjectively preferred, leading to more confidence in answers, and increased ease of use than the alternatives. 4.4 Accompanying tool: radial tour application We have produced an application to illustrate the radial tour to accompany this study. The R package, spinifex, (Spyrison and Cook 2020) is free, open-source and now contains a shiny (Chang et al. 2020) application that allows users to apply various preprocessing tasks and interactively explore their data via interactive radial tour. Example datasets are provided with the ability to upload data. The .html widget produced is a more interactive variant relative to the one used in the user study. Screen captures and more details are provided in the appendix. Run the following R code will run the application locally. ## Download: install.packages(&quot;spinifex&quot;, dependencies = TRUE) ## Run interactive app demonstrating the radial tour: spinifex::run_app() Figure 4.7: Process data tab, interactively loads or select data, check which variables to project, and optionally scale columns by standard deviation. In the initial tab, Figure 4.7, users upload their own (.csv, .rds, or .rda) data or select from predefined data sets. The numeric columns appear as a list of variables to include in the projection. Below that, a line displays whether or not missing rows were removed. Scaling by standard deviation is included by default, as this is a common transformation used to explore linear projections of spaces. Summaries of the raw data and processed numeric data are displayed to illustrate how the data was read and its transformation. Figure 4.8: Radial tour tab, interactively create radial tours, changing the manipulation variable, and color or shape of the resulting manual tour. Here, the palmer penguins data is being explored, bill length was selected to manipulate as it is the only variable separating the green cluster from the orange. By mapping shape to island of observation, we also notice that the species in green live on all three islands, while the other species live only on one of the islands. The second tab, Figure 4.8 contains interaction for selecting the manipulation variable and non-numeric columns can be used to change the color and shape of the data points in the projection. The radial tour is created in real-time, animated as an interactive plotly .html widget. The application offers users a fast, intuitive introduction elucidating what the radial tour does and some of the features offered. 4.5 Extended analysis This section covers peripheral and extended analysis. First we explore the demographics of the participants. Then we extend a parallel modeling analysis on log response time. Lastly, we look at the effect ranges and marginal effects of the random effect of the participants and data simulation. Survey participant demographics The target population is relatively well-educated people, as linear projections may prove difficult for generalized consumption. Hence we restrict Prolific.co participants to those with an undergraduate degree (58,700 of the 150,400 users at the study time). From this cohort, 108 performed a complete study. Of these participants, 84 submitted the post-study survey, represented in the following heatmap. All participants were compensated for their time at 7.50 per hour, with a mean time of about 16 minutes. Figure 4.9 shows a heat map of the demographics for these 84 participants. Figure 4.9: Heatmaps of survey participant demographics; counts of age group by completed education as faceted across preferred pronoun. Our sample tended to be between 18 and 35 years of age with an undergraduate or graduate degree. 4.5.1 Response time regression As a secondary explanatory variable, we also want to look at time. First, we take the log transformation of time as it is right-skewed. We repeat the same modeling procedure: 1) Compare the performance of a battery of all additive and multiplicative models. Table 4.3 shows the higher level performance of these models over increasing model complexity. 2) Select the model with the same effect terms, \\(\\alpha \\cdot \\beta + \\gamma + \\delta\\), and examine its coefficients, displayed in Table 4.4. Table 4.3: Model performance regressing on log response time [seconds], \\(\\widehat{Y_2}\\) random effect models, where each includes random effect terms for participants and simulations. We see the same trade-off where AIC/BIC prefer the simplest factor model, while \\(R^2\\) and RMSE is the largest in the full multiplicative model. We again select the model \\(\\alpha \\cdot \\beta + \\gamma + \\delta\\) to explore further as it has relatively high marginal \\(R^2\\) while having much less complexity than the complete interaction model. Conditional \\(R^2\\) includes the random effects, while marginal does not. Fixed effects No.¬†levels No.¬†terms AIC BIC R2 cond. R2 marg. RMSE a 1 3 1000 1027 0.180 0.022 0.462 a+b+c+d 4 8 1026 1075 0.187 0.030 0.460 a*b+c+d 5 12 1036 1103 0.198 0.043 0.457 a*b*c+d 8 28 1069 1207 0.238 0.080 0.447 a*b*c*d 15 54 1125 1380 0.282 0.111 0.438 Table 4.4: Model coefficients for log response time [seconds] \\(\\widehat{Y_2} = \\alpha \\cdot \\beta + \\gamma + \\delta\\), with factor = PCA, location = 0/100%, and shape = EEE held as baselines. Location = 50/50% is the fixed term with the strongest evidence and takes less time. In contrast, the interaction term location = 50/50%:shape = EEV has the most evidence and takes much longer on average. Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 2.48 0.14 42.8 17.41 0.00 *** Factor Factorpca 0.23 0.12 567.6 1.97 0.05 Factorradial 0.39 0.12 571.9 3.29 0.00 ** Fixed effects Location33/66% 0.29 0.14 42.0 2.06 0.05 Location50/50% 0.07 0.14 40.5 0.54 0.59 ShapeEEV -0.15 0.09 8.3 -1.61 0.14 Shapebanana -0.13 0.09 8.3 -1.42 0.19 Dim6 0.14 0.08 8.3 1.90 0.09 Interactions Factorpca:Location33/66% -0.24 0.18 580.9 -1.34 0.18 Factorradial:Location33/66% -0.48 0.18 583.1 -2.63 0.01 ** Factorpca:Location50/50% -0.12 0.18 578.6 -0.69 0.49 Factorradial:Location50/50% -0.08 0.18 580.9 -0.43 0.67 Random effect ranges The random effect terms further clarify the source of the error. Below we compare the effect ranges that can be attributed to the participant and to the simulations next to their marginal effect on the response, a sort of upper bound for the error they could explain. We look at the original accuracy model and then the model regressing log response time. The residual plots have no noticeable non-linear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure 4.10 illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at \\(\\alpha = .95\\), while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95% confidence intervals participation and simulation mean accuracy, respectively. Figure 4.10: Accuracy model: (T) Estimated effect ranges of the random effect terms participant and data simulation of the accuracy model, \\(\\widehat{Y_1} = \\alpha \\cdot \\beta + \\gamma + \\delta\\). Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about two-thirds of the range of the data without the model. All intervals for \\(\\alpha = .95\\) confidence. Similarly, figure 4.11 shows the Gelman simulations and marginal effects of the simulation and participants for \\(Y_2\\), the same model regressing on log response time. Figure 4.11: Log response time model: (T) The effect ranges of Gelman resimulation on posterior distributions for the time model, \\(\\widehat{Y_2} = \\alpha \\cdot \\beta + \\gamma + \\delta\\). These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log time by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: \\(e^{1} = 2.7\\), \\(e^{2.75} = 15.6\\), \\(e^{3.75} = 42.5\\) seconds. Of the simulations on the right, the bottom has a large variation in response time, relative to the effect ranges which means that the variation is explained in the terms of the model and not by the simulation itself. "],["5-ch-cheem.html", "Chapter 5 Exploring Local Explanations of Non-linear Models Using Animated Linear Projections 5.1 SHAP and tree SHAP local explanations 5.2 The cheem viewer 5.3 Case studies 5.4 Discussion", " Chapter 5 Exploring Local Explanations of Non-linear Models Using Animated Linear Projections In the previous chapter discussed the within-participants user study comparing PCA, the grand tour, and the radial tour in a supervised variable attribution task. We found strong evidence that the radial tour leads to large increase in accuracy. Now we can be more confident that the radial tour leads to better analysis of variable-level attribution to features identified in a projection. Given the interpretability crisis of non-linear models, it would be interesting to see if the radial tour can help. Specifically, we will investigate using the radial tour to explore variable sensitivity to the structure identified in linear local explanations of non-linear models. That is under what support of variable importance does an explanation make sense, and when does it fail to be supported by the data. This can provide insight into why an observation is misclassified or otherwise has an extreme residual. We can also test how susceptible a variables contribution is to discerning the predictions of two observations. The increased predictive power comes at the cost of interpretability, which has led to the emergence of eXplainable AI (XAI). XAI attempts to shed light on how models use predictors to arrive at a prediction with a point estimate of the linear feature importance in the vicinity of each instance. These can be considered linear projections and can be further explored interactively to understand better the interaction between features used to make predictions across the predictive model surface. Here we describe interactive linear interpolation used for exploration at any instance and illustrate with examples with categorical (penguin species, chocolate types) and quantitative (football salaries, house prices) output. The methods are implemented in the R package cheem, available on CRAN. In Chapter 2 we introduced predictive modeling, the interpretability crisis of non-linear models, and local explanations  approximations of linear variable importance in the vicinity of one observation. The remainder of this chapter is organized as follows. The following Section, 5.1, induces the SHAP and tree SHAP local explanation. Section 2.4 explains the animations of continuous linear projections. Section 5.2 discusses the visual layout in the interactive interface, how they facilitate analysis, data preprocessing, and package infrastructure. Then Section 5.3 illustrates the application to supervised learning with categorical and quantitative output. We conclude with Section 5.4 of the insights gained and directions that might be explored in the future. 5.1 SHAP and tree SHAP local explanations SHaply Additive exPlanations (SHAP) quantifies the feature contributions of one instance by examining the effect of other features on the predictions. The explanations of SHAP almost all refer to Shapley (1953)s method to evaluate an individuals contribution to cooperative games by assessing the performance of this player in the presence or absence of other players. Strumbelj and Kononenko (2010) introduced the use of SHAP for local explanations in ML models. The attribution of feature importance depends on the sequence of the features already included. The SHAP values are the mean contributions over different feature sequences. The approach is related to partial dependence plots (Molnar 2020), used to explain the effect of a feature by predicting the response for a range of values on this feature after fixing the value of all other features to their mean. Partial dependence plots are a global approximation of the feature importance, while SHAP is specific to one instance. It could also be considered similar to examining the coefficients from all subsets regression, as described in Hadley Wickham, Cook, and Hofmann (2015), which helps to understand the relative importance of each feature in the context of all other candidate features. Figure 5.1: Illustration SHAP values for a random forest model FIFA 2020 player wages from nine skill predictors. A star offensive and defensive player are compared, L. Messi and V. van Dijk, respectively. Panel (a) shows breakdown plots of three sequences of the features, order and magnitude change. Panel (b) shows the distribution of attribution for each feature across 25 sequences of predictors, with the mean displayed as a dot, for each players. Offense and movement are important for Messi but not van Dijk, and conversely, defense and power are important for van Dijk but not Messi. For our application, we use tree SHAP, a variant of SHAP that enjoys a lower computational complexity (Lundberg, Erion, and Lee 2018). Instead of aggregating over sequences of the features, tree SHAP calculates instance-level feature importance by exploring the structure of the decision trees. Tree SHAP is only compatible with tree-based models; we illustrate random forests. The following section will use normalized SHAP values as a projection basis (call this the attribution projection) will have coefficients varied to further scrutinize the feature contributions. Following the use case Explanatory Model Analysis (Biecek and Burzykowski 2021), we use FIFA data to illustrate the use of SHAP. Consider soccer data from the FIFA 2020 season (Leone 2020). There are 5000 instances of 9 skill measures (after aggregating highly correlated features). A random forest model is fit, regressing players wages [2020 Euros] from their skill measurements. We then extract the SHAP values of a star offensive player (L. Messi) and defensive player (V. van Dijk). The results are displayed in Figure 5.1. We expect to see a difference in the attribution of the feature importance across the two positions of the players, which would be interpreted as how the players salary depends on this combination of skill sets. Plot (b) is a modified breakdown plot (Gosiewska and Biecek 2019) where the order of features is fixed, so the two instances can be more easily compared. In summary, these plots highlight how local explanations bring interpretability to a model, at least in the vicinity of their instances. In this instance, two players with different positions receive different profiles of feature importance to explain the prediction of their wages. 5.2 The cheem viewer To explore the local explanations, an ensemble of plots (Unwin and Valero-Mora 2018) is provided, called the cheem viewer. There are two primary plots: the global view to give the context of all of the SHAP values, and the radial tour view to explore the local explanations with user-controlled rotation. In addition, there are numerous user inputs, including feature selection for the radial tour and instance selection for making comparisons. There are different plots used for categorical and quantitative response. Figures 5.2 and 5.3 contain screenshots showing the cheem viewer for the two primary tasks: classification (categorical response) and regression (quantitative response). 5.2.1 Global view The global view provides the context of all instances and facilitates the exploration of the separability of the data- and attribution-spaces. Both of these spaces are of dimension \\(n\\times p\\), where \\(n\\) is the number of instances and \\(p\\) is the number of predictors. The attribution space corresponds to the local explanations for each instance, which will have \\(p\\) values for each instance. A visualization of these spaces is provided by the first two principal components (PCA, Pearson 1901) of their respective spaces. In addition, a plot observed by predicted response is also provided (Fig. 5.2, b). A single 2D projection will not encompass all of the structure of higher-dimensional space, but it is generally a useful visual summary. For classification tasks, misclassified instances are circled in red if applicable. Linked brushing between the plots is provided, and a tabular display of selected points helps to facilitate exploration of the spaces and the model (shown in Fig. 5.2 a and c). While the comparison of these spaces is interesting, the main purpose of the global view is to enable the selection of instances to explore the local explanations. The projection attribution of the Primary Instance (PI) is examined and typically viewed with an optional Comparison Instance (CI). These instances are highlighted as asterisk and \\(\\times\\) in 2D spaces and long dashed and short dotted lines on 1D spaces. 5.2.2 Radial tour The local explanations for all observations are normalized (squared sum of values adds to 1) and thus the relative importance of features can be compared across all instances. These are depicted as a vertical parallel coordinate plot, where each line connects one instances feature attribution (Fig. 5.2 e and 5.3 e). The attribution projections of the PI and CI are shown as dashed and dotted lines, respectively. From this plot, we would read the range of importances across all instances can be interpreted. For classification, one would look at differences between groups on any feature, for example, Fig. 5.2 e suggests that b_l is important for distinguishing the green class from the other two. For regression, one might generally observe which features have low values for all instances (not important), for example, BMI and pwr in 5.3 e, and which have a range of high and low values (e.g.¬†off, def) suggesting important for some instances and not important for other instances. The overlaid bars on the parallel coordinate plot represent the attribution projection of the PI. (Remember that the PI is interactively selected from the global view). The attribution projection is an approximation of the feature importance, for the prediction of this instance. This combination of features best explains the difference between the mean response and an instances predicted value. It is not an indication of the local shape of the model surface, that is, it is not some indication of the tangent to the curve at this point. The attribution projection of the PI is the initial 1D basis in a radial tour, displayed as a density plot for a categorical response (Fig. 5.2, f), and as scatterplots for a quantitative response (Fig. 5.3, f). The PI and CI are indicated by vertical dashed and dotted lines, respectively. The user uses the radial tour to vary contribution of the selected feature between 0-1. Doing so tests the sensitivity of structure (class separation or strength of relationship) to the features contribution. For classification, if the separation between classes diminishes when the feature contribution is reduced then this suggests that the feature is important for the class separation. For regression, if the relationship scatterplot weakens when the feature contribution is reduced then this suggests that the feature is important for accurately predicting the response. 5.2.3 Classification task Selecting a misclassified instance as PI and a correctly classified point nearby in data space as CI, makes it easier to examine the features most responsible for the error. The global view (Fig. 5.2 c) displays the model confusion matrix. The radial tour is 1D, plotted as a density where color indicates class. A scroll bar here enables the user to vary the contribution of each feature to explore the sensitivity the separation to that feature. Figure 5.2: Overview of the cheem viewer for classification tasks. Global view inputs, (a), set the PI, CI, and color statistic. Global view, (b) PC1 by PC2 approximations of the data space and attribution space. (c) prediction by observed y (visual of the confusion matrix for classification tasks). Points are colored by predicted class, and red circles indicate misclassified instances. Radial tour inputs (d) select features to include and which feature is changed in the tour. (e) shows parallel coordinate display of the distribution of the feature attributions while bars dipict contribution for the current basis. The black bar is the variable being changed in the radial tour. Panel (f) is the resulting projection of the data indicated as density in the classification case. 5.2.4 Regression task Selecting an inaccurately predicted instance as PI and an accurately predicted instance, with similar feature values, as CI is a useful way to understand how the model is failing, or not. The global view (Fig. 5.3 a) shows a scatterplot of the observed vs predicted values, which should exhibit a strong relationship if the model is a good fit. The points can be colored by a statistic, residual, a measure of outlyingness (log Mahalanobis distance) or correlation, to help with understand where the model fits better or worse. In the radial tour view, the observed response and the residuals (vertical) are plotted against the attribution projection of the PI (horizontal). The attribution projection can be interpreted similarly to the predicted value from the global view plot. It represents a linear combination of the features, and a good fit would be indicated when there is a strong relationship seen with the observed values. This can be viewed as a local linear approximation if the fitted model is nonlinear. As the contribution of a feature is varied, if the value of the PI doesnt change much it would indicate that the prediction for this instance is NOT sensitive to that feature. Conversely, if the predicted value varies substantially, the prediction is very sensitive to that feature, suggesting that the feature is very important for the PIs prediction. Figure 5.3: Overview of the cheem viewer for regression task highlighting the differences from the classification task and interactive features. Panel (a) shows linked brushing across the global view and the tooltip display when the cursor hovers over an instance. Applied linked brushing, (b), selected points are highlighted in the component spaces and tabularly displayed. Coloring on a statistic (c) highlights structure organized in the attribution space. Interactive tabular display (d) populates when instances are selected. Contribution of the 1D basis effecting the horizontal position (e) parallel coorindate display of the feature attribution from all observations, and horizontal bars show the contribution to the current basis. Regression projection (f) uses the same horizontal projection and fixes the vertical positions to the observed y and residuals, (left and right). 5.2.5 Interactive features The application has several reactive inputs that affect the data used, aesthetic display, and tour manipulation. These reactive inputs make the software flexible and extensible. The application also has more exploratory interactions to help link points across displays and reveal structure found in different spaces. A tooltip displays instance number/name and classification information while the cursor hovers over a point. Linked brushing allows the selection of points (left click and drag) where those points will be highlighted across plots. The information corresponding to the selected points is populated on a dynamic table. These interactions aid exploration of the spaces and, finally, identification of a primary and comparison instance. 5.2.6 Preprocessing It is vital to mitigate the render time of visuals, especially when users may want to iterate many times. All computational operations should be prepared before runtime. The work remaining when an application is run solely reacts to inputs and rendering of visuals and tables. Below we discuss the steps and details of the reprocessing. (ref:citeRf) Liaw and Wiener (2002) (ref:citeTs) Kominsarczyk et al. (2021) The time to preprocess the data will vary significantly with the model and local explanation. For reference, the FIFA data, 5000 instances of nine explanatory features, took 2.5 seconds to fit a random forest model of modest hyperparameters. Extracting the tree SHAP values of each instance took 270 seconds combined. PCA and statistics of the features and attributions took 2.8 seconds. These runtimes were from a non-parallelized R session on a modern laptop, but suffice to say that most of the time will be spent on the local attribution. An increase in model complexity or data dimensionality will quickly become an obstacle. Its reduced computational complexity makes tree SHAP a good candidate to start with.1 5.2.7 Package infrastructure The above-described method and application are implemented as an open-source R package, cheem, available on CRAN. Preprocessing was facilitated with models created via randomForest (Liaw and Wiener 2002) and explanations calculated with treeshap (Kominsarczyk et al. 2021). The application was made with shiny (Chang et al. 2021). The tour visual is built with spinifex (Spyrison and Cook 2020). Both views are created first with ggplot2 (Hadley Wickham 2016) and then rendered as interactive HTML widgets with plotly (Sievert 2020). DALEX (Biecek 2018) and the free ebook, Explanatory Model Analysis (Biecek and Burzykowski 2021) were a huge boon to understanding local explanations and how to apply them. 5.2.8 Installation and getting started The following R code will help with getting up and running: ## Download the package install.packages(&quot;cheem&quot;, dependencies = TRUE) ## Restart the R session, so the IDE has the correct directory structure restartSession() ## Load cheem into session library(&quot;cheem&quot;) ## Try the app run_app() # Processing your data ## Install treeshap from github to use as a local explainer remotes::install_github(&#39;ModelOriented/treeshap&#39;) ## Follow the examples in cheem_ls() ?cheem_ls 5.3 Case studies To illustrate the use of the cheem method, we apply it to modern datasets, two classification examples and then two of regression. 5.3.1 Palmer penguin, species classification The Palmer penguins data (Gorman, Williams, and Fraser 2014; Horst, Hill, and Gorman 2020) was collected on three species of penguins foraging near Palmer Station, Antarctica. The data was publicly available to substitute for the overly-used iris data and is quite similar in form. After removing incomplete instances, there are 333 instances and we will use the four physical measurements, bill length (b_l), bill depth (b_d), flipper length (f_l), and body mass (wgt), for this illustration. A random forest model was fit with species as the output. (ref:casepenguins) Examining the SHAP values for a random forest model classifying Palmer penguin species. The PI is an Chinstrap (orange) penguin that is misclassified as a Gentoo (purple), marked as an asterisk in (a), and the dashed vertical line in (b). The radial view varies the contribution of f_l from the initial attribution projection (b, left), which produces a linear combination where the PI is more probably a Chinstrap than a Gentoo (b, right). (The animation of the radial tour is at vimeo.com/666431172.) Figure 5.4: (ref:casepenguins) Figure 5.4 shows plots from the cheem viewer for exploring the random forest model on the penguins data. Panel (a) shows the global view, and panel (b) shows several 1D projections generated with the radial tour. Penguin 243, a Gentoo (purple), is the PI because it has been misclassified as a Chinstrap (orange). (ref:casepenguinsblfl) Checking what is learned from the cheem viewer. This is a plot of flipper length (f_l) and bill length (b_l), where an asterisk highlights the PI. A Gentoo (purple) misclassified as a Chinstrap (orange). The PI has an unusually small f_l length which is why it is confused with a Chinstrap. Figure 5.5: (ref:casepenguinsblfl) There is more separation visible in the attribution space than the data space, as would be expected. The predicted vs observed plot reveals a handful of misclassified instances. We will explore why a Gentoo has been wrongly labeled as a Chinstrap for this illustration. The PI is a misclassified point (represented by the asterisk in the global view and as a dashed vertical line in the tour view). The CI is a correctly classified point (represented by an \\(\\times\\) and a vertical dotted line). The radial tour starts from the attribution projection of the misclassified instance (b, left). The important features identified by SHAP in the (wrong) prediction for this instance are mostly b_l and b_d with small contributions of f_l and wgt. This projection is a view where the Gentoo (purple) looks much more likely for this instance than Chinstrap. That is, this combination of features is not particularly useful because the PI looks very much like other Gentoo penguins. To explore this, we use the radial tour to vary the contribution of flipper length (f_l). (In our exploration, this was the third feature explored. It is typically useful to explore the features with larger contributions, here b_l and b_d, but when doing this, nothing was revealed about how the PI differed from other Gentoos). On varying f_l as it contributes more to the projection (b, right), we see that more, and more, this penguin looks like a Chinstrap. This suggests that f_l should be considered an important feature for explaining the (wrong) prediction. Figure 5.5 confirms that flipper length (f_l) is important for the confusion of the PI as a Chinstrap. Here, flipper length and body length are plotted, and we can see that the PI is closer to the Chinstrap group in these two features, mostly because it has an unusually low value of flipper length relative to other Gentoos. From this view it makes sense that its a hard instance to account for as decision trees can only partition only vertical and horizontal lines. 5.3.2 Chocolates, milk/dark chocolate classification The chocolates dataset consists of 88 instances of ten nutritional measurements determined from their labels and labeled as either milk or dark. Dark chocolate is considered healthier than milk. The data was collected by students during the Iowa State University class STAT503 from nutritional information from the manufacturers website and normalized to 100g equivalents. The data is available in the cheem package. A random forest model is used for the classification of chocolate type. It could be interesting to examine the nutritional properties of any dark chocolates that have been misclassified as milk. A reason to do this is that a dark chocolate that is nutritionally more like milk should not be considered a healthy alternative. It is interesting to explore which of the nutritional features contribute most to misclassification. (ref:casechocolates) Chocolates data type classification (milk or dark). We select a chocolate labeled as dark though a random forest model predicts it to be milk chocolate from the values on the nutritional label. The attribution projection already looks more like a dark chocolate than milk. We remove four features with the lowest contribution for the selected instance and vary the contribution of Fiber. The misclassification seems improbable when sugar is near the max contribution. Animated tour can be found at vimeo.com/666431143. Figure 5.6: (ref:casechocolates) This type of exploration is shown in Figure 5.6, where a chocolate labeled dark but predicted to be milk is chosen as the PI (instance 22). It is compared with a CI that is a correctly classified dark chocolate (instance 7). The PCA plot, and the SHAP PCA plots (a) show a big difference between the two chocolate types but with confusion for a handful of instances. The misclassifications are clearer in the observed vs predicted plot, and can be seen to be mistaken in both ways: milk to dark and dark to milk. The attribution projection for chocolate 22 suggests that Fiber, Sugars and Calories are most responsible for its incorrect prediction. The way to read this plot is to see that Fiber has a large negative value, while Sugars and Calories have reasonably large positive values. In the density plot, instances on the very left of the display would have high values of Fiber (matching the negative projection coefficient) and low values of Sugars and Calories. The opposite would be the interpretation of a point with high values in this plot. The dark chocolates (orange) are mostly on the left, and this is a reason why they are considered to be healthier: high fiber and low sugar. The density for milk chocolates is further to the right, indicating that they generally have low fiber and high sugar. The instance of interest (dashed line) can be viewed against the comparison instance (dotted line). Now one needs to pay different attention to the parallel plot of the SHAP values, which are local to a particular instance, and the density plot, which is the same projection of all instances as specified by the SHAP values of the instance of interest. We can quickly compare the feature contributions to the two different predictions from the parallel coordinate plot. The instance of interest differs with the comparison primarily on the Fiber feature, which suggests that this is the reason for the incorrect prediction. From the density plot, which is the attribution projection corresponding to the instance of interest, both instances are more like dark chocolates. If we vary the contribution of Sugars, and completely remove Sugars from the projection, this is where the difference becomes apparent. When primarily Fiber is examined, instance 22 looks more like a milk chocolate. (ref:casechocolatesinverse) Chocolates data type classification (milk or dark). Looking at the inverse misclassification, we select a milk chocolate while the model predicts it to be dark chocolate. Sodium and Fiber (Na and Fbr) have the largest differences in attributed feature importance. We remove features with the lowest contributions and vary the contribution of Sodium. This misclassification is not supported when sodium has contribution close to the attribution aligned with the other milk chocolates. Animated tour can be found at vimeo.com/666431143. Figure 5.7: (ref:casechocolatesinverse) It would also be interesting to explore the inverse case, which features lead to a milk chocolate being misclassified as dark. Chocolate 84 is just this case, and we compare it with a correctly predicted milk chocolate (instance 71). This exploration is shown in Figure 5.7. We identify the largest discrepancies in Sodium and Fiber from the parallel coordinate lines. It already appears that the PI is slightly more like milk chocolate than dark. We opt to vary Sodium and find an intermediate contribution of sodium yields much better support for the misclassification. That is, this attribution would be a better explanation for the misclassification. For completeness, we also varied fiber (not shown) and found narrow profiles of when the PI was more separable and in the distribution of its observed dark chocolates that would have led to a correct classification. 5.3.3 FIFA, wage regression The 2020 season FIFA data (Leone 2020; Biecek 2018) contains many skill measurements of soccer/football players and wage information. After aggregating highly correlated skill, we regress player wages [2020 euros] given just the skill aggregates. The model was fit from 5000 instances of the nine skill aggregates before being thinned to 500 players to mitigate occlusion and render time. We compare a leading offensive fielder (L. Messi) with that of a top defensive fielder (V. van Dijk). The same instances were used in figure 5.1. (ref:casefifa) FIFA 2020 data, a random forest model, regresses wages [2020 Euros] from nine aggregated skill measurements. The PI is a star offensive player (L. Messi) compared with a top defensive player (V. van Dijk). We remove three features with low attribution from both players. The attribution projection starts with the selected instance on the right. We vary the contribution from defense (def), the star offensive player is not distinguished in the horizontal direction. At this point, defensive players have been rotated to the highest horizontal value. The animate radial tour can be found at vimeo.com/666431163. Figure 5.8: (ref:casefifa) With figure 5.8, we will test the premise of the local explanation. Offensive and reaction skills (off and rct) are both influential to explaining a star offensive player. As the contribution of defensive skills increases, Messis prediction is no longer separated from the group, and other defensive players are better predicted in this attribution case. In terms of what-if analysis, his predicted wages would be halved if Messis tree SHAP attributions were these levels. 5.3.4 Ames housing 2018, sales price regression Starting from the Ames 2018 housing data (De Cock 2011), the data was subset to North Ames (the neighborhood with the most house sales). The remaining are 338 house sales. A random forest model has regressed this price with the features Lot Area (LtA), Overall Quality (Qlt), Year the house was Build (YrB), Living Area (LvA), number of Bathrooms (Bth), number of Bedrooms (Bdr), total number of Rooms (Rms), Year the Garage was Build (GYB), and Garage Area (GrA). Using interaction from the global view, we select a house with an extreme negative residual and an accurate instance close to it in the data. (ref:caseames) Ames housing 2018 regressing sales price [USD]. The PI sale price was under predicted and had sizable attribution to lot area (LtA). The CI was predicted sales price was similar and much more accurate with its observed sales price while it has very little attribution to lot area. Varying the contribution lot area the separation between these house sales crosses when there is a low contribution of LtA, which is important to explaining the PI and near invariant to the sales price of the CI. The corresponding animation is at vimeo.com/666431134. Figure 5.9: (ref:caseames) Figure 5.9 selects the house sale 74, a sizable under prediction that has a large contribution from lot area. The CI has a similar predicted price though the prediction was accurate and gives almost no attribution to lot size. The attribution projection is places instances with high living areas to the right. We control the contribution of this feature. As the contribution of lot area decreases, the predictive power decreases for the PI, while the CI remains stationary. This large of an importance is living area is relatively uncommon. Boosting tree models may be more resilient to such an under prediction as up-weighting this residual would force its inclusion in the final model. 5.4 Discussion The need to maintain the interpretability of non-linear models is evident. One aspect uses local explanations of the model in the vicinity of an instance. Local explanations approximate the linear feature importance to the model. Our contribution is to assess explanations by examining the support by varying the contributions with a radial tour. First, a global view visualizes approximations of the data space, explanation space, model predictions side-by-side, using dynamic interaction to compare, contrast, and identify instances of interest. The normalized linear importance from the explanation of the PI becomes the feature of interest to further explore with the radial tour. The tours explore the feature sensitivity to the structure identified in the explanation. We have illustrated this method on random forest models using the tree SHAP local explanation, while it could be generally used with any compatible model-explanation pairing. We apply it to the classification and regression tasks. We have created an open-source R package cheem, available on CRAN, to facilitate preprocessing and exploration with the described interactive application. Toy and real data are provided, or upload your data after preprocessing. Alternatively, the package fastshap (Greenwell 2020) claims extremely low runtimes, attributed to fewer calls to the prediction function, partial implementation in C++, and efficient use of logical subsetting. "],["6-ch-conclusion.html", "Chapter 6 Conclusion 6.1 Contributions 6.2 Limitations and future work", " Chapter 6 Conclusion Multivariate data is widely used in many fields. We know that visualizing data is more robust than numerical summarization alone. It allows the analyst to get a feel for the data rapidly, check for erroneous values, and confirm model assumptions. But visualizing data spaces becomes increasingly complex as dimensionality increases. Static linear dimension reduction has been widely used to extend the dimensionality of spaces viewed. Dynamic animations of linear projections, tours, further increase the perceptible information of linearly reduced spaces. Manual tours novelly allow the analyst to steer contributions of the basis. The work outlined in this thesis makes several contributions to multivariate data visualization focusing on manual tours. 6.1 Contributions The contributions of this thesis can be split into scientific knowledge and software. 6.1.1 Scientific knowledge First, I clarify the use of Rodrigues rotation formula to solve the rotation matrix with the definition of two manipulation angles. This sets up a scaffolding to extend the manual tour to three dimensions with another rotation angle to span the manipulation space. This work also supports the use of manual tours by illustrating use cases on high-energy physics data. Then I define a task and accuracy measure for a variable attribution of the separation of two clusters. A crowdsourced user study is conducted comparing the performance from PCA, the grand tour, and the radial tour. There is considerable evidence for a sizable improvement in accuracy with the use of the radial tour, which participants also subjectively prefer. Lastly, I purpose the cheem analysis to explore the variable support of local explanations from black-box models. From a non-linear model, the local explanations of all observations are calculated. Then compare data space, attribution space, and model information side-by-side as an ensemble graphic. From this, identify a primary observation to explore the explanation in detail. The normalized attribution this point becomes the starting basis for a radial tour. Then vary the contributions of variables, testing their contributions sensitivity to the predictive discernment identified in the explanation. 6.1.2 Software The R package spinifex facilitates the creation of manual tours, which allow an analyst control over the contributions of a variable. It handles data transformations and the identification of various starting bases. It creates a framework for the layered composition of tours interoperably with the previous tourr package. This composition will feel at home to ggplot2 users. After composition, tours can be animated and exported as interactive HTML widgets or fixed animations as .gif, or .mp4 files. Vignettes and interactive application help users rapidly understand the concepts of facilitated work. The impact of spinifex can be seen in two ways. My contributions to spinifex and tourr won the ACEMS Impact and Engagement Award, 2018. Furthermore, the package is available on CRAN with vignettes and version notes on its pkgdown site. It has been downloaded over 14,400 times from CRAN between 09 April 2019 and 28 November 2021. The second software contribution is the cheem package. It facilitates the tree SHAP local explanations from tree-based models. The global view visualizes data space, explanation space, and model information as an ensemble graphic with linked brushing. After observations of interest have been identified in the full context, their local explanation is explored with the radial tour. Doing so allows the support of the explanation to be tested. An interactive application uses these visuals to facilitate the cheem analysis. Several preprocess datasets are included and allows analysts to upload their data after processing. This package was recently uploaded to CRAN and has a corresponding pkgdown site. 6.2 Limitations and future work Below a call and response format is used to discuss the limitations and possible future work to address them following chapter order. The spinifex package is built around one and two-dimensional manual tours. The layered composition of tours is interoperable with \\(d \\in [1, 2]\\) tours produced with tourr. However, non-manual tours can easily increase the embedded dimensionality. As such, \\(d&gt;2\\) tours are under-supported in the layered composition. Additional functions could be added to facilitate geometric display to parallel coordinate plots, Chernoff faces, and pixel-based displays. These displays are potentially best used with data with relatively few observations and many variables. In contrast, extending the output dimension of the manual tour would require an additional manipulation angle. Which would be rotated in a 4D manipulation space. Chapter 3 included the scaffolding for this task. Namely, this would require applying another angle of rotation with Rodrigues rotation formula on the current 3D rotation matrix. Another display dimension may benefit the detection and understanding of the higher dimensional structure though the input of three angles may prove less natural and harder to capture. The manual tour only controls the contribution to one variable at a time. This can become cumbersome and time-consuming as dimensionality increases. In addition to the manual tour controlling the contribution of a single variable, it may be insightful to change the contributions of several variables at once (manipulating a linear combination). Alternatively, a sort of dimension reduction tour, appending several manual tours that sequentially zero the contributions of variables contributing less than some threshold, may prove to expedite analysis, especially for approaching a features intrinsic dimensionality. Setting aside the manual tour, there are several extensions to the layered composition of tours in spinifex, such as extending the type of geometric display functions available, such as adding a text table of the basis, convex hulls, alpha hulls, and a high-density region display where the bulk of the data is shown as density contour, while the outermost observations are displayed as points (Hyndman 1996). The radial tours current three segments (increase-decrease-increase of magnitude) takes a bit to unpack. It may be more approachable to directly relate the position of the slider to the magnitude of the manipulation variable. The display order of the manual tour could be changed to more of an ink tank display, where the first frame would contain zero variable contribution, and the last would have a complete contribution. The starting frame would be the original contribution that would also be exaggerated or annotated to reference against. It may be interesting to experience tours as 3D scatterplots in extended reality with stereoscopically true head tracking may be fruitful. Nelson, Cook, and Cruz-Neira (1998) explore 2D tour is in virtual reality. Other works view 3D scatterplot tours on 2D displays (Yang 1999, 2000). It would be interesting to see modern implementations using WebGL, Mozilla A-frame, or Unity. One concern would be keeping hardware and software as generalized as possible. Besides changing the support of the experimental factors to the user study, it would be more interesting to try different tasks or compare other visualization techniques. The discussed user study crowdsourced participants with little exposure to linear projections. It would be interesting to compare the results from more familiar and experienced participants. The outlined cheem analysis can be generally applied models and local explanations. The package cheem currently calculates tree SHAP for tree-based models supported by treeshap. This could be generalized more broadly to other models and local explanations. Those facilitated by DALEX::explain() seems to be an excellent direction to extend (Biecek 2018; Biecek and Burzykowski 2021). However, processioning runtime would quickly become a formidable obstacle. Alternatively, other statistics may better show the structure identified by explanations. In cheem, we had focused primarily on continuous numeric predictors. Perhaps this analysis could be extended to image, text, or time series analysis. The presence of covariates in these cases may prove essential to having meaningful variable importance to test variable sensitivity of the structure of the explanation. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
