[["index.html", "Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models Welcome", " Interactive and dynamic visualization of high-dimensional data via animated linear projections, their efficacy, and their application to local explanations of non-linear models Nicholas S Spyrison Welcome This book covers is the PhD thesis during my studies at Monash University, Australia. A pdf version can be found here and the code repository can be found on github. 2022-01-02 "],["abstract.html", "Abstract", " Abstract Visualizing data space is crucial to exploratory data analysis, checking model assumptions, and validating model performance. Yet visualization quickly becomes difficult as the dimensionality of the data or features increases. Traditionally, static, low-dimensional linear embeddings are used to mitigate this complexity. Such embedded space is a lossy approximation of the full space. However, viewing many embeddings with interactive supporting views improves the information conveyed. Data visualization tours are a class of dynamic linear projections that animate many linear projections over small changes to the projection basis. Tours are categorized by the path of their bases. Manual tours allow for User-Controlled Steering (UCS) of bases path, where the contributions of individual variables can be controlled. I create a free, open-source R package, spinifex, that facilitates creating such tours. These manipulations of the variables can be precomputed or made in real-time. Display composition and exportable formats are interoperable with the existing package tourr and can be rendered with recent graphics interfaces plotly and gganimate. The former offers interactive use with HTML widgets, while the latter can render to static formats such as .gif or .mp4 files. An interactive application is included to illustrate the use of the manual tour. Theoretically, the UCS of the manual tour should enable an analyst to better explore the variable attribution to the structure identified in an embedding. I find strong evidence to support that radial tour leads to a significant and large increase in accuracy as compared with Principal Component Analysis (PCA) and an alternative tour variant, the grand tour. I conduct a within-participant, crowd-sourced user study comparing these visualization methods. Each of the \\(n=108\\) participants performs two trials with each visual for 648 total trials. The task is a supervised classification problem asking participants which variables attribute to the separation of 2 clusters. Modern modeling techniques are sometimes referred to as black-box models due to the uninterpretable nature of model terms which are often many and non-linear. Recent research in Explainable Artificial Intelligence (XAI) tries to bring interpretability to these models through local explanations. Local explanations are a class of techniques that approximate the linear-variable importance at one point in the data. I build an cheem, an R package to streamline model and local explanation preprocessing, and two novel visuals. First the global view pits the data- and explanation-spaces side-by-side with a residual plot. Interactive features such as linked bushing and tooltips aid in identifying observations to compare. The local explanation from the selected observation becomes a basis used in creating the radial tour. This allows an analyst to evaluate the explanation and explore the sensitivity of the explanation to changes in the variable contribution. "],["acknowledgments.html", "Acknowledgments", " Acknowledgments I would like to express my sincere gratitude to my supervisors, professor Kimbal Marriott and professor Dianne Cook, for their support of my Ph.D studies and research, their subject expertise, and their careers of supervising and teaching in addition to performing research. Thank you for continuously pushing me and my research to new levels. I have enjoyed teaching data visualization, which has been strongly shaped by Dis practical, data-first, visualization-often pragmatic approach. I will continue to hearing Kims persistent question what do we learn from this? as a reminder not to get lost in the details of implementation, but also to regularly step back and analyze if this is the correct object to change. A special thanks to professor Przemyslaw Biecek for giving his input in the formulation stages of my project and his easy-to-understand explanations of complex modeling aspects. Thank you for responding to cold emails and being available for collaboration. I thank my fellow Ph.D students, lab members, and Pomodoro partners especially on the occasional of stimulating discussions and for the positive peer pressure of knowing others are around and working. Thanks immensely to those who empathized with me and others, especially through the hardships of studies and COVID-19. Gratitude to Ying Zhou for her enduring support through the thick of my studies and wavering mental health. Last but not least, I would like to thank my parents, Doug and Terry, for their support and concerns at odd hours of the day. Thanks to Alan and Claire for their companionship and support now and in our more formative years. I am looking forward to seeing you all in person shortly. "],["preface.html", "Preface", " Preface This thesis has been written using R Markdown with the bookdown package (Xie 2016). All materials required to compile the thesis are available at https://github.com/nspyrison/thesis_monash_phd. I recognize that terminology is often overburdened by ambiguous use, with several changing meanings coming from different fields. My background comes from Statistics and I will default to terms from statistics and geometry. Chapter has been published in The R Journal. Chapters and have not been submitted yet. "],["1-ch-introduction.html", "Chapter 1 Introduction 1.1 Research questions 1.2 Methodology 1.3 Contributions 1.4 Background 1.5 Thesis structure", " Chapter 1 Introduction Exploratory Data Analysis (EDA) is the process of the initial summarization and visualization of a dataset. This is a critical first step of checking for realistic values, finding improper data formats, and revealing insights (Tukey 1977). Early and frequent data visualization is key to the data analysts workflow cycle (Hadlet Wickham and Grolemund 2017). As modern datasets grow in complexity use of multivariate data is ubiquitous. The number of variables in the data increases the difficulty of creating and portraying an accurate representation of the data, which is central to the iterated workflow. Figure 1.1: Data analysis workflow (Hadlet Wickham and Grolemund 2017). This work focuses primary on multivariate data visualization, but also facilitates transforming data and interpretation of models. Early attempts at high-dimension visuals in scatterplot matrices (Chambers et al. 1983) and parallel coordinate plots (Ocagne 1885). Principal component analysis (PCA, Pearson (1901)) reorients the basis to components, linear combinations of the original variables ordered by descending amount of variation explained. These components are typically viewed as discrete orthogonal pairs. A data visualization tour (Cook et al. 2008; S. Lee et al. 2021) is a class of linear projections that animate small changes to the projection basis. Intuitively, they show a projection of the data object down to lower-dimensional space in the same way that a 3D object casts a 2D shadow. A key feature of the tour is the persistence and tractability of the points through many frames. In the shadow analogy an object, such as a bar stool may be casting a circular shadow that could come from any number of shapes. However, if the stool were rotated, the legs would show in the shadow quickly giving an intuitive interpretation of the object. Similarly, looking at a data object over the rotation of its variables yields information about its structure. In this way and aided with linked brushing and other interactions, such continuous tours excel at extending the interpretability of multivariate spaces. Chapter walks through some of the previous alternatives and why we ultimately continue with this class of animated linear dimension reduction. Component spaces and tours optimize for specific objectives or are selected randomly. None of the previous methods allow for an analyst to control the contributions of variables to the basis. This is a crucial component for human-in-the-loop analysis (Karwowski 2006). If the analyst wants to explore what happens to the structure if one variable were removed or contribution of another was increased they had no way to do so. 1.1 Research questions The over-arching question of interest can be stated as: Can the radial tour with user interaction help analysts understand linear projections, and explore the sensitivity of structure in the projection to the variables contributing to the projection? Understanding variable sensitivity to the structure in a projection frame is crucial factor analysis after identifying a feature of interest. If an identified feature is the what of an analysis then its variable attributions are its how. The user interaction afforded by the radial tour should allow for a more precise exploration of this structure. RQ 1. How do we define user interaction for the radial tours to add and remove variables smoothly from a 2D linear projection of data? Neither component spaces nor grand tour provide a means for changing the contributions of a desired variable. To facilitate variable interaction, we need to have a means of manipulating the basis. This is crucial to explore the sensitivity of the variable contributions to the structure in a frame. RQ 2. Does the use of the radial tour improve analysts understanding of the relationship between variables and structure in 2D linear projections? How can we be sure that having a means of control leads to a meaningfully better analysis? Comparing alternative methods should lend insight into which methods perform well under specific tasks. RQ 3. Can the radial tours be used in conjunction with the local explanation, SHAP, to improve the interpretability of black-box models? The tension from the trade-off between accuracy and interpretability of black-box models is rising. There is a clear need to be able to explain black-box models. After extrapolating local explanations of all observations, we want to explore that space with the help of the radial tour. 1.2 Methodology The research corresponding with RQ #1 entails algorithm/software design adapting the algorithm from Cook and Buja (1997). This allows for interactive control of 2D projections and serves as a foundation for the remaining work. To address RQ #2, a controlled experimental study has explored the efficacy of interactive radial tours as compared with two benchmark methods: Principal Component Analysis (PCA, Pearson (1901)) and the grand tour (Asimov 1985). This was a within-participant user study where each participant experienced each visual. Trials were balanced across three other experimental factors: location of the signal, the shape of the cluster distributions, and the dimensionality of the data. Ethics approval was obtained for this work. The approval and disclosure forms are available at the project repository: https://github.com/nspyrison/spinifex_study/tree/master/ethics. The research for RQ #3 involves fundamental visualization design. We know that the SHAP value is a local explanation for one observation. This SHAP value will also serve as the 1D basis for the radial tour. While using SHAP as a projection basis is novel, it is not particularly insightful by itself. With the radial tour we can change variable contributions. We also provide linkage information, the within-class distributions of the SHAP components as parallel coordinate marks on the basis. We also offer a global view and related statistics to map to color to aid in exploring the sensitivity of the SHAP-space relative to the sensitivity of the original data space. 1.3 Contributions spinifex, a package offering a consistent framework for performing radial tours and the rendering of any tours to various formats: Perform radial tours to explore the variable sensitivity to structure Transform numeric variable in the data Extract various bases exposing features of the data Interoperable with tours generated with tour (Hadley Wickham et al. 2011) Layered interface for producing tours that mirror the layered approach of ggplot2 (Hadley Wickham 2016) A user study comparing the efficacy of the radial tour against the alternatives of PCA the grand tour includes: Creation of supervised classification task to assess the variable attribution to the separation of clusters performed under various levels of experimental factors: location, shape, and dimensionality. Definition of an accuracy measure to evaluate this task. Results: strong evidence that the radial tour increases the accuracy of this task by a sizable amount while the task is performed fastest with the grand tour. Attribution of the error by performing a mixed model regression helps to explain the source of the error term into the variability of participants skill aptitude for this task and variability of the difficultly of a simulation by random chance. Introduces an interactive application to preprocess data and explore. Users can choose from six supplied datasets or upload their own. cheem, a package applying the radial tour to local explanations of black-box models, including: Preprocessing; creation of a random forest model, the extraction of all observations tree SHAP local explanation, and extraction of other statistics for display. Visualization of approximations of the data- and attribution-space side-by-side with linked brushing, hover tooltips, and tabular display of selected points. Evaluating the local explanations with the use of the radial tour we can explore the sensitivity to the structure identified better see what variable support the explanation holds realistic. 1.4 Background This section starts with setting the scope for the type of data we are focusing on, gives a brief motivation then works through previous multivariate visualizations and their scalability. By the end, the focus narrows to linear projections, and in particular, the class of animated linear projections known as the tour. For our purposes I will be focusing on the case where data \\(X_{nxp}\\) contains \\(n\\) observations of \\(p\\) variables, is complete with no missing values, variables are numeric (ideally not ordinal levels), and \\(n&gt;p\\) typically many more observations than variables. While I write as though always operating on the original variable space these methods could similarly be applied to feature decomposition of data not fitting this description. In the case of the linear projection let, \\(Y_{nxd} = X_{nxp} * A_{pxd}\\) be the embedding of the data mapped by the basis \\(A\\), where \\(d&lt;p\\). When \\(p\\) is large, say over 10 or 20 variables, the viewing space is quite large. In these cases, a PCA initialization step is commonly used where the variables are approximated as fewer principal components, and this reduced space can be viewed, albeit with the disadvantage of having another linear mapping back to the original space. Hadley Wickham, Cook, and Hofmann (2015) also view model spaces and features while urging to have a preference for visualizing data-space directly. Visualization is much more robust than numerical summarization alone (Anscombe 1973; Matejka and Fitzmaurice 2017). In these studies, data sets have the same summary statistics, yet contains obvious visual trends and shapes that could go completely unheeded if plotting is foregone. Data visualization is fundamental to EDA and quickly evaluating data supports ensuring that models are suitable. Figure 1.2: Starting from the profile of a dinosaur, observations are allowed to drift (by iterated simulated annealing) toward 12 patterns provided that they stay close to the original statistics (Matejka and Fitzmaurice 2017). Visualization of data yields stark patterns that are easy to miss in numerical summarization. 1.4.1 Scatterplot matrices The work in Grinstein, Trutschl, and Cvek (2002) gives a good taxonomy of high-dimensional visualization. We will follow a few examples building up to why we conclude with tour methods. Broadly speaking, we are concerned with the question How can an analyst visualize arbitrary \\(p-\\) dimensions? To illustrate some of the options for data I use the penguins data(Gorman, Williams, and Fraser 2014, horst_palmerpenguins_2020). It contains 333 observations of four physical measurements across three species of penguins observed near Palm Station, Antarctica. Viewing as many univariate histograms or density curves is one method. Similarly, one could look at all variable pairing as scatter plots. This forms the crux of the scatterplot matrices, also known as SPLOM (Chambers et al. 1983). In a scatterplot matrix, variables are displayed across the columns and rows, the diagonal elements show the univariate densities while off-diagonal positions show scatterplot pairs. This is useful for getting a handle on the support and shapes of the variables, but is not going to scale well with dimension and is not a suitable audience-ready display as it is very busy and doesnt draw attention to any one spot. Munzner reminds us to abstract all of the cognitive work out of the visual, allowing the audience to focus on seeing the evidence supporting the claim (Munzner 2014). Figure 1.3: (ref:penguinsmplom-cap) 1.4.2 Parallel coordinate plots Alternatively, we could consider a class of observation-based visuals. In parallel coordinate plots (Ocagne 1885) variables are arranged horizontally and observations are connected by lines with the height mapping to the quantile or z-value for each variable. This scales much better with dimensions but poorly with observations. It also suffers from an asymmetry with the variable order, that is, changing the order of the variable will lead people to very different conclusions. The x-axis is also used to display variables rather than the values of the observations. This restricts the amount of information that can be interpreted between variables. Munzner asserts that position is the more human-perceptible channel for encoding information; we should like to reserve it for the values of the observations. The same issues persist across other observation-based displays such as radial variants, pixel-oriented visuals, and Chernoff faces (Keim 2000; Chernoff 1973). These visuals are better suited for the \\(n&lt;p\\) case with more variables than observations. Figure 1.4: Parallel coordinate plots of penguins data. Does not scale well with observations and suffers from asymmetry with the variable ordering, and horizontal position is used for variable rather than observation levels. 1.4.3 Dimension reduction Ultimately, we will need to turn to dimension reduction to create a compelling visual allowing audiences to focus on features with contributions from multiple variables. Dimension reduction is separated into two categories, linear and non-linear. The linear case spans all affine mathematical transformations, essentially any mapping where parallel lines stay parallel. Non-linear transformations are the complement of the linear case, think transformations containing exponents or interacting terms. Examples in low dimensions are relatable. For instance, shadows are examples of linear projections where a 3-dimensional object casts a 2D projection, the shadow. Our vision at any one instance of time, or a picture, are also a 2D projections. An example of a non-linear transformation is that of 2D representation of the globe. There are many different ways (and features to optimize) to distort the surface to display as a map. The most common may be rectangular displays where the area is distorted more and more with the distance away from the equator. Other distortions are created when the surface is unwrapped as a long ellipse. Yet others create non-continuous gaps in oceans to minimize the distortion of countries. Non-linear techniques often have hyperparameters that affect how the spaces are distorted to fit into a fewer dimensions. To quote Anastasios Panagiotelis, All non-linear projections are wrong, but some are useful, a play on George Boxs quote about models. Non-linear techniques distort the space in unclear ways, and what is more, they can introduce features not in the data depending on the selection of hyperparameters. The presence of structure in a non-linear model is necessary but not sufficient to conclude the existence of a structure in the data. Unfortunately, there is no free lunch here. An increase in the original data dimensions will lead to a \\(p-d\\)-dimensional viewing space in the linear case, and an increasingly perturbed and distorted space in non-linear techniques. The intrinsic dimensionality of data is the number of variables needed to minimally represent the data (Grinstein, Trutschl, and Cvek 2002). This is an important aspect of dimension reduction that does not have to end in visual, but is also a common part of factor analysis and preprocessing data. Consider a Psychology survey consisting of 100 questions about the Big Five personality traits. The data consists of 100 variables, while the theory would suggest the intrinsic dimensionality is five. The data likely picks up on other aspects and may better be summarized in with eight or ten dimensions. If this were the case, reducing the data to this space would be necessary to gate the exponentially increasing view time. 1.4.4 Tours, animated linear projections A single linear projection is a resulting space from the data multiplied by the basis where the basis is an orthonormal matrix (the orientation of the unit origin) mapping the data space to a lower dimension. A data visualization tour animates many such projections through small changes in the basis. In the bar stool shadow analogy, structural information about a hidden object was gained by watching its shadow change due to its rotation. An analyst similarly gains information about the data object by watching continuous changes to the basis (the rotation of the data). Originally in a grand tour (Asimov 1985) several target frames are randomly selected and then interpolated along their geodesic path. Figure 1.5: Illustration of the grand tour selecting random target frames (grey) connected via geodesically interpolated frame (white). Figure from Buja et al. (2005). There are various types of tours which are classified by the generation of their basis paths. A guided tour uses simulated annealing to move progressively closer to an objective function in the embedded space (Hurley and Buja 1990). A more comprehensive discussion and review of tours can be found in the works of Cook et al. (2008) and S. Lee et al. (2021). Tours are used for a couple of salient features: maintains transparency back to the original variable space, and the persistence data points from frame to frame convey more information than looking at discrete jumps to other bases. Because of these features, tours are a good method to extend the visualization of data space as dimensionality increases. The work below covers manual tours (Cook and Buja 1997; Spyrison and Cook 2020) in Chapter . Radial tours are one type of manual tour that where the contribution of one variable is extended radially to a full contribution, removed completely, then restored to its original contribution. Chapter compares the efficacy of the radial tour as compared with PCA and the grand tour in a user study. Lastly, Chapter extends the use of the radial tour to evaluate the local explanation of black-box models. 1.5 Thesis structure The remainder of the thesis is organized as follows: Chapter discusses the theory and implementation of the manual tour in the package spinifex. Chapter discusses a user study evaluating the efficacy of the radial, manual tour as compared with PCA and the grand tour. There is ample evidence that using the radial tour increases the accuracy of responses for the supervised variable-attribution task describing the separation between two variables. Chapter extends the use of manual tours to improve the interpretability of non-linear models. Where manual tours explore variable sensitivity to the structure identified in local explanations of the model. Lastly, Chapter concludes with some takeaways and a discussion of possible extensions. "],["2-ch-spinifex.html", "Chapter 2 spinifex: an R package for creating user-controlled animated linear projections 2.1 Introduction 2.2 Algorithm 2.3 Package structure 2.4 Use cases 2.5 Discussion 2.6 Acknowledgments", " Chapter 2 spinifex: an R package for creating user-controlled animated linear projections This chapter introduces manual tours that allows analysts to influence the contributions to a projection. This feature is absent from previous linear embeddings. This work has changed from its publication, primarily to incorporate and discuss the subsequent ggproto API that extends the flexibility of the geometric displays of tours. Dynamic low-dimensional linear projections of multivariate data known as tour provide an essential tool for exploring multivariate data and models. The R package tourr provides functions for several types of tours: grand, guided, little, local, and frozen. Each of these can be viewed in a development environment, or their basis array can be saved for later consumption. This paper describes a new package, spinifex, which provides a manual tour of multivariate data. In a manual tour an analyst controls the contribution of a variable to the projection. Controlled manipulation is important to explore a variables sensitivity to structure of an identified feature. The use of the manual tour is applied to particle physics data to illustrate the sensitivity of structure in a projection to specific variable contributions. Additionally, we create a ggproto API for composing any tour that mirrors the layered additive approach of ggplot2. Tours can then be animated and exported to various formats with plotly or gganimate. 2.1 Introduction Exploring multivariate spaces is a challenging task, increasingly so as dimensionality increases. Traditionally, static low-dimensional projections are used to display multivariate data in two dimensions, including principal component analysis, linear discriminant spaces or projection pursuit. These are useful for finding relationships between multiple variables, but they are limited because they show only a glimpse of the high-dimensional space. An alternative approach is to use a tour (Asimov 1985) of dynamic linear projections to look at many different low-dimensional projections. Tours can be considered to extend the dimensionality of visualization, which is important as data and models exist in more than three dimensions. The package tourr (Hadley Wickham et al. 2011) provides a platform for generating tours. It can produce a variety of tours, each paired with a variety of possible displays. A user can make a grand, guided, little, local or frozen tour, and display the resulting projected data as a scatterplot, density plot, histogram, or even as Chernoff faces if the projection dimension is more than 3. This work adds a manual tour to the collection. The manual tour was described in Cook and Buja (1997) and allows a user to control the projection coefficients of a selected variable in a 2D projection. The manipulation of these coefficients enable the analyst to explore their sensitivity to the structure within the projection. As manual tours operate on only one variable, they are particularly useful once a feature of interest has been identified. One way to identify interesting features is using a guided tour (Cook et al. 1995). Guided tours select a very specific path, which approaches a projection that optimizes an objective function. The optimization used to guide the tour is simulated annealing (Kirkpatrick, Gelatt, and Vecchi 1983). The direct optimization of a function allows guided tours to rapidly identify interesting projection features given the relatively large parameter-space. After a projection of interest is identified, an analyst can then use the finer brush of the manual tour to control the contributions of individual variables to explore the sensitivity they have on the structure visible in the projection. The paper is organized as follows. Section 2.2 describes the algorithm used to perform a radial manual tour implemented in the package spinifex. Section 2.3 discussed the functions, their usage composing tours with ggplot2 (Hadley Wickham 2016) and their animation by plotly (Sievert 2020) or gganimate (Pedersen and Robinson 2020). Package functionality and code usage following the order applied in the algorithm follows in section 2.3.2. Section 2.4 illustrates how this can be used for sensitivity analysis applied to multivariate data collected on high-energy physics experiments (Wang et al. 2018). Section 2.5 summarizes this paper and discusses potential future directions. 2.2 Algorithm The algorithm to conduct a manual tour interactively by recording mouse/cursor motion is described in detail in Cook and Buja (1997). Movement can be in any direction and magnitude, but it can also be constrained in several ways: radial: fix the direction of contribution, and allow the magnitude to change. angular: fix the magnitude, and allow the angle or direction of the contribution to vary. horizontal, vertical: allow rotation only around the horizontal or vertical axis of the current 2D projection. The algorithm described here produces a radial tour as an animation sequence. It takes the current contribution of the chosen variable, and using rotation brings this variable fully into the projection, completely removes it, before returning to the original position. 2.2.1 Notation The notation used to describe the algorithm for a 2D radial manual tour is as follows: \\(\\textbf{X}\\), the data, an \\(n \\times p\\) numeric matrix to be projected. \\(\\textbf{A}\\), any orthonormal projection basis, \\(p \\times d\\) matrix, describing the projection from \\(\\mathbb{R}^p \\Rightarrow \\mathbb{R}^d\\). \\(k\\), is the index of the manipulation variable or manip var for short. \\(\\textbf{e}\\), a 1D basis vector of length \\(p\\), with 1 in the \\(k\\)-th position and 0 elsewhere. \\(\\textbf{M}\\) is a \\(p \\times 3\\) matrix, defining the 3D subspace where data rotation occurs and is called the manip(ulation) space. \\(\\textbf{R}\\), the \\(d+1\\)-D rotation matrix, for performing unconstrained 3D rotations within the manip space, \\(\\textbf{M}\\). \\(\\theta\\), the angle of in-projection rotation, for example, on the reference axes; \\(c_\\theta, s_\\theta\\) are its cosine and sine. \\(\\phi\\), the angle of out-of-projection rotation, into the manip space; \\(c_\\phi, s_\\phi\\) are its cosine and sine. The initial value for animation purposes is \\(\\phi_1\\). \\(\\textbf{U}\\), the axis of rotation for out-of-projection rotation orthogonal to \\(\\textbf{e}\\). \\(\\textbf{Y} = \\textbf{X} \\times \\textbf{A}\\), the resulting projection of the data through the manip space, \\(\\textbf{M}\\), and rotation matrix, \\(\\textbf{R}\\). The algorithm operates entirely on projection bases and incorporates the data only when making the projected data plots in light of efficiency. 2.2.2 Steps 2.2.2.1 Step 0) Setup The flea data (Lubischew (1962)), available in the tourr package, is used to illustrate the algorithm. The data contains 74 observations of six variables, physical measurements of flea beetles. Each observation belongs to one of three species. An initial 2D projection basis must be provided. A suggested way to start is to identify an interesting projection using a projection pursuit guided tour. Here the holes index is used to find a 2D projection of the flea data, which shows three separated species groups. Figure 2.1 shows the initial projection of the data. The left panel displays the projection basis (\\(\\textbf{B}\\)) and can be used as a visual guide of the magnitude and direction that each variable contributes to the projection. The right panel shows the projected data, \\(\\textbf{Y}_{[n,~2]} ~=~ \\textbf{X}_{[n,~p]} \\textbf{B}_{[p,~2]}\\). The color and shape of points are mapped to the flea species. Figure 2.1: Biplot of the initial 2D projection: representation of the basis (left) and resulting data projection (right) of standardized flea data. The color and shape of data points are mapped to the species of flea beetle. The basis was produced by a projection pursuit guided tour with the holes index. The contribution of the variables aede2 and tars1 approximately contrasts the other variables. The visible structure in the projection are the three clusters corresponding to the three species. 2.2.2.2 Step 1) Choose manip variable In figure 2.1 the contribution of the variables tars1 and aede2 mostly contrast the contribution of the other four variables. These two variables combined contribute in the direction of the projection where the purple cluster is separated from the other two clusters. The variable aede2 is selected as the manip var, the variable to be controlled in the tour. The question that will be explored is: how important is this variable to the separation of the clusters in this projection? 2.2.2.3 Step 2) Create the 3D manip space Initialize the coordinate basis vector as a zero vector, \\(\\textbf{e}\\), of length \\(p\\), and set the \\(k\\)-th element to 1. In the example data, aede2 is the fifth variable in the data, so \\(k=5\\), set \\(e_5=1\\). Use a Gram-Schmidt process to orthonormalize the coordinate basis vector on the original 2D projection to describe a 3D manip space, \\(\\textbf{M}\\). \\[\\begin{align*} e_k &amp;\\leftarrow 1 \\\\ \\textbf{e}^*_{[p,~1]} &amp;= \\textbf{e} - \\langle \\textbf{e}, \\textbf{B}_1 \\rangle \\textbf{B}_1 - \\langle \\textbf{e}, \\textbf{B}_2 \\rangle \\textbf{B}_2 \\\\ \\textbf{M}_{[p,~3]} &amp;= (\\textbf{B}_1,\\textbf{B}_2,\\textbf{e}^*) \\end{align*}\\] The manip space provides a 3D projection from \\(p\\)-dimensional space, where the coefficient of the manip var can range completely between [0, 1]. This 3D space serves as the medium to rotate the projection basis relative to the selected manipulation variable. Figure 2.2 illustrates this 3D manip space with the manip var highlighted. This representation is produced by calling the view_manip_space() function. This diagram is purely used to help explain the algorithm. Figure 2.2: Illustration of a 3D manip space, the projection plane is shown as a blue circle extending into and out of the display. A manipulation direction is initialized, the red circle, orthogonal to the projection plane. This allows the selected variable, aede2, to change its contribution back to the projection plane. The other variables contributions rotate into this space as well, preserving the orthogonal structure, but are omitted in the manipulation dimension for simplicity. 2.2.2.4 Step 3) Defining a 3D rotation The basis vector corresponding to the manip var (red line in Figure 2.2), can be operated like a lever anchored to the origin. This is the process of the manual control, that rotates the manip variable into and out of the 2D projection (Figure 2.3). As the variable contribution is controlled, the manip space turns, and the projection onto the horizontal projection plane correspondingly changes. This is a manual tour. Generating a sequence of values for the rotation angles produces a path for the rotation of the manip space. For a radial tour, fix \\(\\theta\\), the angle describing rotation within the projection plane, and compute a sequence for \\(\\phi\\), defining movement out of the plane. This will change \\(\\phi\\) from the initial value, \\(\\phi_1\\), the angle between \\(\\textbf{e}\\) and its shadow in \\(\\textbf{B}\\), to a maximum of \\(0\\) (manip var fully in projection), then to a minimum of \\(\\pi/2\\) (manip var out of projection), before returning to \\(\\phi_1\\). Rotations in 3D can be defined by the axes they pivot on. Rotation within the projection, \\(\\theta\\), is rotation around the \\(Z\\)-axis. Out-of-projection rotation, \\(\\phi\\), is the rotation around an axis on the \\(XY\\) plane, \\(\\textbf{U}\\), orthogonal to \\(\\textbf{e}\\). Given these axes, the rotation matrix, \\(\\textbf{R}\\), can be written as follows, using Rodrigues rotation formula (originally published in Rodrigues (1840)): \\[\\begin{align*} \\textbf{R}_{[3,~3]} &amp;= \\textbf{I}_3 + s_\\phi\\*\\textbf{U} + (1-c_\\phi)\\*\\textbf{U}^2 \\\\ &amp;= \\begin{bmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\\\ \\end{bmatrix} + \\begin{bmatrix} 0 &amp; 0 &amp; c_\\theta s_\\phi \\\\ 0 &amp; 0 &amp; s_\\theta s_\\phi \\\\ -c_\\theta s_\\phi &amp; -s_\\theta s_\\phi &amp; 0 \\\\ \\end{bmatrix} + \\begin{bmatrix} -c_\\theta (1-c_\\phi) &amp; s^2_\\theta (1-c_\\phi) &amp; 0 \\\\ -c_\\theta s_\\theta (1-c_\\phi) &amp; -s^2_\\theta (1-c_\\phi) &amp; 0 \\\\ 0 &amp; 0 &amp; c_\\phi-1 \\\\ \\end{bmatrix} \\\\ &amp;= \\begin{bmatrix} c_\\theta^2 c_\\phi + s_\\theta^2 &amp; -c_\\theta s_\\theta (1 - c_\\phi) &amp; -c_\\theta s_\\phi \\\\ -c_\\theta s_\\theta (1 - c_\\phi) &amp; s_\\theta^2 c_\\phi + c_\\theta^2 &amp; -s_\\theta s_\\phi \\\\ c_\\theta s_\\phi &amp; s_\\theta s_\\phi &amp; c_\\phi \\end{bmatrix} \\\\ \\end{align*}\\] where \\[\\begin{align*} \\textbf{U} &amp;= (u_x, u_y, u_z) = (s_\\theta, -c_\\theta, 0) \\\\ &amp;= \\begin{bmatrix} 0 &amp; -u_z &amp; u_y \\\\ u_z &amp; 0 &amp; -u_x \\\\ -u_y &amp; u_x &amp; 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; -c_\\theta \\\\ 0 &amp; 0 &amp; -s_\\theta \\\\ c_\\theta &amp; s_\\theta &amp; 0 \\\\ \\end{bmatrix} \\\\ \\end{align*}\\] 2.2.2.5 Step 4) Creating an animation of the radial rotation The steps outlined above can be used to create any arbitrary rotation in the manip space. To use these for sensitivity analysis, the radial rotation is built into an animation where the manip var is rotated fully into the projection, completely out, and then back to the initial value. This involves allowing \\(\\phi\\) to vary between \\(0\\) and \\(\\pi/2\\), call the steps \\(\\phi_i\\). Figure 2.3: Select frames highlight the animation of a radial manual tour manipulating aede2: (1) original projection, (2) full contribution, (3) zero contribution, before returning to the original contribution. Set initial value of \\(\\phi_1\\) and \\(\\theta\\): \\(\\phi_1 = \\cos^{-1}{\\sqrt{B_{k1}^2+B_{k2}^2}}\\), \\(\\theta = \\tan^{-1}\\frac{B_{k2}}{B_{k1}}\\). Where \\(\\phi_1\\) is the angle between \\(\\textbf{e}\\) and its shadow in \\(\\textbf{B}\\). Set an angle increment (\\(\\Delta_\\phi\\)) that sets the step size for the animation, to rotate the manip var into and out of the projection. Uses of angle increment, rather than a number of steps to control the movement is consistent with the tour algorithm as implemented in the tourr. Step towards \\(0\\), where the manip var is entirely in the projection plane. Step towards \\(\\pi/2\\), where the manip variable has no contribution to the projection. Step back to \\(\\phi_1\\). In each of the steps 3-5, a small step may be added to ensure that the endpoints of \\(\\phi\\) (\\(0\\), \\(\\pi/2\\), \\(\\phi_1\\)) is reached. 2.2.2.6 Step 5) Projecting the data The operation of a manual tour is defined on the projection bases. Only when the data plot needs to be made the data projected into the relevant basis. \\[\\begin{align*} \\textbf{Y}^{(i)}_{[n,~3]} &amp;= \\textbf{X}_{[n,~p]} \\textbf{M}_{[p,~3]} \\textbf{R}^{(i)}_{[3,3]} \\end{align*}\\] where \\(\\textbf{R}^{(i)}_{[3,3]}\\) is the incremental rotation matrix, using \\(\\phi_i\\). To make the data plot, use the first two columns of . Show the projected data for each frame in sequence to form an animation. Tours are typically viewed as an animation. The animation of this tour can be viewed online on GitHub. The page may take a moment to load. 2.3 Package structure This section describes the functions available in the package, their usage, and how to install and get up and running. 2.3.1 Functions Table 2.1 lists the primary functions and their purpose. These are grouped into four types: processing the data, production of tour path, the composition of the tour display, and its animation. Table 2.1: Summary of primary functions. Family Function Related to Description processing scale_01/sd scale each column to [0,1]/std dev away from the mean processing basis_pca/olda/ Rdimtools::do.* basis of orthogonal component spaces processing basis_half_circle basis with uniform contribution across half of a circle processing basis_guided tourr::guided_tour silently return the basis from a guided tour tour path manual_tour basis and interpolation information for a manual tour tour path save_history tourr::save_history silent, extended wrapper returning other tour arrays display ggtour ggplot2::ggplot canvas and initialization for a tour animation display proto_point/text geom_point/text adds observation points/text display proto_density/2d geom_density/2d adds density curve/2d contours display proto_hex geom_hex adds hexagonal heatmap of observations display proto_basis/1d adds adding basis visual in a unit-circle/-rectangle display proto_origin/1d adds reference mark in the center of the data display proto_default/1d wrapper for proto_* point + basis + origin display facet_wrap_tour ggplot2::facet_wrap facets on the levels of variable display append_fixed_y add/overwrite a fixed vertical position animation animate_plotly plotly::ggplotly render as an interactive hmtl widget animation animate_gganimate gganimate::animate render as a .gif, .mp4, or other video format animation filmstrip static gpplot faceting on the frames of the animation 2.3.2 Usage Using the penguins data , available in the package, to illustrate a manual tour, we will illustrate generating a manual tour to explore the sensitivity of a variable separating two clusters. The composition of the tour display echos the additive layered approach of ggplot2, while abstracting away the complexity of dealing with changing number of frames and their animation. ## Process penguins data dat &lt;- scale_sd(penguins[1:4]) clas &lt;- penguins$species bas &lt;- basis_olda(data = dat, class = clas) ## The tour path of the bases mt_path &lt;- manual_tour(basis = bas, manip_var = 1, data = dat) ## Composing the display of the tour ggt &lt;- ggtour(mt_path, angle = .15) + proto_point(aes_args = list(color = clas, shape = clas), identity_args = list(alpa = .8, size = 1.5)) + proto_basis(&quot;left&quot;) + proto_origin() ## Animating animate_plotly(ggt, fps = 10) 2.3.3 Installation The spinifex is available from CRAN, the following code will help to get up and running: # Installation: install.package(&quot;spinifex&quot;) ## Install from CRAN library(&quot;spinifex&quot;) ## Load into session # Getting started: ## Shiny app for visualizing basic application run_app(&quot;intro&quot;) ## View the code vignette vignette(&quot;getting_started_with_spinifex&quot;) ## More about proto_* functions vignette(&quot;ggproto_api&quot;) 2.4 Use cases Wang et al. (2018) introduce a new tool, PDFSense, to visualize the sensitivity of hadronic experiments to nucleon structure. The parameter-space of these experiments lies in 56 dimensions, and are approximated as the ten first principal components. Cook, Laa, and Valencia (2018) illustrates how to learn more about the structures using a grand tour. Tours can better resolve the shape of clusters, intra-cluster detail, and better outlier detection than PDFSense &amp; TFEP (TensorFlow embedded projections) or traditional static embeddings. This example builds from here, illustrating how the manual tour can be used to examine the sensitivity of structure in a projection to different parameters. The specific 2D projections passed to the manual tour were provided in their work. The data has a hierarchical structure with top-level clusters; DIS, VBP, and jet. Each cluster is a particular class of experiments, each with many experimental datasets which each have many observations of their own. In consideration of data density, we conduct manual tours on subsets of the DIS and jet clusters. This explores the sensitivity of the structure to each of the variables in turn and we present the subjectively best and worst variable to manipulate for identifying dimensionality of the clusters and describing the span of the clusters. 2.4.1 Jet cluster The jet cluster resides in a smaller dimensionality than the full set of experiments, with four principal components explaining 95% of the variation in the cluster (Cook, Laa, and Valencia 2018). The data within this 4D embedding is further subset to ATLAS7old and ATLAS7new, to focus on two groups that occupy different parts of the subspace. Radial manual tours controlling contributions from PC4 and PC3 are shown in Figures 2.4 and 2.5, respectively. The difference in shape can be interpreted as the experiments probing different phase spaces. Back-transforming the principal components to the original variables can be done for a more detailed interpretation. When PC4 is removed from the projection (Figure 2.4), the difference between the two groups is removed, indicating that PC4 is essential for the separation of experiments. However, eliminating PC3 from the projection (Figure 2.5) does not affect the structure, meaning PC3 is not important for distinguishing experiments. Animations for the remaining PCs can be viewed at the following links: PC1, PC2, PC3, and PC4. It can be seen that only PC4 is important for viewing the difference in these two experiments. Figure 2.4: Select frames from a radial tour of PC4 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When PC4 is removed from the projection (frame 10), there is little difference between the clusters, suggesting that PC4 is important for distinguishing the experiments. Figure 2.5: Frames from the radial tour manipulating PC3 within the jet cluster, with color indicating experiment type: ATLAS7new (green) and ATLAS7old (orange). When the contribution from PC3 is changed, there is little change in the separation of the clusters, suggesting that PC3 is not important for distinguishing the experiments. 2.4.2 DIS cluster Following Cook, Laa, and Valencia (2018), to explore the DIS cluster, PCA is recomputed and the first six principal components, explaining 48% of the full sample variation, are used. The contributions of PC6 and PC2 are explored in Figures 2.6 and 2.7, respectively. Three experiments are examined: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). Both PC2 and PC6 contribute to the projection similarly. When PC6 is rotated into the projection, variation in the DIS HERA1+2 is greatly reduced. When PC2 is removed from the projection, dimuon SIDIS becomes more distinct. Even though both variables contribute similarly to the original projection their contributions have quite different effects on the structure of each cluster, and the distinction between clusters. Animations of all of the principal components can be viewed from the links: PC1, PC2, PC3, PC4, PC5, and PC6. Figure 2.6: Select frames from a radial tour exploring the sensitivity that PC6 has on the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). DIS HERA1+2 is distributed in a cross-shaped plane, and charm SIDIS occupies the center of this cross, and dimuon SIDIS is a linear cluster crossing DIS HERA1+2. As the contribution of PC6 is increased, DIS HERA1+2 becomes almost singular in one direction (frame 5), indicating that this cluster has very little variability in the direction of PC6. Figure 2.7: Frames from the radial tour exploring the sensitivity PC2 to the structure of the DIS cluster, with color indicating experiment type: DIS HERA1+2 (green), dimuon SIDIS (purple), and charm SIDIS (orange). As the contribution of PC2 is decreased, dimuon SIDIS becomes more distinguishable from the other two clusters, indicating that in the absence of PC2 is important for separating this cluster from the others. 2.5 Discussion Dynamic linear projections of numeric multivariate data, tours, play an important role in data visualization; they extend the dimensionality of visuals to peek into high-dimensional data and parameter spaces. This research has taken the manual tour algorithm, specifically the radial rotation, used in GGobi (Swayne et al. 2003) to interactively rotate a variable into or out of a 2D projection, and modified it to create an animation that performs the same task. It is most useful for examining the importance of variables and how the structure in the projection is sensitive or not to specific variables. This functionality is made available in the package spinifex. Which also extends the geometric display and export formats interoperable with the tourr package. This work was motivated by problems in physics, and thus the usage was illustrated on data comparing experiments of hadronic collisions to explore the sensitivity of cluster structure to different principal components. These tools can be applied quite broadly to many multivariate data analysis problems. The manual tour is constrained in the sense that the effect of one variable is dependent on the contributions of other variables in the manip space. However, this can be useful to simplify a projection by removing variables without affecting the visible structure. Defining a manual rotation in high dimensions is possible using Givens rotations and Householder reflections as outlined in Buja et al. (2005). This would provide more flexible manual rotation but more difficult for a user because they have the choice (too much choice) of which directions to move. Another future research topic could be to extend the algorithm for use on 3D projections. With the current popularity and availability of 3D virtual displays, this may benefit the detection and understanding of the higher dimensional structure or enable the examination of functions. Having a graphical user interface would be useful for making it easier and more accessible to a general audience. This is possible to implement using shiny (Chang et al. 2020). The primary purposes of the interface would be to allow the user to interactively change the manip variable easily and the interpolation step for more or less detailed views. 2.6 Acknowledgments This article was created in R, using knitr (Xie 2020) and rmarkdown (Allaire et al. 2020), with code generating the examples inline. The source files for this article be found at github.com/nspyrison/spinifex_paper/. The animated gifs can also be viewed at this site. The source code for the spinifex package can be found at github.com/nspyrison/spinifex/. "],["3-ch-efficacy_radial_tour.html", "Chapter 3 The benefit of user-controlled radial tour for understanding variable contributions to structure in linear projections 3.1 Introduction 3.2 Background 3.3 User study 3.4 Results 3.5 Response time regression 3.6 Conclusion 3.7 Accompanying tool: radial tour application 3.8 Acknowledgments 3.9 Appendix", " Chapter 3 The benefit of user-controlled radial tour for understanding variable contributions to structure in linear projections THE CHAPTER IS NOW SLIGHTLY OUTDATED, Bring content over again after Intro changes and proofreading. Now we have the means to perform radial tours. Should we be confident that this method with user control will lead to better analysis than traditional alternatives? This chapter discusses the user study to elucidate the efficacy of the radial tour. Principal component analysis is a long-standing go-to method for exploring multivariate data. Data visualization tours are a class of linear projections animated over small changes in the projection basis. The radial tour is one instance that rotates the contribution of a select variable. Does this variable-level control help an analyst explore multivariate data? This paper describes a user study evaluating the efficacy of using the radial tour in comparison to two existing methods, principal component analysis, and the grand tour. We devise a supervised classification task where participants evaluate variable attribution of the separation between two classes. Accuracy and response time are measured as response variables. Data were collected from 108 crowdsourced participants, who performed two trials of each visual for 648 trials in total. There is strong evidence that the radial tour increases accuracy. Participants also preferred to use the radial tour over alternatives for this task. 3.1 Introduction Multivariate data is ubiquitous. Exploratory Data Analysis (EDA, Tukey 1977) is essential for understanding the data and testing model assumptions. Data visualization is more robust and informative than statistical summarization alone (Anscombe 1973; Matejka and Fitzmaurice 2017). Focusing on hypothesis testing can result in tunnel vision of an analyst, causing them to miss visual particularities in the data (Yanai and Lercher 2020). Data visualization is integral to EDA and our comprehension of the data. But how do we know which methods to use to visualize data best? Models are becoming increasingly complex models involving many features and terms causing an opaqueness to their interpretability. Exploratory Artificial Intelligence (XAI, Adadi and Berrada (2018); Arrieta et al. (2020)) attempt to make black-box models more transparent by offering techniques to increase their interpretability. Multivariate data visualization is a similarly important part of exploring features spaces and communicating interpretations of models (Biecek 2018; Biecek and Burzykowski 2021; Hadley Wickham, Cook, and Hofmann 2015). Dimension reduction is commonly used with visualization to provide informative low-dimensional summaries of high-dimensional data. There have been several user studies for dimension reduction comparing across embeddings and display dimensionality (Gracia et al. 2016; Wagner Filho et al. 2018). There are also empirical metrics and comparisons used to describe non-linear reduction and how well and faithfully they embed the data (Bertini, Tatu, and Keim 2011; Liu et al. 2017; Sedlmair, Munzner, and Tory 2013; Maaten and Hinton 2008). There is an absence of studies comparing techniques for assessing variable attribution across visualization methods. This paper describes a crowdsourced (by prolific.co), user study conducted to assess the efficacy of different visualization methods. Cluster data is simulated under several additional experimental factors, namely: location, shape, and dimensionality. We task participants with identifying the variables attributing to the separation between two clusters. We define an accuracy measure for this task and use response time as a response variable of secondary interest. We perform mixed-model regression on these measures and find radial tour has strong evidence for a large improvement in accuracy from using radial tour over alternatives Principal Component Analysis (PCA). We also find evidence for relatively small differences in response time with PCA being the fastest then grand then radial. The paper is structured as follows. Section 3.2 discusses several visualization methods, including the ones compared in the study. Section 3.3 describes the experimental factors, tasks, and evaluation measures used. The results of the study are discussed in Section 3.4. Conclusions and potential future directions are discussed in Section 3.6. The software used for the study is described in Section 3.7. 3.2 Background Here, we discuss common multivariate techniques, including the methods before settling on PCA, grand tour, and the radial, manual tour. 3.2.1 Scatterplot matrix One could consider looking at \\(p\\) histograms or univariate densities. This will miss features in two or more dimensions. Similarly, all combinations of variables can be viewed as a scatterplot matrix (Chambers et al. 1983). Figure 3.1 shows the first three components of simulated data as a scatterplot matrix. Looking at \\(p\\) univariate densities or many bivariate scatterplots at once quickly becomes burdensome as dimensionality increases, and only displays information containing in 2 orthogonal dimensions, that is features that require in three dimensions will never be resolved. 3.2.2 Parallel coordinates plot Another common way to display multivariate data is with a parallel coordinates plot (Ocagne 1885), which shows observations by their quantile values for each variable with connected by lines to the quantile value in subsequent variables. Parallel coordinates plot and other observations-based visuals such as pixel plots or Chernoff faces scale well with the number of dimensions but poorly with observations. These are perhaps best used when there are more variables than observations. Observations-based visuals have a couple of issues. One is that they are asymmetric across variable ordering which can lead to different conclusions or features being focused on due to variable order. Another notable issue of observations-based visuals is the graphical channel used to convey information. Munzner suggests that position is the visual channel that is most perceptible by human perception (Munzner 2014). In the case of parallel coordinates plots, the horizontal axes span variables rather than the values of one variable. That is the loss of using an axis, our most discerning visual channel. 3.2.3 Principal component analysis PCA is a good baseline of comparison for linear projections because of its frequent and broad use across disciplines. Principal component analysis (Pearson 1901) finds new components, a linear combinations of the original variables, ordered by decreasing variation. While the full dimensionality is intact, the benefit comes from the ordered nature of the components. The data is said to be approximated but the first several components, the exact number typically being subjectively selected given the variance contained by each dimension. Figure 3.1: Scatterplot matrix of the first four principal components simulated data in six dimension. An analyst would have to view PC1 by PC2 and PC1 by PC4 to have a thorough take on which variables attribute to the separation between clusters. 3.2.4 Animated linear projections, tours A data visualization tour animates many linear projections over small changes in the projection basis. One of the insightful features of the tour is the object permanence of the data points; one can track the relative changes of observations as the basis moves, as opposed to discretely jumping to an orthogonal view with no intermediate information. Types of tours are distinguished by the selection of their basis paths (S. Lee et al. 2021; Cook et al. 2008). To contrast with the discrete orientations of PCA, we compare with continuous changes of linear projection with grand and radial tours. 3.2.4.1 Grand tours In a grand tour (Asimov 1985), the target bases are selected randomly. The grand tour is the first and most widely known tour. The random selection of target bases makes it a general unguided exploratory tool. It will make a good comparison that has continuity of data points in nearby frames along with the radial tour but lacks the user control enjoyed by PCA and radial tours. 3.2.4.2 Manual and radial tours Whether an analyst uses a component space or the grand tour they have no way of influencing the basis. They cannot explore the structure identified or change the contribution of the variables. This means of user-control-steering is a key aspect of manual tours that should facilitate testing variable attribution. The manual tour (Cook and Buja 1997) defines its basis path by manipulating the basis contribution of a selected variable. A manipulation dimension is appended onto the projection plane, with a full contribution given to the selected variable. The target bases are then chosen to rotate this newly created manipulation space. The target bases are then similarly orthogonally restrained, the data is projected through interpolated frames and rendered into an animation. For the variables to remain independent of each other, the contributions of the other variables must also change, ie. dimension space must maintain its orthonormal structure. A key feature of the manual tour is that it allows users to control the variable contributions to the basis. This means that such manipulations can be selected and queued in advance or selected on the spot for human-in-the-loop analysis (Karwowski 2006). However, this navigation is relatively time-consuming due to the vast volume of \\(p\\)-space (an aspect of the curse of dimensionality, Bellman (1957)) and the abstract method of steering the projection basis. It is advisable first to identify a basis of particular interest and then use a manual tour as more directed, local exploration tool to observe how the contribution of a variable is sensitive to the feature of interest. To simplify the task and keep its duration realistic, we consider a variant of the manual tour, called a radial tour. In a radial tour, the selected variable is allowed to change its magnitude of contribution but not its angle; it must move along the direction of its original contribution radius. The radial tour benefits from both continuity of the data alongside grand tours, but also allows the user to steer via choosing the variable to rotate. The recent implementation of manual tours us the R package spinifex (Spyrison and Cook 2020), which facilitates manual tours (and radial variant). It is also compatible with tours made with tourr (Hadley Wickham et al. 2011) and facilitates exporting to .gif or .html widget, with recent graphic packages. Now that we have a readily available means to produce various tours, we want to see how they fare against traditional discrete displays commonly used with PCA. 3.3 User study An experiment was constructed to assess the performance of the radial tour relative to the grand tour and PCA for interpreting the variable attribution contributing to separation between two clusters. These three methods were applied to simulations across three experimental factors: cluster shape, location of the cluster separation, and data dimensionality. Data was collected using a specially constructed web app, through crowdsourced with prolific.co (Palan and Schitter 2018). 3.3.1 Objective PCA will be used as a baseline for comparison as it is the most common linear embedding. The grand tour will act as a secondary control that will help evaluate the benefit of animation but without influencing its path. Lastly, the radial tour should perform best as it benefits both from animation and being user-control of the contribution of individual variables. Then for some subset of tasks, we expect to find that the radial tour performs most accurately, as it enjoys the persistence of points and input control to explore specific variables. Secondly, it may be the case that grand performs faster than the alternatives as its absence of inputs will allow to focus all of their attention on interpreting the fixed path. Conversely, we are less sure about the accuracy of such limited grand tours as there is no objective function in the selection of the bases; it is possible that, by chance, the planes altogether avoid bases showing cluster separation. However, given that the data dimensionality will be modest, it seems likely that grand tour will regularly crosses frames with the correct information to perform the task. We measure the accuracy and response time over the support of the discussed experimental factors. The null hypotheses can be stated as: \\(~~~~H_0: y_1, \\text{task accuracy does not vary with the visualization method} \\\\\\) \\(~~~~~H_\\alpha: y_1, \\text{task accuracy does vary with the visualization method} \\\\\\) \\(~~~~~H_0: y_2, \\text{task response time does not vary with the visualization method} \\\\\\) \\(~~~~~H_\\alpha: y_2, \\text{task response time does vary with the visualization method} \\\\\\) 3.3.2 Experimental factors In addition to visual factor, we vary the data across three aspects: 1) The location of the difference between clusters, by mixing a signal and a noise variable at different ratios, we vary the number of variables and their magnitude of cluster separation, 2) the shape of the clusters, to reflect varying distributions of the data, and 3) the dimension-ality of the data. Below we describe the levels within each factor, while Figure 3.2 gives a visual representation. Figure 3.2: Illustration of the experimental factors, the parameter space of the independent variables, the support of our study. The location of the separation of the clusters is a crucial aspect of analysis, it is the variables or combination their of that is important to the explanation of the structure. To test the sensitivity to this, we mix a noise variable with the signal-containing variable such that the difference in the clusters is mixed at the following percentages: 0/100% (not mixed), 33/66%, 50/50% (evenly mixed). In selecting the shape of the clusters, we follow the convention given by Scrucca et al. (2016), where 14 variants of model families containing three clusters are defined. The name of the model family is the abbreviation of its respective volume, shape, and orientation of the cluster, which are either equal or vary. We use the models EEE, EEV, and EVV. The latter is further modified by moving four-fifths of the data out in a V or banana-like shape. Dimension-ality is tested at two modest levels, namely, in four dimensions containing three clusters and six dimensions with four clusters. We must do so to bound the difficulty and search space to keep the task realistic for crowdsourcing. 3.3.3 Task and evaluation With our hypothesis formulated, let us turn our attention to the task and how to evaluate it. Regardless of the visual method, the elements of the display are held constant a 2D scatterplot with axis biplot to its left. Observations were supervised with the cluster level mapped to color and shape. Participants were asked to check any/all variables that contribute more than average to the cluster separation green circles and orange triangles, which was further explained in the explanatory video as mark and all variable that carries more than their fair share of the weight, or one quarter in the case of four variables. The instructions iterated several times in the video was: 1) use the input controls to find a frame that contains separation between the clusters of green circles and orange triangles, 2) look at the orientation of the variable contributions in the gray circle, a visual depiction of basis, and 3) select all variables that contribute more than average in the direction of the separation in the scatterplot. Independent with factor and block values, participants were limited to 60 seconds for each evaluation of this task. This restriction did not impact many participants as the 25th, 50th, 75th quantiles of response time were about 7, 21, and 30 seconds respectively. The evaluation measure of this task was designed with a couple of features in mind: 1) the sum of squares of the individual variable weights should be one, and 2) symmetric about zero, that is, without preference to under- or over-guessing. With these in mind, we define the following measure for evaluating the task. Let a data \\(\\textbf{X}_{n\\*p\\*k}\\) be a simulation containing clusters of observations of different distributions. Where \\(n\\) is the number of observations, \\(p\\) is the number of variables, and \\(k\\) is the number of clusters. Cluster membership is exclusive; an observation cannot belong to more than one cluster. We define weights, \\(W\\) to be a vector explaining the variable-wise difference between two clusters. Namely, the difference of each variable between clusters, as a proportion of the total difference, less \\(1/p\\), the amount of difference each variable would hold if it were uniformly distributed. Participant responses are a logical value for each variable, whether or not the participant thinks each variable separates the two clusters more than uniformly distributed separation. Then \\(Y_1\\) is a vector of variable accuracy. \\[\\begin{align*} W_{j} &amp;=\\frac {(\\overline{X_{j=1, k=1}} - \\overline{X_{1, 2}}, ~...~ (\\overline{X_{p, 1}} - \\overline{X_{p, 2}})} {\\sum_{j=1}^{p}(|\\overline{X_{j, k=1}} - \\overline{X_{j, k=2}}|)} - \\frac{1}{p} \\\\ \\\\ \\text{Accuracy}, Y &amp;= \\sum_{j=1}^{p}I(r_j) * sign(w_j) * \\sqrt{|w_j|} \\\\ \\end{align*}\\] Where \\(I\\) is the indicator function. Then the task accuracy is the sum of this vector. We use the time till the last response as a secondary dependent variable \\(Y_2\\). Figure 3.3: (L), PCA biplot of the components showing the most cluster separation with (R) illustration of the magnitude of cluster separation is for each variable (bars) and the weight of the variable accuracy if selected (red/green lines). The horizontal dashed line is \\(1 / p\\), the amount of separation each variable would have if evenly distributed. The weights equal the signed square of the difference between each variable value and the dashed line. 3.3.4 Visual design standardization Section 3.2 gives the sources and descriptions of the visual factors PCA, grand tours, and radial manual tours. The factors are tested within-participant, with each factor being evaluated by each participant. The order that factors are experienced is controlled with the block assignment as illustrated below in Figure 3.4. Below we cover the visual design standardization, as well the input and display within each factor. The visualization methods were standardized wherever possible. Each factor was shown as a biplot, display variable contributions on a unit circle. All aesthetic values (colors, shapes, sizes, absence of legend, and absence of axis titles) were held constant. Variable contributions were always shown left of the scatterplot embeddings with their aesthetic values consistent. What did vary between factors were their inputs which caused a discrete jump to another pair or principal components. They were absent for the grand tour with target bases to animate through selected at random, or for the radial tour, which variable should have its contribution animated. PCA inputs allowed for users to select between the top four principal components for both the x and y-axis regardless of the data dimensionality (either four or six). There was no user input for the grand tour; users were instead shown a 15-second animation of the same randomly selected path. Participant were able to view the same clip up to four times within the time limit. Radial tours were also displayed at five frames per second with an interpolation step size of 0.1 radians. Users were able to swap between variables. The display would change the start of radially increasing the contribution of the selected variable until it was full, zeroed, and then back to its initial contribution. The complete animation of any variable takes about 20 seconds and is almost entirely in the projection frame at around six seconds. The starting basis of each is initialized to a half-clock design, where the variables were evenly distributed in half of the circle which is then orthonormalized. This design was created to be variable agnostic while maximizing the independence of the variables. 3.3.5 Data simulation Each dimension is originally distributed as \\(\\mathcal{N}(2 * I(signal), 1)~|~\\text{covariance}~\\Sigma\\), a function of the shape factor. Signal variables had a correlation of 0.9 when they have equal orientation and -0.9 when their orientations vary. Noise variables were restricted to zero correlation. Each cluster is simulated with 140 observations and is offset in a variable that did not distinguish previous variables. Clusters of the EVV shape are transformed to the banana-chevron shape. Then location mixing is applied by post-multiplying a (2x2) rotation matrix to the signal variable and a noise variable for the clusters in question. All variables are then standardized by standard deviation. The rows and columns are then shuffled randomly. The observations cluster and order of shuffling are attached to the data and saved. Each of these replications is then iterated with each level of the factor. For PCA, every pair of the top four principal components and saved as 12 plots. For the grand tour, we first save two basis paths of differing dimension before each replication is projected through the common basis path. At the same time, each repetitions variable order was previously shuffled. The resulting animations were saved as .gif files. The radial tour starts at either the four or six variable half-clock basis, where each variable has a uniform contribution and no variable contributing in the opposite direction (to minimize variable dependence), a radial tour is then produced for each variable and saved as a .gif. 3.3.6 Randomized factor assignment Now, with simulation and their artifacts in hand. We explain how the experimental factors are assignment, and illustrate how this is experienced from a participants perspective. We section the study into three periods. Each period is linked to a randomized level of factor visualization and the location. The order of dimension and shape are of secondary interest and are held constant in increasing order of difficultly; four then six dimensions and EEE, EEV, then EVV-banana, respectively. Each period starts with an untimed training task at the simplest remaining block levels; location = 0/100%, shape = EEE, and four dimensions with three clusters. This serves to introduce and familiarize participants with input and visual differences. After the training, the participant is evaluated on two tasks with the same factor*location level across the increasing difficulty of dimension*shape. The plot was removed after 60 seconds, though participants rarely reached this limit. The order of the levels of the factor and location is randomized with a nested Latin square where all levels of the visual factor are exhausted before advancing to the next level of location. That means we need \\(3!^2 = 36\\) participants to evaluate all permutations of the experimental factors once. This randomization is essential to control for any potential learning effects the participant may receive. Figure 3.4 illustrates how an arbitrary participant experiences the experimental factors. Figure 3.4: Illustration of how a hypothetical participant 63 is assigned factor and block parameterizations. Each of the 6-factor order permutations is exhausted before iterating to the next permutation of location order. Through pilot studies sampled by convenience (information technology and statistics Ph.D. students attending Monash University), we predict that we need three complete evaluations to power our study properly; we set out to crowdsource \\(N = 3 * 3!^2 = 108\\) participants. 3.3.7 Participants We recruited \\(N = 108\\) participants via prolific.co (Palan and Schitter 2018). We filtered participants based on their claimed education requiring that they have completed at least an undergraduate degree (some 58,700 of the 150,400 users at the time); we apply this filter under the premise that linear projections and biplot displays used will not be regularly used for consumption by general audiences. There is also the implicit filter that Prolific participants must be at least 18 years of age and implicit biases of timezone, location, and language. Participants were compensated for their time at 7.50 per hour, whereas the mean duration of the survey was about 16 minutes. We cant preclude previous knowledge or experience with the factors but validate this assumption in the follow-up survey asking about familiarity with the factors. The appendix contains a heatmap distribution of age and education paneled across preferred pronouns of the participants that completed the survey, who are relatively young, well educated, and slightly more likely to identify as males. 3.3.8 Data collection Data were recorded by a shiny application and were written to a Google Sheet after each third of the study. Especially at the start of the study, participants experienced adverse network conditions due to the volume of participants hitting the application with modest allocated resources. In addition to this, API read/write limitations further hindered data collection. To mitigate this, we throttled the volume of participants and over-collect survey trials until we had received our target three evaluations of all permutation levels. The processing steps were minimal. First, we format to an analysis-ready form, decoding values to a more human-readable state, and add a flag to indicate if the survey had complete data. We filter to only the latest three complete studies of each block parameterization, those which should have experienced the least adverse network conditions. The bulk of the studies removed were partial data and a few over-sampled permutations. This brings us to the 108 studies described in the paper, from which models and aggregation tables were built. The post-study surveys were similarly decoded to human-readable format and then filtered to include only those 84 surveys that were associated with the final 108 studies. The code, response files, their analyses, and the study application are publicly available at on GitHub. 3.4 Results To recap, the primary response variable is task accuracy, as defined in section 3.3.3, and the log of response time will be used as a secondary response variable. We have two primary data sets; the user study evaluations and the post-study survey. The former is the 108 participants with the explanatory variables: visual factor, location of the cluster separation signal, the shape of variance-covariance matrix, and the dimensionality of the data. Block parameterization and randomization were discussed in section 3.3.2. The survey was completed by 84 of these 108 people. It collected demographic information (preferred pronoun, age, and education), and subjective measures for each of the factors (preference, familiarity, ease of use, and confidence). Below we look at the marginal performance of the block parameters and survey responses. After that, we build a battery of regression models to explore the variables and their interactions. Lastly, we look at the subjective measures between the factors. 3.4.1 Accuracy regression To more thoroughly examine explanatory variables, we regress against accuracy. All models have a random effect term on the participant, which captures the effect of the individual participant. After we look at models of the block parameters, we extend to compare against survey variables. Last, we compare adding a random effect for data and regressing against time till last response fares against benchmark models. The matrices for models with more than a few terms quickly become rank deficient; there is not enough data to explain all of the effect terms. In building a set of models to test, we include all single term models those with all independent terms. We also include an interaction term of factor by location, allowing for the slope of each location to change across each level of the factor. For comparison, an overly complex model with all interaction terms is included. \\[ \\begin{array}{ll} \\textbf{Fixed effects} &amp;\\textbf{Full model} \\\\ \\alpha &amp;\\widehat{Y_1} = \\mu + \\alpha_i + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha + \\beta + \\gamma + \\delta &amp;\\widehat{Y_1} = \\mu + \\alpha_i + \\beta_j + \\gamma_k + \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha * \\beta + \\gamma + \\delta &amp;\\widehat{Y_1} = \\mu + \\alpha_i * \\beta_j + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha * \\beta * \\gamma + \\delta &amp;\\widehat{Y_1} = \\mu + \\alpha_i * \\beta_j * \\gamma_k + \\textbf{Z} + \\textbf{W} + \\epsilon \\\\ \\alpha * \\beta * \\gamma * \\delta &amp;\\widehat{Y_1} = \\mu + \\alpha_i * \\beta_j * \\gamma_k * \\delta_l + \\textbf{Z} + \\textbf{W} + \\epsilon \\end{array} \\] \\[ \\begin{array}{ll} \\text{where } &amp;\\mu \\text{ is the intercept of the model including the mean of random effect} \\\\ &amp;\\epsilon \\sim \\mathcal{N}(0,~\\sigma), \\text{ the error of the model} \\\\ &amp;\\textbf{Z} \\sim \\mathcal{N}(0,~\\tau), \\text{ the random effect of participant} \\\\ &amp;\\textbf{W} \\sim \\mathcal{N}(0,~\\upsilon), \\text{ the random effect of simulation} \\\\ &amp;\\alpha_i \\text{, fixed term for factor}~|~i\\in (\\text{pca, grand, radial}) \\\\ &amp;\\beta_j \\text{, fixed term for location}~|~j\\in (\\text{0/100\\%, 33/66\\%, 50/50\\%}) \\text{ \\% noise/signal mixing} \\\\ &amp;\\gamma_k \\text{, fixed term for shape}~|~k\\in (\\text{EEE, EEV, EVV banana}) \\text{ model shapes} \\\\ &amp;\\delta_l \\text{, fixed term for dimension}~|~l\\in (\\text{4 variables \\&amp; 3 cluster, 6 variables \\&amp; 4 clusters}) \\\\ \\end{array} \\] Table 3.1: Model performance of random effect models regressing accuracy. Each model includes a random effect term of the participant explaining the individuals influence on accuracy. Complex models perform better in terms of \\(R^2\\) and RMSE, yet AIC and BIC penalize their large number of fixed effects in favor of the much simpler model containing only the visual factor. Conditional \\(R^2\\) includes the random effects, while marginal does not. Fixed effects No. levels No. terms AIC BIC R2 cond. R2 marg. RMSE a 1 3 1000 1027 0.180 0.022 0.462 a+b+c+d 4 8 1026 1075 0.187 0.030 0.460 a*b+c+d 5 12 1036 1103 0.198 0.043 0.457 a*b*c+d 8 28 1069 1207 0.238 0.080 0.447 a*b*c*d 15 54 1125 1380 0.282 0.111 0.438 Table 3.2: The task accuracy model coefficients for \\(\\widehat{Y_1} = \\alpha * \\beta + \\gamma + \\delta\\), with factor=pca, location=0/100%, and shape=EEE held as baselines. Factor being radial is the fixed term with the strongest evidence supporting the hypothesis. When crossing factor with location radial performs worse with 33/66% mixing relative to the PCA with no mixing. The model fit is based on the 648 evaluations by the 108 participants. Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 0.03 0.08 44.2 0.44 0.66 factor Factorpca -0.15 0.09 622.4 -1.74 0.08 Factorradial 0.22 0.09 618.6 2.46 0.01 fixed effects Location33/66% 0.10 0.09 84.9 1.09 0.28 Location50/50% 0.05 0.09 83.0 0.58 0.56 ShapeEEV 0.04 0.06 11.5 0.79 0.44 Shapebanana -0.03 0.06 11.5 -0.48 0.64 Dim6 -0.06 0.05 11.5 -1.39 0.19 interactions Factorpca:Location33/66% 0.06 0.13 587.3 0.49 0.63 Factorradial:Location33/66% -0.28 0.13 577.6 -2.14 0.03 Factorpca:Location50/50% 0.09 0.13 589.6 0.68 0.50 Factorradial:Location50/50% -0.10 0.13 588.0 -0.77 0.44 We also want to visually explore the conditional variables in the model. Figure 3.5 explores violin plots of accuracy by factor while faceting on the location (vertical) and shape (horizontal). Radial tends to increase the accuracy received, and especially so when there is no signal/noise mixing. Figure 3.5: Violin plots of terms of the model \\(\\widehat{Y_1} = \\alpha * \\beta + \\gamma + \\delta\\). Overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests suitable for handling discrete data. Participants are more confident and find radial tour easier to use than the grand tour. Participants claim low familiarity as we expect from crowdsourced participants. Radial is more preferred compared with either alternative for this task. 3.5 Response time regression As a secondary explanatory variable, we also want to look at time. First, we take the log transformation of time as it is right-skewed. We repeat the same modeling procedure: 1) build a battery of all additive and multiplicative models. 2) Compare their performance, reporting some top performers. 3) Select a model to examine its coefficients. Table 3.3: Model performance regressing on log response time [seconds], \\(\\widehat{Y_2}\\) random effect models, where each model includes random effect terms for participants and simulations. We see the same trade-off where the simplest factor model is preferred by AIC/BIC, while \\(R^2\\) and RMSE is larest in the full multiplicative model. We again select the model \\(\\alpha * \\beta + \\gamma + \\delta\\) to explore further as it has relatively high marginal \\(R^2\\) while having much less complexity than the complete interaction model. Conditional \\(R^2\\) includes the random effects, while marginal does not. Fixed effects No. levels No. terms AIC BIC R2 cond. R2 marg. RMSE a 1 3 1000 1027 0.180 0.022 0.462 a+b+c+d 4 8 1026 1075 0.187 0.030 0.460 a*b+c+d 5 12 1036 1103 0.198 0.043 0.457 a*b*c+d 8 28 1069 1207 0.238 0.080 0.447 a*b*c*d 15 54 1125 1380 0.282 0.111 0.438 Table 3.4: Model coefficients for log response time [seconds] \\(\\widehat{Y_2} = \\alpha * \\beta + \\gamma + \\delta\\), with factor=PCA, location=0/100%, and shape=EEE held as baselines. Location=50/50% is the fixed term with the strongest evidence and takes less time. In contrast, the interaction term location=50/50%:shape=EEV has the most evidence and takes much longer on average. Estimate Std. Error df t value Pr(&gt;|t|) (Intercept) 2.48 0.14 42.8 17.41 0.00 *** Factor Factorpca 0.23 0.12 567.6 1.97 0.05 Factorradial 0.39 0.12 571.9 3.29 0.00 ** Fixed effects Location33/66% 0.29 0.14 42.0 2.06 0.05 Location50/50% 0.07 0.14 40.5 0.54 0.59 ShapeEEV -0.15 0.09 8.3 -1.61 0.14 Shapebanana -0.13 0.09 8.3 -1.42 0.19 Dim6 0.14 0.08 8.3 1.90 0.09 Interactions Factorpca:Location33/66% -0.24 0.18 580.9 -1.34 0.18 Factorradial:Location33/66% -0.48 0.18 583.1 -2.63 0.01 ** Factorpca:Location50/50% -0.12 0.18 578.6 -0.69 0.49 Factorradial:Location50/50% -0.08 0.18 580.9 -0.43 0.67 3.5.1 Subjective measures The 84 evaluations of the post-study survey also collect four subjective measures for each factor. Figure 3.6 shows the Likert plots, or stacked percentage bar plots, alongside violin plots with the same non-parametric, ranked sum tests previously used. Participants preferred to use radial for this task. Participants were also more confident of their answers and found radial tours easier than grand tours. All factors have reportedly low familiarity, as expected from crowdsourced participants. Figure 3.6: The subjective measures of the 84 responses of the post-study survey, five discrete Likert scale levels of agreement (L) Likert plots (stacked percent bar plots) with (R) violin plots of the same measures. Violin plots are overlaid with global significance from the Kruskal-Wallis test, and pairwise significance from the Wilcoxon test, both are non-parametric, ranked sum tests. 3.6 Conclusion Data visualization is an integral part of EDA. Yet through exploration of data in high dimensions become difficult. Previous methods offer no means for an analyst to impact the projection basis. The manual tour provides a mechanism for changing the contribution of a selected variable to the basis. Giving analysts such control should facilitate the exploration of variable-level sensitivity to the identified structure. We find strong evidence that using the radial tour improves the accuracy relative to PCA or the grand tour on the supervised cluster task assigning variable attribution to the separation of the two clusters. This paper discussed an \\(n=108\\), with-in participant user study comparing the efficacy of three linear projection techniques. The participants performed a supervised cluster task, specifically identifying which variables contribute to the separation between two target clusters. This was evaluated evenly over four experimental factors. In summary, we find strong evidence that using the radial tour leads to a sizable increase in accuracy. There is also evidence for a small change response time, with an increasing order of PCA, grand, and radial. The effect sizes on accuracy are large relative to the change from the other experimental factors, though smaller than the random effect of the participant. The radial tour was subjectively most preferred, leading to more confidence in answers, and increased ease of use than the alternatives. There are several ways that this study could be extended. In addition to expanding the support of the experimental factors, more exciting directions include: changing the type of the task, visualizations used, and experience level of the target population. It is difficult to achieve good coverage given the number of possible permutations. Keep in mind the volume of traffic and low effort of responses from participants when crowdsourcing. 3.7 Accompanying tool: radial tour application To accompany this study we have produced an application to illustrate the radial tour. The R package, spinifex, (Spyrison and Cook 2020) is free, open-source and now contains an shiny (Chang et al. 2020) application that allows users to apply various preprocessing tasks and interactively explore their data via interactive radial tour. Example datasets are provided with the ability to upload data. The .html widget produced is a more interactive variant relative to the one used in the user study. Screen captures and more details are provided in the appendix. Run the following R code will run the application locally. ## Download: install.packages(&quot;spinifex&quot;, dependencies = TRUE) ## Run shiny app: spinifex::run_app() 3.8 Acknowledgments This research was supported by an Australian government Research Training Program (RTP) scholarship. This article was created in R (R Core Team 2020) and rmarkdown (Xie, Allaire, and Grolemund 2018). Visuals were prepared with spinifex. All packages used are available from the Comprehensive R Archive Network CRAN. The source files for this article, application, data, and analysis can be found on GitHub. The source code for the spinifex package and accompanying shiny application can be found here. 3.9 Appendix Survey participant demographics The target population is relatively well educated people, as linear projections may prove difficult for generalized consumption. Hence we restrict Prolific.co participants to those with an undergraduate degree (58,700 of the 150,400 users at the time of the study). From this cohort 108 performed a complete study. Of these participants, 84 submitted the post-study survey, who are represented in the following heatmap. All participants were compensated for their time at 7.50 per hour, with a mean time of about 16 minutes. Figure 3.7: Heatmaps of survey participant demographics; counts of age group by completed education as faceted across preferred pronoun. Our sample tended to be between 18 and 35 years of age with an undergraduate or graduate degree. Random effect ranges Residual plots have no noticeable non-linear trends and contain striped patterns as an artifact from regressing on discrete variables. Figure 3.8 illustrates (T) the effect size of the random terms participant and simulation, or more accurately, the 95% CI from Gelman simulation of their posterior distribution. The effect size of the participant is much larger than simulation. The most extreme participants are statistically significant at \\(\\alpha = .95\\), while none of the simulation effects significantly deviate from the null of having no effect size on the marks. In comparison, (B) 95% confidence intervals participation and simulation mean accuracy, respectively. Figure 3.8: (T) Estimated effect ranges of the random effect terms participant and data simulation of the accuracy model, \\(\\widehat{Y_1} = \\alpha * \\beta + \\gamma + \\delta\\). Confidence intervals are created with Gelman simulation on the effect posterior distributions. The effect size of the participant is relatively large, with several significant extrema. None of the simulations deviate significantly. (B) The ordered distributions of the CI of mean marks follow the same general pattern and give the additional context of how much variation is in the data, an upper limit to the effect range. The effect ranges capture about two-thirds of the range of the data without the model. All intervals for \\(\\alpha = .95\\) confidence. Figure 3.9: (T) The effect ranges of Gelman resimulation on posterior distributions for the time model, \\(\\widehat{Y_2} = \\alpha * \\beta + \\gamma + \\delta\\). These show the magnitude and distributions of particular participants and simulations. Simulation has a relatively small effect on response time. (B) Confidence intervals for mean log time by participant and simulation. The marginal density shows that the response times are left-skewed after log transformation. Interpreting back to linear time there is quite the spread of response times: \\(e^{1} = 2.7\\), \\(e^{2.75} = 15.6\\), \\(e^{3.75} = 42.5\\) seconds. Of the simulations on the right, the bottom has a large variation in response time, relative to the effect ranges which means that the variation is explained in the terms of the model and not by the simulation itself. Radial tour application details Below we describe a locally ran shiny app available in the spinifex package. It streamlines creating and interacting with radial tours more interactive than the application used in the user study. Figure 3.10: Process data tab, interactively loads or select data, check which variables to project, and optionally scale columns by standard deviation. In the initial tab, users upload their own (.csv, .rds, or .rda) data or select from predefined data sets. The numeric columns appear as a list of variables to include in the projection. Below that, a line displays whether or not NA rows were removed. Scaling by standard deviation is included by default, as this is a common transformation used to explore linear projections of spaces. Summaries of the raw data and processed numeric data are displayed to illustrate how the data was read and its transformation. Figure 3.11: Radial tour tab, interactively create radial tours, changing the manipulation variable, and color or shape of the resulting manual tour. Here, the palmer penguins data is being explored, bill length was selected to manipulate as it is the only variable separating the green cluster from the orange. By mapping shape to island of observation, we also notice that the species in green live on all three islands, while the other species live only on one of the islands. The second tab contains interaction for selecting the manipulation variable and non-numeric columns can be used to change the color and shape of the data points in the projection. The radial tour is created in real-time animating as an interactive plotly .html widget. The application offers users a fast, intuitive introduction elucidating what the radial tour does and some of the features offered. "],["4-ch-cheem.html", "Chapter 4 Scrutinizing the linear variable importance of local explanations of non-linear models with animated linear projections 4.1 Introduction 4.2 Local explanation statistics 4.3 Tours and the radial tour 4.4 Cheem viewer 4.5 Case studies 4.6 Discussion 4.7 Acknowledgments 4.8 References", " Chapter 4 Scrutinizing the linear variable importance of local explanations of non-linear models with animated linear projections THE CHAPTER IS NOW SLIGHTLY OUTDATED, Bring content over again after Intro changes. Now we can be confident that the radial tour leads to better analysis of variable-level attribution to features identified in a projection. We want to increase the interpretability of complex models. Specifically, I suggest a using the radial tour to explore variable sensitivity to the structure identified in linear local explanations of non-linear models. Artificial Intelligence (AI) has seen a revitalization in recent years from the use of increasingly hard-to-interpret black-box models. In such models, increased predictive power comes at the cost of the opacity of factor analysis and variable interpretability. The loss of interpretability has led to the field of eXplainable AI (XAI). XAI attempts to shed light on these models by providing means for interpreting them. A local explanation of a non-linear model gives a point-estimate of linear variable importance in the vicinity of one observation. After creating a model and exacting explanations for each observation, we explore the original variables, the explanations attribution, and model information side-by-side with interactively display. After identifying an observation of interest, its local explanation is used as a 1D projection basis. We then manipulate the magnitude of a variables contribution with a tour technique. The tour animates many projections over small changes in the projection basis as it changes the contribution of one variable. Doing so allows an analyst to visually explore the data through the lens of this local explanation and test the variable support where the explanation seems valid. The interactive application and code facilitating this methodology is available are the R package cheem, available on CRAN. 4.1 Introduction There are different reasons and emphases to fit a model. Breiman and Shmueli (Breiman 2001; Shmueli 2010) introduce the idea of distinguishing modeling based on its purpose; explanatory modeling is done for some inferential purpose, while predictive modeling focuses more on the predictions of out-of-sample observations. The intended use has important implications for model selection and development. In explanatory modeling, interpretability is vital for drawing inferential conclusions. While predictive modeling may opt for more accurate non-linear models. The use of black-box models is becoming increasingly common, but not without their share of controversy (Oneil 2016; Kodiyan 2019). However, the loss of interpretation should not be taken lightly. Interpretability is vital for exploring and protecting against potential biases in any model. For instance, models regularly pick up on biases in the training data that have observed influence on the response variable, which is then built into the model. Such biases include sex (Dastin 2018; Duffy 2019), race (Larson et al. 2016), and age (Díaz et al. 2018). Variable-level interpretability of models is essential in the evaluation models for such biases. Another concern is that of data drift. Data drift is an unexpected shift in support of the variables. Non-linear models are regularly more sensitive to these changes. The interpretability of the model means more transparency to see where models predictions may be plausible or completely unreliable. Explainable Artificial Intelligence (XAI) is a recent branch of research that tries to increase the interpretability of black-box models. One way to do so is to use local explanations, which take a variable attribution approach to bring transparency to a model. Local explanations attempt to approximate linear variable importance at the location of one observation. Even with a linear space or local approximation, the number of terms is usually sizable, thus challenging to visualize comprehensively. In multivariate data visualization, a tour (Asimov 1985; Buja and Asimov 1986; S. Lee et al. 2021) is a sequence of linear projections of data onto a lower-dimensional space. Tours are viewed as an animation over minor changes to the projection basis. Structure in a projection can then be explored visually to see which variables contribute to the formation of that structure. The intuition is similar to watching the shadow of a hidden 3D object change as the object is rotated; watching the shape of the shadow change conveys information of the structure and features of the object. There are various types of tours distinguished by the generation of projection bases. In a manual tour (Cook and Buja 1997; Spyrison and Cook 2020), the path is defined by changing the contribution of a selected variable. Applying tours to models has been done in a couple of contexts. Specifically for exploring various statistical model fits and classification boundaries (Hadley Wickham, Cook, and Hofmann 2015), and using tree- and forest-based approaches as a projection pursuit index to generate a tour basis paths (Y. D. Lee et al. 2013; Silva, Cook, and Lee 2021). The proposed approach uses the radial, manual tour to scrutinize a local explanation. After identifying an observation of interest, its explanation can be evaluated by testing the support of the structure identified by changing variable contribution with the radial tour. We provide a free and open-source R package cheem with an interactive application to facilitate analysis. We supply toy and modern datasets case studies for classification and regression tasks. The change in the projection basis might feel similar to counterfactual, what-if analysis, such as ceteris paribus (Biecek 2020). This phrase, Latin for other things held constant or all else unchanged, shows how an observations prediction would change from a marginal change in one explanatory variable given that other variables are held constant. It ignores correlations of the variables and imagines a case that was not observed. In contrast, our approach is a geometric explanation of the factual; it varies contributions of the variables by rotating the basis, a reorientation of the data object. Another difference is that the basis must remain orthonormal. That is to say, when the contribution of one variable decreases, the contributions of others necessarily increase such that there is a complete component in that direction. The remainder of this paper is organized as follows. The following section, Local explanation statistics, covers the background of the local explanation, SHAP, and the traditional visuals produced from it. Tours and the radial tour digs deeper into these animations of continuous linear projections. The section Application Design discusses the visual layouts, how they facilitate analysis, data preprocessing, and package infrastructure. The section Case Studies illustrates several applications of this method. We conclude with a Discussion of the insights we draw from classification and regression tasks. 4.2 Local explanation statistics Consider a highly non-linear model. At face value, it is hard to say which variable(s) are sensitive to crossing a classification boundary or identify which variables caused an observation to have a relatively extreme residual. Local explanations shed light on these cases by approximating linear variable importance in the vicinity of one observation. Figure six of Arrieta et al. (2020) gives comprehensive summarization of the taxonomy and literature of explanation techniques. The figure includes a large number of model-specific explanations such as deepLIFT, (Shrikumar et al. 2016; Shrikumar, Greenside, and Kundaje 2017) a popular recursive method for estimating importance in neural networks. There are fewer model-agnostic explanations, of which LIME, (Ribeiro, Singh, and Guestrin 2016) SHAP, (S. Lundberg and Lee 2017) and their variants are popular. These instance-level explanations are used in various ways depending on the data. In images, saliency maps overlay or offset a heatmap indicating necessary pixels (Simonyan, Vedaldi, and Zisserman 2014). For instance, snow may be highlighted when distinguishing if a picture contains a wolf or husky. In text analysis, word-level contextual sentiment analysis can be used to highlight the sentiment and magnitude of influential words (Vanni et al. 2018). In the case of numeric regression, they are used to explain variable additive contributions from the model intercept to the observations prediction (Ribeiro, Singh, and Guestrin 2016). 4.2.1 SHAP and tree SHAP SHaply Additive exPlanations (SHAP) approximates the variable importance in the vicinity of one observation by taking the median importance of a subset of permutations in the explanatory variables. This idea stems from the field of game theory, where Shapley (1953) devised a method to evaluate an individuals contribution to cooperative games by permuting the players that contribute to the score. To illustrate SHAP and its original use, explaining the difference between the intercept and an observations prediction, we use soccer data from FIFA 2020 season (Leone 2020). We have 5000 observations of nine skill measures (after aggregating highly correlated variables). A random forest model is fit to regress the log wages, in 2020 Euros, from the skill measures. We then extract the SHAP values of a star offensive player (L. Messi) and defensive player (V. van Dijk). We expect to see a difference in the attribution of the variable importance across the two positions of the players. Figure 4.1: Illustration of the distribution of SHAP attributions and a break-down plot. From FIFA 2020 data, a random forest model regresses wages from nine skill attributes for a star offensive and defensive player. The players have very different salaries, but a) shows the distributions of 25 permutations in the explanatory variables. The medians of these distributions are the final SHAP values. The variable importance differs across the exogenous information of player position. These explanations make sense; the variable importances seem realistic given the players positions. b) Break-down plots of the observations using their explanations to additively cover the difference between the model intercept and the observation predictions. Figure 4.1 shows the SHAP values of these players. Panel a) shows these players receive a sizable difference in wages. Panel b) shows the underlying distribution of the SHAP attributions while permuting the explanatory variables, with the medians being the SHAP values. In the light of the player position, the difference in the variable importance makes sense; offense and movement skills are more important for the offensive player, while defensive and power skills are more informative to the model for explaining the prediction of the defensive player. We would likewise expect the profile of variable importance to be unique for star players of other positions, such as goalkeepers or middle fielders. Panel b) shows a simplified break-down plot (Gosiewska and Biecek 2019), where a local explanation is used to additively explain the difference from the intercept to the observations prediction. Such additive approaches will show asymmetry in the variable ordering, so we opt to fix the order to panel a) by decreasing the sum of the SHAP values. In summary, this figure highlights how local explanations bring interpretability to a model, at least in the vicinity of their observations. In this instance, two players with different positions receive different profiles of variable importance to explain the prediction of their wages. In application, we apply tree SHAP, a variant of SHAP enjoys a lower computational complexity (S. M. Lundberg, Erion, and Lee 2018). Tree SHAP is only compatible with tree-based models; we illustrate random forests. The following section will use normalized explanations as the starting projection basis to further scrutinize the explanation. 4.3 Tours and the radial tour A data visualization tour animates many linear projections over small changes in the basis. One of the critical features of the tour is the object permanence of the data points; one can track the relative changes of observations as the basis moves, as opposed to discretely jumping to an orthogonal view with no intermediate information. There are various types of tours that are distinguished by selecting their basis paths (S. Lee et al. 2021; Cook et al. 2008). 4.3.1 Manual tours and its radial case The manual tour (Cook and Buja 1997) defines its basis path by manipulating a selected variables contribution to the basis. A manipulation dimension is appended onto the projection plane, giving a full contribution to the chosen variable. The bases are then selected based on rotating this newly created manipulation space. A crucial feature of the manual tour is that it allows users to control the variable contributions of the basis. Such manipulations can be selected and queued in advance or selected on the spot for human-in-the-loop analysis (Karwowski 2006). However, this navigation is relatively time-consuming due to the vast volume of the display space. It is advisable to use this method to explore the sensitivity of the variable contribution to a previously identified feature of interest. In this case, the projection of the normalized explanations is the feature of interest. More generally, the manual tour can change the contribution of a variable to the display dimensions. We will apply a more directed interaction, namely, a radial tour. In a radial tour, the selected variable is allowed to change its magnitude of contribution but not its angle; it must move along the direction of its original contribution. 4.4 Cheem viewer Below we illustrate the two primary displays of the cheem viewer application: the global view and the tour view. Then we cover what we take away from the classification and regression tasks. Lastly, we discuss the preprocessing of the data before application runtime. 4.4.1 Global view The global view provides an essential context of all observations and facilitates the exploration of the separability of the data- and attribution-spaces. While the comparison of these spaces is interesting, the global views purpose is to enable the selection of observations. The local explanation of these points will be explored in more detail. An approximation of these spaces is given as the first two principal components of their respective spaces. Model information, the observed response by its prediction, is also provided. The orientation and magnitude of the variables are inscribed on a unit circle. Misclassified observations are circled in red if applicable. Linked brushing between the plots and tabular display of select points facilitates exploration of the spaces and the model. A single 2D projection will not encompass all of the structure of higher-dimensional space. However, it is a reasonable summarization given the real task at hand; the selection of observations to explore further. 4.4.2 Radial cheem tour The global view facilitated the selection of a primary and optional comparison observation. The variable-level attribution of the primary observation is normalized and used as the initial 1D basis in a radial tour. This is an approximation of the contributions of the linear variables that best explain the difference between the model intercept and an observations prediction, not the local shape of the model surface. The initial frame is the normalized SHAP values of the primary observation. The current projection basis is depicted as the width of a bar, the variables contribution to the horizontal axis. The normalized values of all observations are shown as vertical parallel coordinate plots. The radial tour creates a basis path by varying the contribution of a selected variable, fully into and out of a projection frame. Doing so tests an individual variables sensitivity to the structure identified by the local explanation. The default variable selected has the largest discrepancy between the attribution of primary and comparison observations. The following sections elaborate on the takeaways from applying this approach in classification and regression tasks. Now that we have introduced the global view and corresponding cheem radial tour, let us discuss the differences between the classification and regression cases. 4.4.3 Classification task What information do we glean from using this method on a classification task? Typically we select a misclassified observation compared to a correctly classified point nearby in data space. The initial frame is the linear attribution of that observations local explanation. By default, the manual tour varies the contribution of the variable with the largest difference between the primary and comparison observation; we can test the sensitivity of each variable to structure identified by the local explanation; we are exploring the support of the explanation, evaluating the support or robustness of the prediction. Figure 4.2: Display illustrating the classification case. Plots are colored on predicted class, and red circles indicate misclassified observations. The radial tour is a 1D projection starting at the normalized tree SHAP values of the primary point. The first frame is the linear-variable importances that best describe the difference from model intercept to this observations prediction. We probe the support of the variable contributions by selecting a variable to vary the contribution. 4.4.4 Regression task In the regression case, the global view can be colored on a statistic to highlight the explanation spaces structure. For this purpose, we include residuals, log Mahalanobis distance of data space (a measure of outlyingness), and the correlation of the attribution projection with the observed response. In the radial tour, the horizontal positions are the same, the basis projection of the radial tour. The vertical position is fixed to the observed response variable and residuals in the middle and right panels. Correspondingly, the display changes from univariate density to 2D scatterplot. The basis is still one component (horizontal) independent of the vertical position. Figure 4.3: Display of the regression task. The global view can be colored on the correlation of the attribution projection and observed response. In the tour, the horizontal values are the same as the classification case; the projection through the basis. The vertical position is now mapped to the observed y and residuals. 4.4.5 Interactive features The application has several reactive inputs that affect the data used, aesthetic display, and tour manipulation. These reactive inputs make the software flexible and extensible. The application also has more exploratory interactions to help link points across displays and reveal structure found in different spaces. A tooltip displays observation number/name and classification information while the cursor hovers over a point. Linked brushing allows the selection of points (left click and drag) where those points will be highlighted across plots. The information corresponding to the selected points is populated on a dynamic table. These interactions aid exploration of the spaces and, finally, identification of a primary and comparison observation. Figure 4.4: Illustration of data explorations interactions in the global view. This view has linked brushing, where observations selected in one facet are highlighted in the other facets and populate an interactive tabular display below. Tooltips display when hovering over an observation. 4.4.6 Preprocessing It is vital to mitigate the render time of visuals, especially when users may want to iterate many times. All computational operations should be prepared before runtime. The work remaining when an application is ran is solely reacting to inputs and rendering of visuals and tables. Below we discuss the steps and details of the reprocessing. (ref:citeRf) Liaw and Wiener (2002) (ref:citeTs) Kominsarczyk et al. (2021) The time to preprocess the data will vary significantly with the model and local explanation. For reference, the FIFA data, 5000 observations of nine explanatory variables, took 2.9 seconds to fit a random forest model of modest hyperparameters. Extracting the tree SHAP values of each observation took 254 seconds combined. PCA and statistics of the variables and attributions took 0.6 seconds. These runtimes were from a non-parallelized R session on a modern laptop, but suffice to say that the bulk of the time will be spent on the local attribution. An increase in model complexity or data dimensionality will quickly become an obstacle. With its reduced computational complexity, this makes tree SHAP a good candidate to start with. Alternatively, the package fastshap (Greenwell 2020) claims extremely low runtimes, which are attributed to fewer calls to the prediction function, partial implementation in C++, and efficient use of logical subsetting. 4.4.7 Package infrastructure The above-described method and application are implemented as an open-source R package, cheem available on CRAN. Preprocessing was facilitated with models created via randomForest (Liaw and Wiener 2002), and explanations calculated with treeshap (Kominsarczyk et al. 2021). The application was made with shiny (Chang et al. 2021). The tour visual is built with spinifex (Spyrison and Cook 2020). Both views are created first with first with ggplot2 (Hadley Wickham 2016) and then rendered as interactive HTML widgets with plotly (Sievert 2020). DALEX (Biecek 2018) and the free ebook, Explanatory Model Analysis (Biecek and Burzykowski 2021) were a huge boon to understanding local explanations and how to apply them. 4.4.8 Installation and getting started The following R code will help getting up and running: ## Download the package install.packages(&quot;cheem&quot;, dependencies = TRUE) ## Restart the R session so the IDE has the correct directory structure restartSession() ## Load cheem into session library(&quot;cheem&quot;) ## Try the app run_app() # Processing your data ## Install treeshap from github, to use as a local explainer remotes::install_github(&#39;ModelOriented/treeshap&#39;) ## Local ## Follow the examples in cheem_ls() ?cheem_ls 4.5 Case studies To illustrate the use of the cheem method, we apply it to modern datasets, two classification examples and then two of regression. 4.5.1 1) Penguin, species classification Palmer penguins data (Gorman, Williams, and Fraser 2014; Horst, Hill, and Gorman 2020) consist of 330 observations across four physical measurements of three species of penguins foraging near Palmer Station, Antarctica. A random forest model was fit, classifying the species of the penguin given the physical measurements. (ref:casepenguins) Species classification of Palmer penguin data. We select a chinstrap penguin that is mislabeled as an adelie. By varying the contribution to bill length, we observe the explanation does not hold when bill length has a significant contribution. The .mp4 animation of this tour can be found at github.com/nspyrison/cheem_paper/blob/main/figures/case_penguins.mp4 Figure 4.5: (ref:casepenguins) In figure 4.5, a misclassified point is contrasted with a correctly classified point of its observed class nearby in data-space. The attribution space from the tree SHAP local explanations is a more separable space, where the comparison is squarely in the middle of the orange distribution. The primary observation is between the predicted and observed clusters, a sign of uncertainty in the prediction. The tour varies the contribution of bill length (b_l) as this variable differs most from the contribution of the comparison observation. Downplaying the contribution of bill length is crucial to the linear explanation of this observation being misclassified. 4.5.2 2) Chocolates, milk/dark chocolate classification The chocolates dataset consists of 88 observations of 10 nutritional measurements from their labels. Each of which was labeled as being either milk or dark chocolates. We can see if a manufacturer accurately portrays the chocolate with this data. We are curious to see if chocolates that nutritionally look like milk chocolates are labeled as dark chocolates, which may hold a higher market value. We should note that not all chocolates consist wholly of chocolate. The addition of other ingredients will decrease the predictive power of the model nutritional explanatory variable. A random forest model is fit classifying the type of chocolate. We selected a chocolate labeled dark, through predicted to be milk chocolate compared with a chocolate labeled 85% cocoa. (ref:casechocolates) Chocolates data type classification (milk or dark). We select a chocolate labeled as dark though a random forest model predicts it to be milk chocolate in light of the values on the nutritional label. We vary the contribution of calories from fat. Animated tour can be found at github.com/nspyrison/cheem_paper/blob/main/figures/case_chocolates.mp4. Figure 4.6: (ref:casechocolates) Figure 4.6 similarly shows that attribution-space is more separable than data-space. Interestingly, the class imbalance that we suspected was not observed; there are only six chocolates labeled as dark and predicted as milk, while eight of the inverse case. Calories from fat is the variable with the largest difference in treeshap attribution between these points. In this case, it feels strange to call the selected observation a misclassification of the model. There are plausible reasons that a manufacturer has incentives to cut corners and label their products different than what they are. This feels more like a measurement theory-related problem. In this case, the candy is being sold as dark chocolate, while nutritional value more closely resembles milk chocolates. 4.5.3 3) FIFA, wage regression The 2020 season FIFA data (Leone 2020; Biecek 2018) contains many skill measurements of soccer/football players and wage information. After aggregation of the skill measurements, we regress the log wages [2020 euros] given just the skill aggregates. The model was fit from 5000 observations of the nine skill aggregates before being thinned to 500 players to mitigate occlusion and render time. We compare a leading offensive fielder (L. Messi) with that of a top defensive fielder (V. van Dijk), the same observations were used in figure ??. (ref:casefifa) FIFA 2020, regressing log wages [2020 Euros] from aggregations of skill measurements. The primary observation is a star offensive player (L. Messi) compared with a top defensive player (V. van Dijk). The animate radial tour can be found at github.com/nspyrison/cheem_paper/blob/main/figures/case_fifa.mp4 Figure 4.7: (ref:casefifa) With figure 4.7, we will test the premise of the local explanation. If we remove reaction and movement skills from the basis, offense skills are almost singularly important for explaining the offensive player. We vary the contribution of offensive skills. Offensive skills are removed in the tour (panel b, frame 3), and Messi is no longer separated from the group. We also notice that accuracy has rotated into the frame, maintaining some separability. 4.5.4 4) Ames housing 2018, sales price regression Ames 2018, housing data was subset to North Ames (the neighborhood with the most house sales). The remaining are 338 house sales across nine variables. Using interaction from the global view, we select a house with an extreme negative residual and an accurate observation close to it in the data. (ref:caseames) Ames housing 2018 regressing log sales price [2018 USD]. Because the SHAP values are relatively well distributed across the variables, there is a lot of redundant information to explain the gap between select observations. This case may not be ideal for the cheem methodology, though we did find a near singular frame in the manual tour not, something we came looking for, but certainly, an exciting feature to find. The corresponding animation is at github.com/nspyrison/cheem_paper/blob/main/figures/case_ames2018.mp4 Figure 4.8: (ref:caseames) Figure 4.8 shows the global view and extrema of the tour. The horizontal distance in the tour did not show a significant disparity between our selected points. This is not particularly surprising as most variables have a sizable contribution. Rotating any one variable out of the frame will rotate other vital variables into the frame, preserving most of the distance from intercept to prediction. However, the tour has revealed an interesting feature worth discussing. Notice that the observations pivot about the origin, the basis roughly halfway between bases in frames one and two of panel b) the data is near a singular profile. This means that there is a basis orthogonal to this point that describes sizable variation. Knowing these singular bases can point toward others with meaningful data variation. 4.6 Discussion The need to maintain the interpretability of black-box models is evident. One aspect uses local explanations of the model in the vicinity of an observation. Local explanations approximate the linear variable importance to the model. Our contribution is to assess explanations by examining the support by varying the contributions with a radial tour. First, a global view visualizes approximations of the data space, explanation space, model predictions side-by-side, using dynamic interaction to compare and contrast and identify primary and comparison observations of interest. The normalized linear importance from the explanation of the primary observation becomes the feature of interest to further explore with the radial tour. The tours explore the variable sensitivity to the structure identified in the explanation. We have illustrated this method on random forest models using the tree SHAP local explanation, while it could be generally used with any compatible model-explanation pairing. We apply it to the classification and regression tasks. We have created an open-source R package cheem, available on CRAN, to facilitate preprocessing and exploration with the described interactive application. Toy and real data are provided, or upload your data after preprocessing. 4.7 Acknowledgments We would like to thank Professor Przemyslaw Biecek for his input early in the project and to the broader \\(\\text{MI}^\\text2\\) lab group for the DALEX ecosystem of R and Python packages. This research was supported by Australian Government Research Training Program (RTP) scholarships. Thanks to Jieyang Chong for helping proofread the article. The namesake, Cheem, refers to a fictional race of humanoid trees from Doctor Who lore. DALEX pulls on from that universe, and we initially apply tree SHAP explanations specific to tree-based models. 4.8 References "],["5-ch-conclusion.html", "Chapter 5 Conclusion 5.1 Software development 5.2 Further extensions 5.3 Other contributions", " Chapter 5 Conclusion We know that visualizing data is more robust than numerical summarization alone. It provides a means to rapidly get a feel for the data, check for erroneous values, and confirm model assumptions. But visualizing data spaces becomes increasingly complex as dimensionality increases. Linear dimension reduction and especially dynamic animations of linear projections, tours, seems to be a fruitful way to extend data visualization as dimensionality increases. Previously we havent had a means of testing the sensitivity of individual variables contribution to the structure in one embedding. In Chapter 2 introduced the spinifex package, which facilitates user-controlled manual tours and extends the exporting of any tour, interoperability with tourr. Use of the radial, manual tour does sizably improve the accuracy on variable-level supervised cluster separation task compared with PCA and the grand tour. Chapter @ref(ch-efficacy_radial_tour) covers the with-in participants user study that led to this conclusion. Finally, we extended the use of the manual tour to increase the interpretability of non-linear models by using it to explore their local explanations in the package cheem is discussed in 4. 5.1 Software development The spinifex package facilitates the preprocess transformations with scale_* functions, identifies features with basis_* functions, and allows user-control over variable contributions to the basis with manual tours. It creates a framework for layered creation of tour visuals with proto_* functions will feel at home to ggplot2 users. Manual tours and those created from tourr can be rendered and exported as interactive HTML widgets, .gif, or .mp4 files. Vignettes and interactive an application help users get started. It has been downloaded over 14,400 times from CRAN between 09 April 2019 and 28 November 2021. The package is available on CRAN with vignettes and version notes on its pkgdown site. My contributions spinifex and tourr won the ACEMS Impact and Engagement Award, 2018. In the cheem package, I suggest using manual tours to extend the interpretability of black-box models by exploring their local explanations. A workflow is developed to facilitate the creation of a random forest model, calculating tree SHAP local explanations for each observation. An interactive application illustrates the purposed visual and analysis from several datasets or upload your data after processing. Local explanations are evaluated through testing the sensitivity of the variables to the structure identified in the explanation. cheem was recently uploaded to CRAN and has a corresponding pkgdown site. 5.2 Further extensions In addition to controlling the contribution of a single variable, it may be insightful to able to change contributions of several at once (manipulating on a linear combination). A sort of dimension reduction tour that would append several manual tours together, zeroing the contributions of variables one at a time may prove interesting in the vicinity of the a features intrinsic dimensionality. There are direct natural extensions to spinifex, such as extending the type of protos available, such as adding a text table of the basis, convex hulls, alpha hulls, and a high density region display where the bulk of the data is shown as density contour, while the outer most observations are displayed as points (Hyndman 1996). An additional interpolation of the manual tour could correlate the frame number with the magnitude of a radial tour; the first frame would contain zero magnitude, and the last contains a full contribution, while the default starting frame would initial value. Experiencing tours as 3D scatterplots in extended reality with stereoscopically true head tracking may be fruitful. (Nelson, Cook, and Cruz-Neira 1998) explore 2D tour is in virtual reality. Other works view 3D scatterplot tours on 2D displays (Yang 1999, 2000). It would be interesting to see modern implementations using WebGL, Mozilla A-frame, or Unity. One concern would be trying to keep hardware and software as generalized as possible. Similarly, cheem analysis could be generalized to a broader range models and local explanations. The models and local explanations facilitated by DALEX::explain() seems to be a good starting point (Biecek 2018; Biecek and Burzykowski 2021). Alternatively, there may be other statistics that better show the structure identified by explanations that could be added. 5.3 Other contributions In addition to the research discussed around the thesis of the manual and radial, manual tour other notable contributions during my candidature include: The state-of-the-art on tours for dynamic visualization of high-dimensional data (S. Lee et al. 2021), WIREs Computational Statistics. Review of current tour methods. I contributed writing and manual tour frame discussing manual tours. Is IEEE VIS that good? On key factors in the initial assessment of manuscript and venue quality (Spyrison, Lee, and Besançon 2021). A survey IEEE VIS authors, how they source articles, decide which to read, and evaluate venue quality. We find low evidence that sentiment changes across academic positions for these topics and provide commentary and discussion on the effects of publish or perish environment, standard author and journal metrics, and the need to publish null findings and replication studies. Intraday effect of COVID-19 restrictions on Melbourne electricity consumption (Barrow, Chong, and Spyrison 2020). We corroborate that the Victorian interday effect on energy consumption did not change, and novelly find that the intraday distribution of energy consumption does change. Namely, we find a statistically significant change in the height of the morning and evening peak, energy consumption that we posit is due to less strict schedules associated with working from home, absence of commute time, and other employment changes. We were awarded 1st place of hundreds of entries in the insights category of the Melbourne 2020 Datathon. Student volunteering at three conferences: UseR!2021 - Online, CHI Down Under 2020 - Online, and UseR!2018 - Brisbane, Australia. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
